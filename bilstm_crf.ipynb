{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchcrf import CRF\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "pd.set_option('max_colwidth',None)\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool\n",
    "import math\n",
    "import gzip\n",
    "import wordninja"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/raw_data/已标注data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('MONEY\tMONEY_NEW\tDATE\\tlabel'.split('\\t'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[52, 56], [96, 100]]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_substring(long_str, short_str):\n",
    "    indices = []\n",
    "    length_long = len(long_str)\n",
    "    length_short = len(short_str)\n",
    "    i = 0\n",
    "    while i <= length_long - length_short:\n",
    "        if long_str[i:i+length_short] == short_str:\n",
    "            indices.append([i, i + length_short - 1])\n",
    "        i += 1\n",
    "    return indices\n",
    "text = '<NairaBag > Thank you, we received your payment for 3,000 and the remaining outstanding loan is 3,000.'\n",
    "label = '3,000'\n",
    "find_substring(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315808/315808 [00:09<00:00, 31938.80it/s]\n"
     ]
    }
   ],
   "source": [
    "label_list = []\n",
    "too_many_amount = []\n",
    "too_many_days = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    label_dict = {}\n",
    "\n",
    "    text = str(df['msg'].iloc[i])\n",
    "    amount = str(df['amount'].iloc[i])\n",
    "    days = str(df['days'].iloc[i])\n",
    "\n",
    "    if amount != 'nan':\n",
    "        loc = find_substring(text, amount)\n",
    "        if len(loc) > 1:\n",
    "            too_many_amount.append(1)\n",
    "        else:\n",
    "            label_dict['amount'] =amount\n",
    "            too_many_amount.append(0)\n",
    "    else:\n",
    "        label_dict['amount'] = {}\n",
    "        too_many_amount.append(0)\n",
    "    if days != 'nan':\n",
    "        loc = find_substring(text, days)\n",
    "        if len(loc) > 1:\n",
    "            too_many_days.append(1)\n",
    "        else:\n",
    "            label_dict['days'] = days\n",
    "            too_many_days.append(0)\n",
    "    else:\n",
    "        label_dict['days'] = {}\n",
    "        too_many_days.append(0)\n",
    "    label_list.append(label_dict)\n",
    "df['label'] = label_list\n",
    "df['too_many_amount'] = too_many_amount\n",
    "df['too_many_days'] = too_many_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['too_many_days']==0) & (df['too_many_amount']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['label','too_many_amount','too_many_days'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitJoinWords():\n",
    "    def __init__(self, data_path):\n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            self.corpus = f.read()\n",
    "        self.dictionary = self.build_freq_stats()\n",
    "        self.segmenter = wordninja.LanguageModel('conf/freq_stats.txt.gz')\n",
    "\n",
    "    def words(self, text): \n",
    "        return re.findall('[a-zA-Z]+|[,.]', text)\n",
    "    \n",
    "    def build_freq_stats(self):\n",
    "        freq_stats = Counter(self.words(self.corpus))\n",
    "        sorted_keys = sorted(freq_stats, key=lambda k: freq_stats[k], reverse=True)\n",
    "        with gzip.open('conf/freq_stats.txt.gz', 'wt', encoding='utf-8') as f:\n",
    "            for word in sorted_keys:\n",
    "                f.write(word+'\\n')\n",
    "        return set(sorted_keys)\n",
    "\n",
    "    def split(self, word):\n",
    "        return self.segmenter.split(word)\n",
    "\n",
    "class Tokenizer():\n",
    "    def __init__(self):\n",
    "        self.pattern = re.compile(r'[\\n\\r\\t]|(\\d)|[\\!\\\"\\#\\$\\%\\&\\\\\\'\\(\\)\\*\\+\\/\\:\\;\\<\\=\\>\\?\\@\\[\\\\\\\\\\]\\^\\`\\{\\|\\}\\~\\，\\。\\？\\！\\：\\、\\《\\》\\ ]|([\\,\\.\\-\\_])')\n",
    "        \n",
    "    def tokenize(self, sentence, segmenter):\n",
    "        token_list = []\n",
    "        tokens = re.split(self.pattern, sentence)\n",
    "        for token in tokens:\n",
    "            if token and token not in '\\,\\.\\-\\_':\n",
    "                token_list.extend(segmenter.split(token))\n",
    "            elif token and token in '\\,\\.\\-\\_':\n",
    "                token_list.append(token)\n",
    "        return token_list\n",
    "segmenter = SplitJoinWords('data/raw_data/train.csv')\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294771/294771 [02:18<00:00, 2132.38it/s]\n"
     ]
    }
   ],
   "source": [
    "msg_tokens_list = []\n",
    "amount_tokens_list = []\n",
    "days_tokens_list = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    msg = str(df['msg'].iloc[i])\n",
    "    amount = str(df['amount'].iloc[i])\n",
    "    days = str(df['days'].iloc[i])\n",
    "    msg_tokens = tokenizer.tokenize(msg,segmenter)\n",
    "    if amount != 'nan':\n",
    "        amount_tokens = tokenizer.tokenize(df['amount'].iloc[i],segmenter)\n",
    "    else:\n",
    "        amount_tokens = None\n",
    "    if days != 'nan':\n",
    "        days_tokens = tokenizer.tokenize(df['days'].iloc[i],segmenter)\n",
    "    else:\n",
    "        days_tokens = None  \n",
    "    msg_tokens_list.append(msg_tokens)\n",
    "    amount_tokens_list.append(amount_tokens)\n",
    "    days_tokens_list.append(days_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['msg_tokens'] = msg_tokens_list\n",
    "df['amount'] = amount_tokens_list\n",
    "df['days'] = days_tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294771/294771 [00:06<00:00, 45289.91it/s]\n"
     ]
    }
   ],
   "source": [
    "def bieo(df, text_col, label_cols):\n",
    "    bieo_col = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        msg_tokens = df[text_col].iloc[i]\n",
    "        bieo_list = ['O'] * len(msg_tokens)\n",
    "        for col in label_cols:\n",
    "            label_toknes = df[col].iloc[i]\n",
    "            for j in range(len(msg_tokens)):\n",
    "                if label_toknes and msg_tokens[j:j+len(label_toknes)] == label_toknes:\n",
    "                    bieo_list[j:j+len(label_toknes)-1] = ['I-' + col] * len(label_toknes)\n",
    "                    bieo_list[j] = 'B-' + col\n",
    "                    bieo_list[j+len(label_toknes)-1] = 'E-'  + col\n",
    "        bieo_col.append(bieo_list)\n",
    "    df['label'] = bieo_col\n",
    "bieo(df, text_col = 'msg_tokens',label_cols = ['days', 'amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3)\n",
    "val, test = train_test_split(test, test_size= 2/3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206339/206339 [00:06<00:00, 33807.18it/s]\n",
      "100%|██████████| 29477/29477 [00:00<00:00, 33080.90it/s]\n",
      "100%|██████████| 58955/58955 [00:01<00:00, 33686.35it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('./data/raw_data/train.txt','w',encoding='utf-8') as f:\n",
    "    for i in tqdm(range(len(train))):\n",
    "        text_list = train['msg_tokens'].iloc[i]\n",
    "        label_list = train['label'].iloc[i]\n",
    "        for token, label in zip(text_list, label_list):\n",
    "            f.write(token + '\\t' + label + '\\n')\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('./data/raw_data/val.txt','w',encoding='utf-8') as f:\n",
    "    for i in tqdm(range(len(val))):\n",
    "        text_list = val['msg_tokens'].iloc[i]\n",
    "        label_list = val['label'].iloc[i]\n",
    "        for token, label in zip(text_list, label_list):\n",
    "            f.write(token + '\\t' + label + '\\n')\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('./data/raw_data/test.txt','w',encoding='utf-8') as f:\n",
    "    for i in tqdm(range(len(test))):\n",
    "        text_list = test['msg_tokens'].iloc[i]\n",
    "        label_list = test['label'].iloc[i]\n",
    "        for token, label in zip(text_list, label_list):\n",
    "            f.write(token + '\\t' + label + '\\n')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清洗以及BIO标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',None)\n",
    "def tokenizer(sentence):\n",
    "    sentence = re.sub(r'(\\d)([a-zA-Z])', r'\\1 \\2', sentence)\n",
    "    sentence = re.sub(r'([a-zA-Z])(\\d)', r'\\1 \\2', sentence)\n",
    "    tokens = re.findall(r'\\d|[^\\w\\s]|\\w+', sentence)\n",
    "    return tokens\n",
    "\n",
    "def bio(text, label, label_class,tag_seq=None):\n",
    "    text_split = tokenizer(text)\n",
    "    if not tag_seq:\n",
    "            tag_seq = ['O'] * len(text_split)\n",
    "    label_split = tokenizer(label)\n",
    "    start_indices = [i for i in range(len(text_split)) if text_split[i:i+len(label_split)] == label_split]\n",
    "    if len(start_indices) == 0:\n",
    "        return tag_seq\n",
    "    \n",
    "    for start_index in start_indices:\n",
    "        end_index = start_index + len(label_split)\n",
    "\n",
    "        if end_index - start_index == 1:\n",
    "            tag_seq[start_index] = 'B-' + label_class\n",
    "        else:\n",
    "            tag_seq[start_index] = 'B-' + label_class\n",
    "            tag_seq[end_index-1] = 'E-' + label_class\n",
    "            for i in range(start_index+1, end_index-1):\n",
    "                tag_seq[i] = 'I-' + label_class\n",
    "    return tag_seq\n",
    "\n",
    "def bio_df(df):\n",
    "    df_ = df.copy()\n",
    "    bio_col = []\n",
    "    text_col = []\n",
    "    for i, row in tqdm(df_.iterrows()):\n",
    "        days = str(row['days'])\n",
    "        amount = str(row['amount'])\n",
    "        msg = str(row['msg'])\n",
    "        token_seq = tokenizer(msg)\n",
    "        label_seq = bio(msg, days, 'days')\n",
    "        label_seq = bio(msg, amount, 'amount', label_seq)\n",
    "        assert len(token_seq) == len(label_seq)\n",
    "        bio_col.append(label_seq)\n",
    "        text_col.append(token_seq)\n",
    "    df_['BIO'] = bio_col\n",
    "    df_['text'] = text_col\n",
    "    train, test = train_test_split(df_,test_size=0.1)\n",
    "    with open('comp_train.json', 'w') as f:\n",
    "        for index, row in train.iterrows():\n",
    "            # 将每行的text和label列的值转换为字典\n",
    "            data = {'text': row['text'], 'label': row['BIO']}\n",
    "            # 将字典转换为JSON字符串并写入文件\n",
    "            f.write(json.dumps(data))\n",
    "            f.write('\\n')\n",
    "\n",
    "    with open('comp_test.json', 'w') as f:\n",
    "        for index, row in test.iterrows():\n",
    "            # 将每行的text和label列的值转换为字典\n",
    "            data = {'text': row['text'], 'label': row['BIO']}\n",
    "            # 将字典转换为JSON字符串并写入文件\n",
    "            f.write(json.dumps(data))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "315808it [00:36, 8716.46it/s] \n"
     ]
    }
   ],
   "source": [
    "bio_df(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建word2id和tag2id，id2word和id2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word2id_tag2id(data_path):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(data_path,'r') as f:\n",
    "            for line in f:\n",
    "                sentence = json.loads(line)\n",
    "                sentences.append(sentence['text'])\n",
    "                labels.append(sentence['label'])\n",
    "    word2id = {'<PAD>':0,'<UNK>':1}\n",
    "    tag2id = {}\n",
    "    for sentence, label in zip(sentences, labels):\n",
    "        for word, tag in zip(sentence, label):\n",
    "            if word not in word2id:\n",
    "                word2id[word] = len(word2id)\n",
    "            if tag not in  tag2id:\n",
    "                tag2id[tag] = len(tag2id)\n",
    "    return word2id, tag2id      \n",
    "word2id, tag2id = build_word2id_tag2id(r'./comp_train.json')\n",
    "id2word, id2tag = {v:k for k,v in word2id.items()}, {v:k for k,v in tag2id.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 封装数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path, word2id, tag2id):\n",
    "        self.data_path = data_path\n",
    "        self.word2id = word2id\n",
    "        self.tag2id = tag2id\n",
    "        self.texts = []\n",
    "        self.labels = []\n",
    "        # 加载数据\n",
    "        with open(data_path,'r') as f:\n",
    "            for line in f:\n",
    "                sentence = json.loads(line)\n",
    "                self.texts.append(sentence['text'])\n",
    "                self.labels.append(sentence['label'])\n",
    "        # mask\n",
    "        self.mask = []\n",
    "        for sentence in self.texts:\n",
    "            mask = [1] * len(sentence)\n",
    "            self.mask.append(mask)\n",
    "        # 计算最大长度\n",
    "        max_length = 0     \n",
    "        for sentence_label in self.labels:\n",
    "            length = len(sentence_label)\n",
    "            if length > max_length:\n",
    "                max_length = length\n",
    "\n",
    "        # 填充句子\n",
    "        for i in range(len(self.texts)):\n",
    "            length = len(self.texts[i])\n",
    "            if length < max_length:\n",
    "                pad_length = max_length - length\n",
    "                self.texts[i].extend(['<PAD>'] * pad_length)\n",
    "                self.labels[i].extend(['O'] * pad_length)\n",
    "                self.mask[i].extend([0] * pad_length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        mask = self.mask[idx]\n",
    "        sentence_to_id = []\n",
    "        label_to_id = []\n",
    "        for word, tag, m in zip(sentence, label, mask):\n",
    "            if word in self.word2id:\n",
    "                sentence_to_id.append(self.word2id[word])\n",
    "            else:\n",
    "                sentence_to_id.append(self.word2id['<UNK>'])\n",
    "            label_to_id.append(self.tag2id[tag])\n",
    "        return torch.tensor(sentence_to_id), torch.tensor(label_to_id), torch.tensor(mask).bool()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据封装与模型初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MyDataset('./comp_train.json',word2id, tag2id)\n",
    "dev = MyDataset('./comp_test.json',word2id, tag2id)\n",
    "train_dataloader = DataLoader(train, batch_size=128, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建基于bilstm+crf实现ner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BilstmCrf(word2id, \n",
    "                    tag2id, \n",
    "                    embedding_dim=128, \n",
    "                    hidden_dim=200, \n",
    "                    num_layers=2,\n",
    "                    dropout=0.3)\n",
    "model.to(device)\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, train_dataloader, validate_dataloader, optimizer, scheduler, epochs):\n",
    "    best_f1_score = 0\n",
    "    early_stop = 0\n",
    "    # 模型保存地址\n",
    "    time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime(time.time()))\n",
    "    model_saved_path = f\"./{model_name}_{time_str}.pt\"\n",
    "    best_report = None\n",
    "    for epoch in range(epochs):\n",
    "        loss = train_single_epoch(model, train_dataloader, validate_dataloader, optimizer, epoch)\n",
    "        scheduler.step()\n",
    "        report = eval(model, validate_dataloader, id2tag)\n",
    "        precision = report['macro avg']['precision']\n",
    "        recall = report['macro avg']['recall']\n",
    "        f1_score = report['macro avg']['f1-score']\n",
    "        print(f'epoch:{epoch + 1} precision:{precision} recall:{recall} f1-score:{f1_score}' )\n",
    "        if f1_score > best_f1_score:\n",
    "            early_stop = 0\n",
    "            best_f1_score = f1_score\n",
    "            torch.save(model.state_dict(), model_saved_path)\n",
    "            best_report = report\n",
    "        else:\n",
    "            early_stop += 1\n",
    "            if early_stop == 3:\n",
    "                print(pd.DataFrame(report))\n",
    "                break\n",
    "    print(pd.DataFrame(best_report))\n",
    "    return\n",
    "\n",
    "def train_single_epoch(model, train_dataloader, validate_dataloader, optimizer, epoch):\n",
    "    epoch_loss = 0\n",
    "    for i, (inputs, label, mask) in enumerate(train_dataloader):\n",
    "        # 将数据移到GPU上\n",
    "        model.train()\n",
    "        inputs = inputs.to(device)\n",
    "        label = label.to(device)\n",
    "        mask = mask.to(device)\n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播计算损失\n",
    "        loss = model.compute_loss(inputs, label, mask)\n",
    "\n",
    "        # 反向传播计算梯度\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 统计损失\n",
    "        epoch_loss += loss.item()\n",
    "        # 打印每轮batch的loss\n",
    "        if i == 0 or (i+1) % 10==0 or i==len(train_dataloader):\n",
    "            print(f'epoch:{epoch + 1} batch {i+1}/{len(train_dataloader)}) Loss:{loss.item()}')\n",
    "    return epoch_loss / len(train_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "def eval(model, validate_dataloader, id2tag):\n",
    "    model.eval()\n",
    "\n",
    "    true_labels = []\n",
    "    predict_labels = []\n",
    "\n",
    "    for (inputs, label, mask) in validate_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        out = model.decode(inputs)\n",
    "        for out_sentence, label_sentence in zip(out, label.tolist()):\n",
    "            for predict_label, true_label in zip(out_sentence,label_sentence):\n",
    "                true_labels.append(id2tag[true_label])\n",
    "                predict_labels.append(id2tag[predict_label])\n",
    "    report = classification_report(true_labels, predict_labels, output_dict=True)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 batch 1/2221) Loss:11880.912109375\n",
      "epoch:1 batch 10/2221) Loss:12563.33984375\n",
      "epoch:1 batch 20/2221) Loss:10768.126953125\n",
      "epoch:1 batch 30/2221) Loss:10339.71484375\n",
      "epoch:1 batch 40/2221) Loss:9217.990234375\n",
      "epoch:1 batch 50/2221) Loss:8335.060546875\n",
      "epoch:1 batch 60/2221) Loss:6162.5517578125\n",
      "epoch:1 batch 70/2221) Loss:4114.32421875\n",
      "epoch:1 batch 80/2221) Loss:3003.3466796875\n",
      "epoch:1 batch 90/2221) Loss:2679.3505859375\n",
      "epoch:1 batch 100/2221) Loss:2158.533447265625\n",
      "epoch:1 batch 110/2221) Loss:2558.849609375\n",
      "epoch:1 batch 120/2221) Loss:2190.23193359375\n",
      "epoch:1 batch 130/2221) Loss:2252.865478515625\n",
      "epoch:1 batch 140/2221) Loss:2034.83447265625\n",
      "epoch:1 batch 150/2221) Loss:2036.118408203125\n",
      "epoch:1 batch 160/2221) Loss:1852.30615234375\n",
      "epoch:1 batch 170/2221) Loss:1905.473876953125\n",
      "epoch:1 batch 180/2221) Loss:1625.839599609375\n",
      "epoch:1 batch 190/2221) Loss:1729.02490234375\n",
      "epoch:1 batch 200/2221) Loss:1623.231201171875\n",
      "epoch:1 batch 210/2221) Loss:1761.4169921875\n",
      "epoch:1 batch 220/2221) Loss:1445.1812744140625\n",
      "epoch:1 batch 230/2221) Loss:1609.3978271484375\n",
      "epoch:1 batch 240/2221) Loss:1394.853271484375\n",
      "epoch:1 batch 250/2221) Loss:1342.1019287109375\n",
      "epoch:1 batch 260/2221) Loss:1240.8873291015625\n",
      "epoch:1 batch 270/2221) Loss:1296.51953125\n",
      "epoch:1 batch 280/2221) Loss:1150.0146484375\n",
      "epoch:1 batch 290/2221) Loss:1161.291015625\n",
      "epoch:1 batch 300/2221) Loss:1262.45849609375\n",
      "epoch:1 batch 310/2221) Loss:1145.5841064453125\n",
      "epoch:1 batch 320/2221) Loss:1131.208740234375\n",
      "epoch:1 batch 330/2221) Loss:970.365478515625\n",
      "epoch:1 batch 340/2221) Loss:975.4321899414062\n",
      "epoch:1 batch 350/2221) Loss:838.2515869140625\n",
      "epoch:1 batch 360/2221) Loss:842.9526977539062\n",
      "epoch:1 batch 370/2221) Loss:927.61376953125\n",
      "epoch:1 batch 380/2221) Loss:856.9918212890625\n",
      "epoch:1 batch 390/2221) Loss:868.760986328125\n",
      "epoch:1 batch 400/2221) Loss:760.0899658203125\n",
      "epoch:1 batch 410/2221) Loss:834.13037109375\n",
      "epoch:1 batch 420/2221) Loss:818.3397827148438\n",
      "epoch:1 batch 430/2221) Loss:795.4806518554688\n",
      "epoch:1 batch 440/2221) Loss:774.548828125\n",
      "epoch:1 batch 450/2221) Loss:697.5323486328125\n",
      "epoch:1 batch 460/2221) Loss:778.064453125\n",
      "epoch:1 batch 470/2221) Loss:709.715087890625\n",
      "epoch:1 batch 480/2221) Loss:669.4862060546875\n",
      "epoch:1 batch 490/2221) Loss:825.7706909179688\n",
      "epoch:1 batch 500/2221) Loss:722.767578125\n",
      "epoch:1 batch 510/2221) Loss:601.8920288085938\n",
      "epoch:1 batch 520/2221) Loss:697.6441650390625\n",
      "epoch:1 batch 530/2221) Loss:545.7842407226562\n",
      "epoch:1 batch 540/2221) Loss:624.55078125\n",
      "epoch:1 batch 550/2221) Loss:726.59765625\n",
      "epoch:1 batch 560/2221) Loss:590.5369873046875\n",
      "epoch:1 batch 570/2221) Loss:590.1229248046875\n",
      "epoch:1 batch 580/2221) Loss:629.8662109375\n",
      "epoch:1 batch 590/2221) Loss:483.09820556640625\n",
      "epoch:1 batch 600/2221) Loss:515.9407348632812\n",
      "epoch:1 batch 610/2221) Loss:527.9330444335938\n",
      "epoch:1 batch 620/2221) Loss:529.26123046875\n",
      "epoch:1 batch 630/2221) Loss:575.708251953125\n",
      "epoch:1 batch 640/2221) Loss:437.57012939453125\n",
      "epoch:1 batch 650/2221) Loss:471.3262634277344\n",
      "epoch:1 batch 660/2221) Loss:480.7825012207031\n",
      "epoch:1 batch 670/2221) Loss:467.45196533203125\n",
      "epoch:1 batch 680/2221) Loss:431.2281494140625\n",
      "epoch:1 batch 690/2221) Loss:522.1759033203125\n",
      "epoch:1 batch 700/2221) Loss:426.02642822265625\n",
      "epoch:1 batch 710/2221) Loss:475.6086730957031\n",
      "epoch:1 batch 720/2221) Loss:478.50738525390625\n",
      "epoch:1 batch 730/2221) Loss:391.1358642578125\n",
      "epoch:1 batch 740/2221) Loss:391.2980651855469\n",
      "epoch:1 batch 750/2221) Loss:370.44146728515625\n",
      "epoch:1 batch 760/2221) Loss:499.3375244140625\n",
      "epoch:1 batch 770/2221) Loss:390.967041015625\n",
      "epoch:1 batch 780/2221) Loss:405.3441467285156\n",
      "epoch:1 batch 790/2221) Loss:330.5994567871094\n",
      "epoch:1 batch 800/2221) Loss:364.6398620605469\n",
      "epoch:1 batch 810/2221) Loss:397.79364013671875\n",
      "epoch:1 batch 820/2221) Loss:327.5938415527344\n",
      "epoch:1 batch 830/2221) Loss:387.2869873046875\n",
      "epoch:1 batch 840/2221) Loss:321.4798278808594\n",
      "epoch:1 batch 850/2221) Loss:361.1075134277344\n",
      "epoch:1 batch 860/2221) Loss:367.7652282714844\n",
      "epoch:1 batch 870/2221) Loss:307.46185302734375\n",
      "epoch:1 batch 880/2221) Loss:339.36688232421875\n",
      "epoch:1 batch 890/2221) Loss:339.6363220214844\n",
      "epoch:1 batch 900/2221) Loss:354.5687255859375\n",
      "epoch:1 batch 910/2221) Loss:365.2612609863281\n",
      "epoch:1 batch 920/2221) Loss:286.9350280761719\n",
      "epoch:1 batch 930/2221) Loss:272.6000061035156\n",
      "epoch:1 batch 940/2221) Loss:311.0971984863281\n",
      "epoch:1 batch 950/2221) Loss:353.0426330566406\n",
      "epoch:1 batch 960/2221) Loss:332.38726806640625\n",
      "epoch:1 batch 970/2221) Loss:225.79283142089844\n",
      "epoch:1 batch 980/2221) Loss:241.2747039794922\n",
      "epoch:1 batch 990/2221) Loss:311.3394775390625\n",
      "epoch:1 batch 1000/2221) Loss:335.48095703125\n",
      "epoch:1 batch 1010/2221) Loss:200.48410034179688\n",
      "epoch:1 batch 1020/2221) Loss:354.3004455566406\n",
      "epoch:1 batch 1030/2221) Loss:291.413330078125\n",
      "epoch:1 batch 1040/2221) Loss:242.79397583007812\n",
      "epoch:1 batch 1050/2221) Loss:314.4564208984375\n",
      "epoch:1 batch 1060/2221) Loss:261.4876708984375\n",
      "epoch:1 batch 1070/2221) Loss:337.88446044921875\n",
      "epoch:1 batch 1080/2221) Loss:250.50830078125\n",
      "epoch:1 batch 1090/2221) Loss:219.04627990722656\n",
      "epoch:1 batch 1100/2221) Loss:215.33309936523438\n",
      "epoch:1 batch 1110/2221) Loss:259.9725341796875\n",
      "epoch:1 batch 1120/2221) Loss:266.1207580566406\n",
      "epoch:1 batch 1130/2221) Loss:211.42527770996094\n",
      "epoch:1 batch 1140/2221) Loss:301.5367126464844\n",
      "epoch:1 batch 1150/2221) Loss:183.88851928710938\n",
      "epoch:1 batch 1160/2221) Loss:235.4795684814453\n",
      "epoch:1 batch 1170/2221) Loss:238.50238037109375\n",
      "epoch:1 batch 1180/2221) Loss:262.7681884765625\n",
      "epoch:1 batch 1190/2221) Loss:178.62750244140625\n",
      "epoch:1 batch 1200/2221) Loss:238.2266845703125\n",
      "epoch:1 batch 1210/2221) Loss:208.78021240234375\n",
      "epoch:1 batch 1220/2221) Loss:287.6746520996094\n",
      "epoch:1 batch 1230/2221) Loss:233.49302673339844\n",
      "epoch:1 batch 1240/2221) Loss:231.26876831054688\n",
      "epoch:1 batch 1250/2221) Loss:204.86874389648438\n",
      "epoch:1 batch 1260/2221) Loss:237.91830444335938\n",
      "epoch:1 batch 1270/2221) Loss:294.92041015625\n",
      "epoch:1 batch 1280/2221) Loss:176.32211303710938\n",
      "epoch:1 batch 1290/2221) Loss:220.48023986816406\n",
      "epoch:1 batch 1300/2221) Loss:213.2832794189453\n",
      "epoch:1 batch 1310/2221) Loss:245.46405029296875\n",
      "epoch:1 batch 1320/2221) Loss:202.45870971679688\n",
      "epoch:1 batch 1330/2221) Loss:245.6179656982422\n",
      "epoch:1 batch 1340/2221) Loss:202.95042419433594\n",
      "epoch:1 batch 1350/2221) Loss:183.03646850585938\n",
      "epoch:1 batch 1360/2221) Loss:256.7325439453125\n",
      "epoch:1 batch 1370/2221) Loss:214.22683715820312\n",
      "epoch:1 batch 1380/2221) Loss:200.29754638671875\n",
      "epoch:1 batch 1390/2221) Loss:141.22055053710938\n",
      "epoch:1 batch 1400/2221) Loss:249.49826049804688\n",
      "epoch:1 batch 1410/2221) Loss:122.24528503417969\n",
      "epoch:1 batch 1420/2221) Loss:220.41305541992188\n",
      "epoch:1 batch 1430/2221) Loss:175.57339477539062\n",
      "epoch:1 batch 1440/2221) Loss:147.0846405029297\n",
      "epoch:1 batch 1450/2221) Loss:130.4701385498047\n",
      "epoch:1 batch 1460/2221) Loss:173.76730346679688\n",
      "epoch:1 batch 1470/2221) Loss:233.2919158935547\n",
      "epoch:1 batch 1480/2221) Loss:166.02830505371094\n",
      "epoch:1 batch 1490/2221) Loss:216.859130859375\n",
      "epoch:1 batch 1500/2221) Loss:188.13034057617188\n",
      "epoch:1 batch 1510/2221) Loss:183.10256958007812\n",
      "epoch:1 batch 1520/2221) Loss:194.37625122070312\n",
      "epoch:1 batch 1530/2221) Loss:146.35215759277344\n",
      "epoch:1 batch 1540/2221) Loss:158.95004272460938\n",
      "epoch:1 batch 1550/2221) Loss:173.98565673828125\n",
      "epoch:1 batch 1560/2221) Loss:176.9417266845703\n",
      "epoch:1 batch 1570/2221) Loss:176.46273803710938\n",
      "epoch:1 batch 1580/2221) Loss:167.85516357421875\n",
      "epoch:1 batch 1590/2221) Loss:234.00650024414062\n",
      "epoch:1 batch 1600/2221) Loss:147.23936462402344\n",
      "epoch:1 batch 1610/2221) Loss:125.37124633789062\n",
      "epoch:1 batch 1620/2221) Loss:116.58071899414062\n",
      "epoch:1 batch 1630/2221) Loss:169.29647827148438\n",
      "epoch:1 batch 1640/2221) Loss:140.5999755859375\n",
      "epoch:1 batch 1650/2221) Loss:210.83941650390625\n",
      "epoch:1 batch 1660/2221) Loss:155.9103240966797\n",
      "epoch:1 batch 1670/2221) Loss:165.3437957763672\n",
      "epoch:1 batch 1680/2221) Loss:139.5345458984375\n",
      "epoch:1 batch 1690/2221) Loss:82.4690933227539\n",
      "epoch:1 batch 1700/2221) Loss:128.09988403320312\n",
      "epoch:1 batch 1710/2221) Loss:199.79808044433594\n",
      "epoch:1 batch 1720/2221) Loss:190.75210571289062\n",
      "epoch:1 batch 1730/2221) Loss:213.3509063720703\n",
      "epoch:1 batch 1740/2221) Loss:180.55886840820312\n",
      "epoch:1 batch 1750/2221) Loss:171.11956787109375\n",
      "epoch:1 batch 1760/2221) Loss:210.49575805664062\n",
      "epoch:1 batch 1770/2221) Loss:204.2218780517578\n",
      "epoch:1 batch 1780/2221) Loss:119.96540832519531\n",
      "epoch:1 batch 1790/2221) Loss:161.66058349609375\n",
      "epoch:1 batch 1800/2221) Loss:148.66110229492188\n",
      "epoch:1 batch 1810/2221) Loss:98.356201171875\n",
      "epoch:1 batch 1820/2221) Loss:132.54537963867188\n",
      "epoch:1 batch 1830/2221) Loss:108.00885009765625\n",
      "epoch:1 batch 1840/2221) Loss:135.94175720214844\n",
      "epoch:1 batch 1850/2221) Loss:129.3854522705078\n",
      "epoch:1 batch 1860/2221) Loss:133.69493103027344\n",
      "epoch:1 batch 1870/2221) Loss:89.68699645996094\n",
      "epoch:1 batch 1880/2221) Loss:141.5122528076172\n",
      "epoch:1 batch 1890/2221) Loss:112.08403015136719\n",
      "epoch:1 batch 1900/2221) Loss:103.95501708984375\n",
      "epoch:1 batch 1910/2221) Loss:108.11924743652344\n",
      "epoch:1 batch 1920/2221) Loss:95.885986328125\n",
      "epoch:1 batch 1930/2221) Loss:142.2856903076172\n",
      "epoch:1 batch 1940/2221) Loss:149.73016357421875\n",
      "epoch:1 batch 1950/2221) Loss:164.82876586914062\n",
      "epoch:1 batch 1960/2221) Loss:127.50558471679688\n",
      "epoch:1 batch 1970/2221) Loss:110.81574249267578\n",
      "epoch:1 batch 1980/2221) Loss:127.76133728027344\n",
      "epoch:1 batch 1990/2221) Loss:136.924560546875\n",
      "epoch:1 batch 2000/2221) Loss:131.45240783691406\n",
      "epoch:1 batch 2010/2221) Loss:165.92098999023438\n",
      "epoch:1 batch 2020/2221) Loss:141.99752807617188\n",
      "epoch:1 batch 2030/2221) Loss:118.50594329833984\n",
      "epoch:1 batch 2040/2221) Loss:150.5281524658203\n",
      "epoch:1 batch 2050/2221) Loss:123.1415023803711\n",
      "epoch:1 batch 2060/2221) Loss:157.35562133789062\n",
      "epoch:1 batch 2070/2221) Loss:138.30963134765625\n",
      "epoch:1 batch 2080/2221) Loss:178.9935302734375\n",
      "epoch:1 batch 2090/2221) Loss:139.2317657470703\n",
      "epoch:1 batch 2100/2221) Loss:170.85379028320312\n",
      "epoch:1 batch 2110/2221) Loss:76.10896301269531\n",
      "epoch:1 batch 2120/2221) Loss:160.54054260253906\n",
      "epoch:1 batch 2130/2221) Loss:82.88218688964844\n",
      "epoch:1 batch 2140/2221) Loss:112.79673767089844\n",
      "epoch:1 batch 2150/2221) Loss:114.25410461425781\n",
      "epoch:1 batch 2160/2221) Loss:107.61761474609375\n",
      "epoch:1 batch 2170/2221) Loss:136.98558044433594\n",
      "epoch:1 batch 2180/2221) Loss:139.32351684570312\n",
      "epoch:1 batch 2190/2221) Loss:80.52676391601562\n",
      "epoch:1 batch 2200/2221) Loss:119.02728271484375\n",
      "epoch:1 batch 2210/2221) Loss:86.4557113647461\n",
      "epoch:1 batch 2220/2221) Loss:65.28214263916016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchcrf\\__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorCompare.cpp:413.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
      "d:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 precision:0.8280896747094458 recall:0.7983012359942376 f1-score:0.8123559012925167\n",
      "epoch:2 batch 1/2221) Loss:76.26997375488281\n",
      "epoch:2 batch 10/2221) Loss:85.35252380371094\n",
      "epoch:2 batch 20/2221) Loss:93.84513854980469\n",
      "epoch:2 batch 30/2221) Loss:93.95509338378906\n",
      "epoch:2 batch 40/2221) Loss:94.27284240722656\n",
      "epoch:2 batch 50/2221) Loss:91.32664489746094\n",
      "epoch:2 batch 60/2221) Loss:99.82341766357422\n",
      "epoch:2 batch 70/2221) Loss:81.10442352294922\n",
      "epoch:2 batch 80/2221) Loss:58.92112731933594\n",
      "epoch:2 batch 90/2221) Loss:82.06031036376953\n",
      "epoch:2 batch 100/2221) Loss:100.6032943725586\n",
      "epoch:2 batch 110/2221) Loss:135.50535583496094\n",
      "epoch:2 batch 120/2221) Loss:112.96754455566406\n",
      "epoch:2 batch 130/2221) Loss:77.35137939453125\n",
      "epoch:2 batch 140/2221) Loss:133.91244506835938\n",
      "epoch:2 batch 150/2221) Loss:178.332763671875\n",
      "epoch:2 batch 160/2221) Loss:111.77056121826172\n",
      "epoch:2 batch 170/2221) Loss:180.7086181640625\n",
      "epoch:2 batch 180/2221) Loss:119.13520812988281\n",
      "epoch:2 batch 190/2221) Loss:97.44049072265625\n",
      "epoch:2 batch 200/2221) Loss:95.80203247070312\n",
      "epoch:2 batch 210/2221) Loss:85.8903579711914\n",
      "epoch:2 batch 220/2221) Loss:54.92547607421875\n",
      "epoch:2 batch 230/2221) Loss:122.16071319580078\n",
      "epoch:2 batch 240/2221) Loss:131.4919891357422\n",
      "epoch:2 batch 250/2221) Loss:180.9757537841797\n",
      "epoch:2 batch 260/2221) Loss:161.0455322265625\n",
      "epoch:2 batch 270/2221) Loss:104.17115783691406\n",
      "epoch:2 batch 280/2221) Loss:91.4383316040039\n",
      "epoch:2 batch 290/2221) Loss:92.36680603027344\n",
      "epoch:2 batch 300/2221) Loss:103.36361694335938\n",
      "epoch:2 batch 310/2221) Loss:171.21078491210938\n",
      "epoch:2 batch 320/2221) Loss:93.83428955078125\n",
      "epoch:2 batch 330/2221) Loss:94.61932373046875\n",
      "epoch:2 batch 340/2221) Loss:64.32681274414062\n",
      "epoch:2 batch 350/2221) Loss:157.3341064453125\n",
      "epoch:2 batch 360/2221) Loss:107.2344970703125\n",
      "epoch:2 batch 370/2221) Loss:133.53347778320312\n",
      "epoch:2 batch 380/2221) Loss:122.94808197021484\n",
      "epoch:2 batch 390/2221) Loss:103.17497253417969\n",
      "epoch:2 batch 400/2221) Loss:54.44953918457031\n",
      "epoch:2 batch 410/2221) Loss:121.62236022949219\n",
      "epoch:2 batch 420/2221) Loss:90.64214324951172\n",
      "epoch:2 batch 430/2221) Loss:100.51749420166016\n",
      "epoch:2 batch 440/2221) Loss:155.75985717773438\n",
      "epoch:2 batch 450/2221) Loss:126.2556381225586\n",
      "epoch:2 batch 460/2221) Loss:67.19413757324219\n",
      "epoch:2 batch 470/2221) Loss:206.20443725585938\n",
      "epoch:2 batch 480/2221) Loss:105.09878540039062\n",
      "epoch:2 batch 490/2221) Loss:105.60400390625\n",
      "epoch:2 batch 500/2221) Loss:68.4374008178711\n",
      "epoch:2 batch 510/2221) Loss:78.98741912841797\n",
      "epoch:2 batch 520/2221) Loss:106.99922943115234\n",
      "epoch:2 batch 530/2221) Loss:59.75758361816406\n",
      "epoch:2 batch 540/2221) Loss:89.86375427246094\n",
      "epoch:2 batch 550/2221) Loss:90.31712341308594\n",
      "epoch:2 batch 560/2221) Loss:55.56438446044922\n",
      "epoch:2 batch 570/2221) Loss:132.96173095703125\n",
      "epoch:2 batch 580/2221) Loss:106.55419921875\n",
      "epoch:2 batch 590/2221) Loss:67.51769256591797\n",
      "epoch:2 batch 600/2221) Loss:97.75009155273438\n",
      "epoch:2 batch 610/2221) Loss:96.62937927246094\n",
      "epoch:2 batch 620/2221) Loss:65.12890625\n",
      "epoch:2 batch 630/2221) Loss:56.326263427734375\n",
      "epoch:2 batch 640/2221) Loss:150.7770233154297\n",
      "epoch:2 batch 650/2221) Loss:76.09496307373047\n",
      "epoch:2 batch 660/2221) Loss:95.18147277832031\n",
      "epoch:2 batch 670/2221) Loss:78.1117935180664\n",
      "epoch:2 batch 680/2221) Loss:56.42132568359375\n",
      "epoch:2 batch 690/2221) Loss:40.085548400878906\n",
      "epoch:2 batch 700/2221) Loss:62.50059509277344\n",
      "epoch:2 batch 710/2221) Loss:90.76040649414062\n",
      "epoch:2 batch 720/2221) Loss:110.90663146972656\n",
      "epoch:2 batch 730/2221) Loss:68.9073486328125\n",
      "epoch:2 batch 740/2221) Loss:96.31877136230469\n",
      "epoch:2 batch 750/2221) Loss:99.977294921875\n",
      "epoch:2 batch 760/2221) Loss:94.38011169433594\n",
      "epoch:2 batch 770/2221) Loss:90.43473052978516\n",
      "epoch:2 batch 780/2221) Loss:150.8577423095703\n",
      "epoch:2 batch 790/2221) Loss:105.5186767578125\n",
      "epoch:2 batch 800/2221) Loss:62.05291748046875\n",
      "epoch:2 batch 810/2221) Loss:83.66224670410156\n",
      "epoch:2 batch 820/2221) Loss:107.28623962402344\n",
      "epoch:2 batch 830/2221) Loss:65.53771209716797\n",
      "epoch:2 batch 840/2221) Loss:160.28445434570312\n",
      "epoch:2 batch 850/2221) Loss:121.30813598632812\n",
      "epoch:2 batch 860/2221) Loss:59.04095458984375\n",
      "epoch:2 batch 870/2221) Loss:69.62095642089844\n",
      "epoch:2 batch 880/2221) Loss:58.50556945800781\n",
      "epoch:2 batch 890/2221) Loss:107.67666625976562\n",
      "epoch:2 batch 900/2221) Loss:68.41707611083984\n",
      "epoch:2 batch 910/2221) Loss:94.46585083007812\n",
      "epoch:2 batch 920/2221) Loss:55.7467041015625\n",
      "epoch:2 batch 930/2221) Loss:105.39866638183594\n",
      "epoch:2 batch 940/2221) Loss:50.0576171875\n",
      "epoch:2 batch 950/2221) Loss:129.75384521484375\n",
      "epoch:2 batch 960/2221) Loss:76.12610626220703\n",
      "epoch:2 batch 970/2221) Loss:90.1722412109375\n",
      "epoch:2 batch 980/2221) Loss:66.75350952148438\n",
      "epoch:2 batch 990/2221) Loss:67.22552490234375\n",
      "epoch:2 batch 1000/2221) Loss:71.46725463867188\n",
      "epoch:2 batch 1010/2221) Loss:77.08363342285156\n",
      "epoch:2 batch 1020/2221) Loss:93.49103546142578\n",
      "epoch:2 batch 1030/2221) Loss:69.87036895751953\n",
      "epoch:2 batch 1040/2221) Loss:137.1034393310547\n",
      "epoch:2 batch 1050/2221) Loss:114.6900634765625\n",
      "epoch:2 batch 1060/2221) Loss:102.63539123535156\n",
      "epoch:2 batch 1070/2221) Loss:62.613616943359375\n",
      "epoch:2 batch 1080/2221) Loss:81.34905242919922\n",
      "epoch:2 batch 1090/2221) Loss:43.611961364746094\n",
      "epoch:2 batch 1100/2221) Loss:176.02206420898438\n",
      "epoch:2 batch 1110/2221) Loss:74.84259033203125\n",
      "epoch:2 batch 1120/2221) Loss:83.59014892578125\n",
      "epoch:2 batch 1130/2221) Loss:77.23506164550781\n",
      "epoch:2 batch 1140/2221) Loss:143.4208221435547\n",
      "epoch:2 batch 1150/2221) Loss:79.72181701660156\n",
      "epoch:2 batch 1160/2221) Loss:72.29176330566406\n",
      "epoch:2 batch 1170/2221) Loss:107.49723815917969\n",
      "epoch:2 batch 1180/2221) Loss:78.60707092285156\n",
      "epoch:2 batch 1190/2221) Loss:95.96762084960938\n",
      "epoch:2 batch 1200/2221) Loss:73.96614074707031\n",
      "epoch:2 batch 1210/2221) Loss:103.05277252197266\n",
      "epoch:2 batch 1220/2221) Loss:60.54466247558594\n",
      "epoch:2 batch 1230/2221) Loss:78.46070861816406\n",
      "epoch:2 batch 1240/2221) Loss:61.56605529785156\n",
      "epoch:2 batch 1250/2221) Loss:108.8113784790039\n",
      "epoch:2 batch 1260/2221) Loss:185.97332763671875\n",
      "epoch:2 batch 1270/2221) Loss:67.81854248046875\n",
      "epoch:2 batch 1280/2221) Loss:42.43528747558594\n",
      "epoch:2 batch 1290/2221) Loss:81.39067840576172\n",
      "epoch:2 batch 1300/2221) Loss:56.693878173828125\n",
      "epoch:2 batch 1310/2221) Loss:36.00798797607422\n",
      "epoch:2 batch 1320/2221) Loss:38.642913818359375\n",
      "epoch:2 batch 1330/2221) Loss:65.338134765625\n",
      "epoch:2 batch 1340/2221) Loss:104.20057678222656\n",
      "epoch:2 batch 1350/2221) Loss:55.625335693359375\n",
      "epoch:2 batch 1360/2221) Loss:123.82817077636719\n",
      "epoch:2 batch 1370/2221) Loss:86.76324462890625\n",
      "epoch:2 batch 1380/2221) Loss:77.20404052734375\n",
      "epoch:2 batch 1390/2221) Loss:51.89088439941406\n",
      "epoch:2 batch 1400/2221) Loss:46.337127685546875\n",
      "epoch:2 batch 1410/2221) Loss:62.044151306152344\n",
      "epoch:2 batch 1420/2221) Loss:105.85806274414062\n",
      "epoch:2 batch 1430/2221) Loss:118.58926391601562\n",
      "epoch:2 batch 1440/2221) Loss:47.35316467285156\n",
      "epoch:2 batch 1450/2221) Loss:70.60661315917969\n",
      "epoch:2 batch 1460/2221) Loss:62.54113006591797\n",
      "epoch:2 batch 1470/2221) Loss:73.20834350585938\n",
      "epoch:2 batch 1480/2221) Loss:79.61796569824219\n",
      "epoch:2 batch 1490/2221) Loss:90.57132720947266\n",
      "epoch:2 batch 1500/2221) Loss:130.50439453125\n",
      "epoch:2 batch 1510/2221) Loss:32.95611572265625\n",
      "epoch:2 batch 1520/2221) Loss:83.44914245605469\n",
      "epoch:2 batch 1530/2221) Loss:80.92543029785156\n",
      "epoch:2 batch 1540/2221) Loss:105.3226547241211\n",
      "epoch:2 batch 1550/2221) Loss:53.35968780517578\n",
      "epoch:2 batch 1560/2221) Loss:59.52604675292969\n",
      "epoch:2 batch 1570/2221) Loss:56.96630859375\n",
      "epoch:2 batch 1580/2221) Loss:87.06764221191406\n",
      "epoch:2 batch 1590/2221) Loss:42.51838684082031\n",
      "epoch:2 batch 1600/2221) Loss:70.38282775878906\n",
      "epoch:2 batch 1610/2221) Loss:123.21096801757812\n",
      "epoch:2 batch 1620/2221) Loss:143.271728515625\n",
      "epoch:2 batch 1630/2221) Loss:49.128578186035156\n",
      "epoch:2 batch 1640/2221) Loss:79.4652099609375\n",
      "epoch:2 batch 1650/2221) Loss:96.57810974121094\n",
      "epoch:2 batch 1660/2221) Loss:44.50849914550781\n",
      "epoch:2 batch 1670/2221) Loss:35.71275329589844\n",
      "epoch:2 batch 1680/2221) Loss:108.36189270019531\n",
      "epoch:2 batch 1690/2221) Loss:52.16407775878906\n",
      "epoch:2 batch 1700/2221) Loss:105.62071990966797\n",
      "epoch:2 batch 1710/2221) Loss:43.54345703125\n",
      "epoch:2 batch 1720/2221) Loss:154.97189331054688\n",
      "epoch:2 batch 1730/2221) Loss:64.03742980957031\n",
      "epoch:2 batch 1740/2221) Loss:72.39175415039062\n",
      "epoch:2 batch 1750/2221) Loss:59.00508117675781\n",
      "epoch:2 batch 1760/2221) Loss:121.49659729003906\n",
      "epoch:2 batch 1770/2221) Loss:48.166725158691406\n",
      "epoch:2 batch 1780/2221) Loss:48.32171630859375\n",
      "epoch:2 batch 1790/2221) Loss:48.741119384765625\n",
      "epoch:2 batch 1800/2221) Loss:82.11404418945312\n",
      "epoch:2 batch 1810/2221) Loss:130.74147033691406\n",
      "epoch:2 batch 1820/2221) Loss:66.90705108642578\n",
      "epoch:2 batch 1830/2221) Loss:53.212677001953125\n",
      "epoch:2 batch 1840/2221) Loss:52.04339599609375\n",
      "epoch:2 batch 1850/2221) Loss:70.02375793457031\n",
      "epoch:2 batch 1860/2221) Loss:73.09550476074219\n",
      "epoch:2 batch 1870/2221) Loss:247.55264282226562\n",
      "epoch:2 batch 1880/2221) Loss:83.06243896484375\n",
      "epoch:2 batch 1890/2221) Loss:111.2575912475586\n",
      "epoch:2 batch 1900/2221) Loss:112.63169860839844\n",
      "epoch:2 batch 1910/2221) Loss:47.309051513671875\n",
      "epoch:2 batch 1920/2221) Loss:58.416160583496094\n",
      "epoch:2 batch 1930/2221) Loss:97.14898681640625\n",
      "epoch:2 batch 1940/2221) Loss:84.70352172851562\n",
      "epoch:2 batch 1950/2221) Loss:98.74092102050781\n",
      "epoch:2 batch 1960/2221) Loss:57.64491271972656\n",
      "epoch:2 batch 1970/2221) Loss:71.1806640625\n",
      "epoch:2 batch 1980/2221) Loss:19.684486389160156\n",
      "epoch:2 batch 1990/2221) Loss:89.248046875\n",
      "epoch:2 batch 2000/2221) Loss:66.568359375\n",
      "epoch:2 batch 2010/2221) Loss:63.65925598144531\n",
      "epoch:2 batch 2020/2221) Loss:86.38710021972656\n",
      "epoch:2 batch 2030/2221) Loss:73.90348052978516\n",
      "epoch:2 batch 2040/2221) Loss:65.40109252929688\n",
      "epoch:2 batch 2050/2221) Loss:53.08851623535156\n",
      "epoch:2 batch 2060/2221) Loss:119.05613708496094\n",
      "epoch:2 batch 2070/2221) Loss:69.10650634765625\n",
      "epoch:2 batch 2080/2221) Loss:78.45018005371094\n",
      "epoch:2 batch 2090/2221) Loss:45.92329406738281\n",
      "epoch:2 batch 2100/2221) Loss:37.550209045410156\n",
      "epoch:2 batch 2110/2221) Loss:45.36054992675781\n",
      "epoch:2 batch 2120/2221) Loss:82.33065795898438\n",
      "epoch:2 batch 2130/2221) Loss:41.75498962402344\n",
      "epoch:2 batch 2140/2221) Loss:41.12281799316406\n",
      "epoch:2 batch 2150/2221) Loss:33.88856506347656\n",
      "epoch:2 batch 2160/2221) Loss:115.9809341430664\n",
      "epoch:2 batch 2170/2221) Loss:66.23439025878906\n",
      "epoch:2 batch 2180/2221) Loss:140.5747528076172\n",
      "epoch:2 batch 2190/2221) Loss:42.01829528808594\n",
      "epoch:2 batch 2200/2221) Loss:58.91520690917969\n",
      "epoch:2 batch 2210/2221) Loss:84.99554443359375\n",
      "epoch:2 batch 2220/2221) Loss:60.45326232910156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 precision:0.8284561803130355 recall:0.8271853016225373 f1-score:0.8270912148981423\n",
      "epoch:3 batch 1/2221) Loss:39.80754089355469\n",
      "epoch:3 batch 10/2221) Loss:65.91925048828125\n",
      "epoch:3 batch 20/2221) Loss:32.208770751953125\n",
      "epoch:3 batch 30/2221) Loss:44.97972106933594\n",
      "epoch:3 batch 40/2221) Loss:41.57355499267578\n",
      "epoch:3 batch 50/2221) Loss:68.93804168701172\n",
      "epoch:3 batch 60/2221) Loss:41.27845001220703\n",
      "epoch:3 batch 70/2221) Loss:91.4185562133789\n",
      "epoch:3 batch 80/2221) Loss:74.0404052734375\n",
      "epoch:3 batch 90/2221) Loss:77.93690490722656\n",
      "epoch:3 batch 100/2221) Loss:21.763397216796875\n",
      "epoch:3 batch 110/2221) Loss:56.86851501464844\n",
      "epoch:3 batch 120/2221) Loss:31.849945068359375\n",
      "epoch:3 batch 130/2221) Loss:37.12626647949219\n",
      "epoch:3 batch 140/2221) Loss:63.42279815673828\n",
      "epoch:3 batch 150/2221) Loss:57.38053894042969\n",
      "epoch:3 batch 160/2221) Loss:60.096954345703125\n",
      "epoch:3 batch 170/2221) Loss:110.36955261230469\n",
      "epoch:3 batch 180/2221) Loss:43.97471618652344\n",
      "epoch:3 batch 190/2221) Loss:66.01011657714844\n",
      "epoch:3 batch 200/2221) Loss:45.753074645996094\n",
      "epoch:3 batch 210/2221) Loss:93.46746826171875\n",
      "epoch:3 batch 220/2221) Loss:70.80964660644531\n",
      "epoch:3 batch 230/2221) Loss:64.42788696289062\n",
      "epoch:3 batch 240/2221) Loss:46.7283935546875\n",
      "epoch:3 batch 250/2221) Loss:53.53050231933594\n",
      "epoch:3 batch 260/2221) Loss:92.36518859863281\n",
      "epoch:3 batch 270/2221) Loss:73.68379211425781\n",
      "epoch:3 batch 280/2221) Loss:61.59144592285156\n",
      "epoch:3 batch 290/2221) Loss:97.7180404663086\n",
      "epoch:3 batch 300/2221) Loss:46.42601013183594\n",
      "epoch:3 batch 310/2221) Loss:48.34588623046875\n",
      "epoch:3 batch 320/2221) Loss:28.46881866455078\n",
      "epoch:3 batch 330/2221) Loss:61.996788024902344\n",
      "epoch:3 batch 340/2221) Loss:75.99561309814453\n",
      "epoch:3 batch 350/2221) Loss:56.16015625\n",
      "epoch:3 batch 360/2221) Loss:28.937042236328125\n",
      "epoch:3 batch 370/2221) Loss:131.27679443359375\n",
      "epoch:3 batch 380/2221) Loss:39.85444641113281\n",
      "epoch:3 batch 390/2221) Loss:84.48248291015625\n",
      "epoch:3 batch 400/2221) Loss:41.19941711425781\n",
      "epoch:3 batch 410/2221) Loss:39.38615417480469\n",
      "epoch:3 batch 420/2221) Loss:55.436798095703125\n",
      "epoch:3 batch 430/2221) Loss:54.3011474609375\n",
      "epoch:3 batch 440/2221) Loss:45.910789489746094\n",
      "epoch:3 batch 450/2221) Loss:41.49407958984375\n",
      "epoch:3 batch 460/2221) Loss:42.36750793457031\n",
      "epoch:3 batch 470/2221) Loss:56.043731689453125\n",
      "epoch:3 batch 480/2221) Loss:46.362525939941406\n",
      "epoch:3 batch 490/2221) Loss:112.93310546875\n",
      "epoch:3 batch 500/2221) Loss:54.10774230957031\n",
      "epoch:3 batch 510/2221) Loss:91.31629943847656\n",
      "epoch:3 batch 520/2221) Loss:31.552581787109375\n",
      "epoch:3 batch 530/2221) Loss:66.16588592529297\n",
      "epoch:3 batch 540/2221) Loss:38.061737060546875\n",
      "epoch:3 batch 550/2221) Loss:73.70531463623047\n",
      "epoch:3 batch 560/2221) Loss:73.97702026367188\n",
      "epoch:3 batch 570/2221) Loss:74.76667785644531\n",
      "epoch:3 batch 580/2221) Loss:64.28746795654297\n",
      "epoch:3 batch 590/2221) Loss:63.91938781738281\n",
      "epoch:3 batch 600/2221) Loss:42.2733154296875\n",
      "epoch:3 batch 610/2221) Loss:36.582489013671875\n",
      "epoch:3 batch 620/2221) Loss:67.54110717773438\n",
      "epoch:3 batch 630/2221) Loss:45.24896240234375\n",
      "epoch:3 batch 640/2221) Loss:103.81781768798828\n",
      "epoch:3 batch 650/2221) Loss:55.592918395996094\n",
      "epoch:3 batch 660/2221) Loss:40.3682861328125\n",
      "epoch:3 batch 670/2221) Loss:61.71875\n",
      "epoch:3 batch 680/2221) Loss:50.508270263671875\n",
      "epoch:3 batch 690/2221) Loss:42.7872314453125\n",
      "epoch:3 batch 700/2221) Loss:34.687225341796875\n",
      "epoch:3 batch 710/2221) Loss:37.34205627441406\n",
      "epoch:3 batch 720/2221) Loss:136.29959106445312\n",
      "epoch:3 batch 730/2221) Loss:58.31724548339844\n",
      "epoch:3 batch 740/2221) Loss:76.209716796875\n",
      "epoch:3 batch 750/2221) Loss:63.98985290527344\n",
      "epoch:3 batch 760/2221) Loss:34.675262451171875\n",
      "epoch:3 batch 770/2221) Loss:38.1505126953125\n",
      "epoch:3 batch 780/2221) Loss:46.8929443359375\n",
      "epoch:3 batch 790/2221) Loss:57.41526794433594\n",
      "epoch:3 batch 800/2221) Loss:50.160423278808594\n",
      "epoch:3 batch 810/2221) Loss:90.94483947753906\n",
      "epoch:3 batch 820/2221) Loss:65.01517486572266\n",
      "epoch:3 batch 830/2221) Loss:77.1415023803711\n",
      "epoch:3 batch 840/2221) Loss:75.80291748046875\n",
      "epoch:3 batch 850/2221) Loss:66.98790740966797\n",
      "epoch:3 batch 860/2221) Loss:44.9969482421875\n",
      "epoch:3 batch 870/2221) Loss:47.91014862060547\n",
      "epoch:3 batch 880/2221) Loss:71.5953369140625\n",
      "epoch:3 batch 890/2221) Loss:47.40917205810547\n",
      "epoch:3 batch 900/2221) Loss:76.00238037109375\n",
      "epoch:3 batch 910/2221) Loss:45.37828063964844\n",
      "epoch:3 batch 920/2221) Loss:72.05548095703125\n",
      "epoch:3 batch 930/2221) Loss:91.67617797851562\n",
      "epoch:3 batch 940/2221) Loss:28.86524200439453\n",
      "epoch:3 batch 950/2221) Loss:58.64591979980469\n",
      "epoch:3 batch 960/2221) Loss:67.64982604980469\n",
      "epoch:3 batch 970/2221) Loss:61.96977233886719\n",
      "epoch:3 batch 980/2221) Loss:51.51289367675781\n",
      "epoch:3 batch 990/2221) Loss:102.92231750488281\n",
      "epoch:3 batch 1000/2221) Loss:64.12289428710938\n",
      "epoch:3 batch 1010/2221) Loss:80.8350830078125\n",
      "epoch:3 batch 1020/2221) Loss:41.445159912109375\n",
      "epoch:3 batch 1030/2221) Loss:23.936309814453125\n",
      "epoch:3 batch 1040/2221) Loss:35.617156982421875\n",
      "epoch:3 batch 1050/2221) Loss:79.22879028320312\n",
      "epoch:3 batch 1060/2221) Loss:44.45082092285156\n",
      "epoch:3 batch 1070/2221) Loss:53.92206573486328\n",
      "epoch:3 batch 1080/2221) Loss:43.013038635253906\n",
      "epoch:3 batch 1090/2221) Loss:17.72649383544922\n",
      "epoch:3 batch 1100/2221) Loss:32.331024169921875\n",
      "epoch:3 batch 1110/2221) Loss:30.32788848876953\n",
      "epoch:3 batch 1120/2221) Loss:34.48876953125\n",
      "epoch:3 batch 1130/2221) Loss:40.357177734375\n",
      "epoch:3 batch 1140/2221) Loss:72.46882629394531\n",
      "epoch:3 batch 1150/2221) Loss:20.966415405273438\n",
      "epoch:3 batch 1160/2221) Loss:58.46160888671875\n",
      "epoch:3 batch 1170/2221) Loss:73.09120178222656\n",
      "epoch:3 batch 1180/2221) Loss:22.694427490234375\n",
      "epoch:3 batch 1190/2221) Loss:48.687522888183594\n",
      "epoch:3 batch 1200/2221) Loss:86.04234313964844\n",
      "epoch:3 batch 1210/2221) Loss:19.482681274414062\n",
      "epoch:3 batch 1220/2221) Loss:57.54070281982422\n",
      "epoch:3 batch 1230/2221) Loss:149.36700439453125\n",
      "epoch:3 batch 1240/2221) Loss:54.243919372558594\n",
      "epoch:3 batch 1250/2221) Loss:58.04583740234375\n",
      "epoch:3 batch 1260/2221) Loss:84.42069244384766\n",
      "epoch:3 batch 1270/2221) Loss:72.39379119873047\n",
      "epoch:3 batch 1280/2221) Loss:103.70671081542969\n",
      "epoch:3 batch 1290/2221) Loss:37.75700378417969\n",
      "epoch:3 batch 1300/2221) Loss:63.330589294433594\n",
      "epoch:3 batch 1310/2221) Loss:128.8424072265625\n",
      "epoch:3 batch 1320/2221) Loss:41.919158935546875\n",
      "epoch:3 batch 1330/2221) Loss:76.637939453125\n",
      "epoch:3 batch 1340/2221) Loss:38.85651397705078\n",
      "epoch:3 batch 1350/2221) Loss:51.1971435546875\n",
      "epoch:3 batch 1360/2221) Loss:74.79344177246094\n",
      "epoch:3 batch 1370/2221) Loss:26.45232391357422\n",
      "epoch:3 batch 1380/2221) Loss:54.37103271484375\n",
      "epoch:3 batch 1390/2221) Loss:28.802825927734375\n",
      "epoch:3 batch 1400/2221) Loss:14.587661743164062\n",
      "epoch:3 batch 1410/2221) Loss:66.5770263671875\n",
      "epoch:3 batch 1420/2221) Loss:49.790138244628906\n",
      "epoch:3 batch 1430/2221) Loss:21.752410888671875\n",
      "epoch:3 batch 1440/2221) Loss:112.72988891601562\n",
      "epoch:3 batch 1450/2221) Loss:18.488327026367188\n",
      "epoch:3 batch 1460/2221) Loss:42.702552795410156\n",
      "epoch:3 batch 1470/2221) Loss:80.27363586425781\n",
      "epoch:3 batch 1480/2221) Loss:102.26677703857422\n",
      "epoch:3 batch 1490/2221) Loss:78.4810791015625\n",
      "epoch:3 batch 1500/2221) Loss:46.738922119140625\n",
      "epoch:3 batch 1510/2221) Loss:33.80791473388672\n",
      "epoch:3 batch 1520/2221) Loss:92.55601501464844\n",
      "epoch:3 batch 1530/2221) Loss:33.09590148925781\n",
      "epoch:3 batch 1540/2221) Loss:36.70973205566406\n",
      "epoch:3 batch 1550/2221) Loss:39.994842529296875\n",
      "epoch:3 batch 1560/2221) Loss:57.78515625\n",
      "epoch:3 batch 1570/2221) Loss:62.495697021484375\n",
      "epoch:3 batch 1580/2221) Loss:40.445159912109375\n",
      "epoch:3 batch 1590/2221) Loss:61.29716491699219\n",
      "epoch:3 batch 1600/2221) Loss:64.40422058105469\n",
      "epoch:3 batch 1610/2221) Loss:113.19217681884766\n",
      "epoch:3 batch 1620/2221) Loss:24.7481689453125\n",
      "epoch:3 batch 1630/2221) Loss:69.89968872070312\n",
      "epoch:3 batch 1640/2221) Loss:70.0738296508789\n",
      "epoch:3 batch 1650/2221) Loss:81.11115264892578\n",
      "epoch:3 batch 1660/2221) Loss:58.39476776123047\n",
      "epoch:3 batch 1670/2221) Loss:46.33103942871094\n",
      "epoch:3 batch 1680/2221) Loss:44.395782470703125\n",
      "epoch:3 batch 1690/2221) Loss:34.29762268066406\n",
      "epoch:3 batch 1700/2221) Loss:60.10057830810547\n",
      "epoch:3 batch 1710/2221) Loss:65.02423858642578\n",
      "epoch:3 batch 1720/2221) Loss:45.99717712402344\n",
      "epoch:3 batch 1730/2221) Loss:56.223785400390625\n",
      "epoch:3 batch 1740/2221) Loss:45.84883117675781\n",
      "epoch:3 batch 1750/2221) Loss:25.754722595214844\n",
      "epoch:3 batch 1760/2221) Loss:43.054840087890625\n",
      "epoch:3 batch 1770/2221) Loss:81.51129913330078\n",
      "epoch:3 batch 1780/2221) Loss:73.9691162109375\n",
      "epoch:3 batch 1790/2221) Loss:28.712955474853516\n",
      "epoch:3 batch 1800/2221) Loss:93.64280700683594\n",
      "epoch:3 batch 1810/2221) Loss:33.2852783203125\n",
      "epoch:3 batch 1820/2221) Loss:38.310630798339844\n",
      "epoch:3 batch 1830/2221) Loss:114.65849304199219\n",
      "epoch:3 batch 1840/2221) Loss:82.24425506591797\n",
      "epoch:3 batch 1850/2221) Loss:51.83259582519531\n",
      "epoch:3 batch 1860/2221) Loss:45.16914367675781\n",
      "epoch:3 batch 1870/2221) Loss:77.18476867675781\n",
      "epoch:3 batch 1880/2221) Loss:65.91510772705078\n",
      "epoch:3 batch 1890/2221) Loss:47.16874694824219\n",
      "epoch:3 batch 1900/2221) Loss:30.47357177734375\n",
      "epoch:3 batch 1910/2221) Loss:39.652374267578125\n",
      "epoch:3 batch 1920/2221) Loss:40.98993682861328\n",
      "epoch:3 batch 1930/2221) Loss:86.7938003540039\n",
      "epoch:3 batch 1940/2221) Loss:73.74824523925781\n",
      "epoch:3 batch 1950/2221) Loss:75.99787902832031\n",
      "epoch:3 batch 1960/2221) Loss:55.92982482910156\n",
      "epoch:3 batch 1970/2221) Loss:70.14329528808594\n",
      "epoch:3 batch 1980/2221) Loss:37.571441650390625\n",
      "epoch:3 batch 1990/2221) Loss:91.20281982421875\n",
      "epoch:3 batch 2000/2221) Loss:48.25373077392578\n",
      "epoch:3 batch 2010/2221) Loss:84.31039428710938\n",
      "epoch:3 batch 2020/2221) Loss:26.388648986816406\n",
      "epoch:3 batch 2030/2221) Loss:26.92469024658203\n",
      "epoch:3 batch 2040/2221) Loss:65.72135925292969\n",
      "epoch:3 batch 2050/2221) Loss:59.145469665527344\n",
      "epoch:3 batch 2060/2221) Loss:78.96063995361328\n",
      "epoch:3 batch 2070/2221) Loss:40.40074157714844\n",
      "epoch:3 batch 2080/2221) Loss:52.195213317871094\n",
      "epoch:3 batch 2090/2221) Loss:37.083953857421875\n",
      "epoch:3 batch 2100/2221) Loss:82.84071350097656\n",
      "epoch:3 batch 2110/2221) Loss:106.9661636352539\n",
      "epoch:3 batch 2120/2221) Loss:48.636444091796875\n",
      "epoch:3 batch 2130/2221) Loss:32.60191345214844\n",
      "epoch:3 batch 2140/2221) Loss:36.21612548828125\n",
      "epoch:3 batch 2150/2221) Loss:39.66131591796875\n",
      "epoch:3 batch 2160/2221) Loss:42.3572998046875\n",
      "epoch:3 batch 2170/2221) Loss:36.71067810058594\n",
      "epoch:3 batch 2180/2221) Loss:65.2416763305664\n",
      "epoch:3 batch 2190/2221) Loss:30.25067138671875\n",
      "epoch:3 batch 2200/2221) Loss:48.90965270996094\n",
      "epoch:3 batch 2210/2221) Loss:24.5384521484375\n",
      "epoch:3 batch 2220/2221) Loss:29.750228881835938\n",
      "epoch:3 precision:0.990485414267703 recall:0.9523688912517206 f1-score:0.9699889728741843\n",
      "epoch:4 batch 1/2221) Loss:71.59420776367188\n",
      "epoch:4 batch 10/2221) Loss:38.26593780517578\n",
      "epoch:4 batch 20/2221) Loss:32.36711883544922\n",
      "epoch:4 batch 30/2221) Loss:31.798858642578125\n",
      "epoch:4 batch 40/2221) Loss:39.672264099121094\n",
      "epoch:4 batch 50/2221) Loss:64.88130187988281\n",
      "epoch:4 batch 60/2221) Loss:43.43473815917969\n",
      "epoch:4 batch 70/2221) Loss:52.85625457763672\n",
      "epoch:4 batch 80/2221) Loss:13.951828002929688\n",
      "epoch:4 batch 90/2221) Loss:30.23242950439453\n",
      "epoch:4 batch 100/2221) Loss:38.753868103027344\n",
      "epoch:4 batch 110/2221) Loss:39.623291015625\n",
      "epoch:4 batch 120/2221) Loss:57.071510314941406\n",
      "epoch:4 batch 130/2221) Loss:44.307411193847656\n",
      "epoch:4 batch 140/2221) Loss:39.14524841308594\n",
      "epoch:4 batch 150/2221) Loss:56.60657501220703\n",
      "epoch:4 batch 160/2221) Loss:18.37487030029297\n",
      "epoch:4 batch 170/2221) Loss:49.73539733886719\n",
      "epoch:4 batch 180/2221) Loss:67.3239517211914\n",
      "epoch:4 batch 190/2221) Loss:28.187515258789062\n",
      "epoch:4 batch 200/2221) Loss:11.482803344726562\n",
      "epoch:4 batch 210/2221) Loss:45.875946044921875\n",
      "epoch:4 batch 220/2221) Loss:61.150718688964844\n",
      "epoch:4 batch 230/2221) Loss:34.12004089355469\n",
      "epoch:4 batch 240/2221) Loss:19.240921020507812\n",
      "epoch:4 batch 250/2221) Loss:25.625869750976562\n",
      "epoch:4 batch 260/2221) Loss:36.746002197265625\n",
      "epoch:4 batch 270/2221) Loss:33.26902770996094\n",
      "epoch:4 batch 280/2221) Loss:42.387847900390625\n",
      "epoch:4 batch 290/2221) Loss:91.94134521484375\n",
      "epoch:4 batch 300/2221) Loss:48.472572326660156\n",
      "epoch:4 batch 310/2221) Loss:32.33445739746094\n",
      "epoch:4 batch 320/2221) Loss:19.786964416503906\n",
      "epoch:4 batch 330/2221) Loss:44.4169921875\n",
      "epoch:4 batch 340/2221) Loss:19.56653594970703\n",
      "epoch:4 batch 350/2221) Loss:24.2392578125\n",
      "epoch:4 batch 360/2221) Loss:28.94310760498047\n",
      "epoch:4 batch 370/2221) Loss:37.75273895263672\n",
      "epoch:4 batch 380/2221) Loss:61.41254425048828\n",
      "epoch:4 batch 390/2221) Loss:26.565521240234375\n",
      "epoch:4 batch 400/2221) Loss:50.65155792236328\n",
      "epoch:4 batch 410/2221) Loss:81.46470642089844\n",
      "epoch:4 batch 420/2221) Loss:37.91142272949219\n",
      "epoch:4 batch 430/2221) Loss:92.92888641357422\n",
      "epoch:4 batch 440/2221) Loss:28.52782440185547\n",
      "epoch:4 batch 450/2221) Loss:44.21406555175781\n",
      "epoch:4 batch 460/2221) Loss:30.147918701171875\n",
      "epoch:4 batch 470/2221) Loss:61.49437713623047\n",
      "epoch:4 batch 480/2221) Loss:58.231178283691406\n",
      "epoch:4 batch 490/2221) Loss:37.569114685058594\n",
      "epoch:4 batch 500/2221) Loss:99.67296600341797\n",
      "epoch:4 batch 510/2221) Loss:41.649017333984375\n",
      "epoch:4 batch 520/2221) Loss:23.82508087158203\n",
      "epoch:4 batch 530/2221) Loss:27.019821166992188\n",
      "epoch:4 batch 540/2221) Loss:44.013999938964844\n",
      "epoch:4 batch 550/2221) Loss:43.131980895996094\n",
      "epoch:4 batch 560/2221) Loss:30.794052124023438\n",
      "epoch:4 batch 570/2221) Loss:61.821754455566406\n",
      "epoch:4 batch 580/2221) Loss:60.61396789550781\n",
      "epoch:4 batch 590/2221) Loss:88.59886169433594\n",
      "epoch:4 batch 600/2221) Loss:22.625473022460938\n",
      "epoch:4 batch 610/2221) Loss:44.55461120605469\n",
      "epoch:4 batch 620/2221) Loss:29.226638793945312\n",
      "epoch:4 batch 630/2221) Loss:74.34365844726562\n",
      "epoch:4 batch 640/2221) Loss:58.21014404296875\n",
      "epoch:4 batch 650/2221) Loss:54.763275146484375\n",
      "epoch:4 batch 660/2221) Loss:72.0020980834961\n",
      "epoch:4 batch 670/2221) Loss:32.21283721923828\n",
      "epoch:4 batch 680/2221) Loss:47.228851318359375\n",
      "epoch:4 batch 690/2221) Loss:57.456756591796875\n",
      "epoch:4 batch 700/2221) Loss:31.89464569091797\n",
      "epoch:4 batch 710/2221) Loss:32.22990417480469\n",
      "epoch:4 batch 720/2221) Loss:51.260955810546875\n",
      "epoch:4 batch 730/2221) Loss:53.30682373046875\n",
      "epoch:4 batch 740/2221) Loss:46.970558166503906\n",
      "epoch:4 batch 750/2221) Loss:27.241844177246094\n",
      "epoch:4 batch 760/2221) Loss:29.106040954589844\n",
      "epoch:4 batch 770/2221) Loss:49.135589599609375\n",
      "epoch:4 batch 780/2221) Loss:26.344223022460938\n",
      "epoch:4 batch 790/2221) Loss:43.17548370361328\n",
      "epoch:4 batch 800/2221) Loss:32.18080139160156\n",
      "epoch:4 batch 810/2221) Loss:77.16620635986328\n",
      "epoch:4 batch 820/2221) Loss:16.079727172851562\n",
      "epoch:4 batch 830/2221) Loss:32.058921813964844\n",
      "epoch:4 batch 840/2221) Loss:39.765350341796875\n",
      "epoch:4 batch 850/2221) Loss:27.80760955810547\n",
      "epoch:4 batch 860/2221) Loss:27.323959350585938\n",
      "epoch:4 batch 870/2221) Loss:29.271385192871094\n",
      "epoch:4 batch 880/2221) Loss:34.05891418457031\n",
      "epoch:4 batch 890/2221) Loss:55.374420166015625\n",
      "epoch:4 batch 900/2221) Loss:51.533531188964844\n",
      "epoch:4 batch 910/2221) Loss:68.63773345947266\n",
      "epoch:4 batch 920/2221) Loss:32.33482360839844\n",
      "epoch:4 batch 930/2221) Loss:29.540390014648438\n",
      "epoch:4 batch 940/2221) Loss:29.065811157226562\n",
      "epoch:4 batch 950/2221) Loss:91.43358612060547\n",
      "epoch:4 batch 960/2221) Loss:12.195442199707031\n",
      "epoch:4 batch 970/2221) Loss:18.46550750732422\n",
      "epoch:4 batch 980/2221) Loss:35.267112731933594\n",
      "epoch:4 batch 990/2221) Loss:45.788177490234375\n",
      "epoch:4 batch 1000/2221) Loss:22.374542236328125\n",
      "epoch:4 batch 1010/2221) Loss:50.37122344970703\n",
      "epoch:4 batch 1020/2221) Loss:37.213348388671875\n",
      "epoch:4 batch 1030/2221) Loss:42.917076110839844\n",
      "epoch:4 batch 1040/2221) Loss:38.43873596191406\n",
      "epoch:4 batch 1050/2221) Loss:59.684356689453125\n",
      "epoch:4 batch 1060/2221) Loss:20.616928100585938\n",
      "epoch:4 batch 1070/2221) Loss:22.81256866455078\n",
      "epoch:4 batch 1080/2221) Loss:90.08364868164062\n",
      "epoch:4 batch 1090/2221) Loss:52.47669982910156\n",
      "epoch:4 batch 1100/2221) Loss:39.31578826904297\n",
      "epoch:4 batch 1110/2221) Loss:27.458961486816406\n",
      "epoch:4 batch 1120/2221) Loss:30.84490203857422\n",
      "epoch:4 batch 1130/2221) Loss:28.573532104492188\n",
      "epoch:4 batch 1140/2221) Loss:18.66100311279297\n",
      "epoch:4 batch 1150/2221) Loss:41.506797790527344\n",
      "epoch:4 batch 1160/2221) Loss:100.62281036376953\n",
      "epoch:4 batch 1170/2221) Loss:46.26097869873047\n",
      "epoch:4 batch 1180/2221) Loss:18.23975372314453\n",
      "epoch:4 batch 1190/2221) Loss:49.856117248535156\n",
      "epoch:4 batch 1200/2221) Loss:60.56489562988281\n",
      "epoch:4 batch 1210/2221) Loss:90.57007598876953\n",
      "epoch:4 batch 1220/2221) Loss:28.434158325195312\n",
      "epoch:4 batch 1230/2221) Loss:80.25065612792969\n",
      "epoch:4 batch 1240/2221) Loss:36.567176818847656\n",
      "epoch:4 batch 1250/2221) Loss:45.9405517578125\n",
      "epoch:4 batch 1260/2221) Loss:66.7378921508789\n",
      "epoch:4 batch 1270/2221) Loss:47.38127136230469\n",
      "epoch:4 batch 1280/2221) Loss:70.07449340820312\n",
      "epoch:4 batch 1290/2221) Loss:45.53126525878906\n",
      "epoch:4 batch 1300/2221) Loss:20.36145782470703\n",
      "epoch:4 batch 1310/2221) Loss:47.14087677001953\n",
      "epoch:4 batch 1320/2221) Loss:50.74446105957031\n",
      "epoch:4 batch 1330/2221) Loss:16.847579956054688\n",
      "epoch:4 batch 1340/2221) Loss:38.96026611328125\n",
      "epoch:4 batch 1350/2221) Loss:45.775611877441406\n",
      "epoch:4 batch 1360/2221) Loss:48.052589416503906\n",
      "epoch:4 batch 1370/2221) Loss:23.263473510742188\n",
      "epoch:4 batch 1380/2221) Loss:31.339317321777344\n",
      "epoch:4 batch 1390/2221) Loss:17.959556579589844\n",
      "epoch:4 batch 1400/2221) Loss:34.93226623535156\n",
      "epoch:4 batch 1410/2221) Loss:33.332298278808594\n",
      "epoch:4 batch 1420/2221) Loss:44.48412322998047\n",
      "epoch:4 batch 1430/2221) Loss:69.8626708984375\n",
      "epoch:4 batch 1440/2221) Loss:41.74211120605469\n",
      "epoch:4 batch 1450/2221) Loss:17.075355529785156\n",
      "epoch:4 batch 1460/2221) Loss:43.017173767089844\n",
      "epoch:4 batch 1470/2221) Loss:16.239349365234375\n",
      "epoch:4 batch 1480/2221) Loss:31.681747436523438\n",
      "epoch:4 batch 1490/2221) Loss:41.20923614501953\n",
      "epoch:4 batch 1500/2221) Loss:50.08349609375\n",
      "epoch:4 batch 1510/2221) Loss:20.849830627441406\n",
      "epoch:4 batch 1520/2221) Loss:27.83661651611328\n",
      "epoch:4 batch 1530/2221) Loss:32.675880432128906\n",
      "epoch:4 batch 1540/2221) Loss:29.573028564453125\n",
      "epoch:4 batch 1550/2221) Loss:51.1900634765625\n",
      "epoch:4 batch 1560/2221) Loss:56.83226776123047\n",
      "epoch:4 batch 1570/2221) Loss:52.19230651855469\n",
      "epoch:4 batch 1580/2221) Loss:42.81089782714844\n",
      "epoch:4 batch 1590/2221) Loss:51.662574768066406\n",
      "epoch:4 batch 1600/2221) Loss:67.32935333251953\n",
      "epoch:4 batch 1610/2221) Loss:50.5467529296875\n",
      "epoch:4 batch 1620/2221) Loss:22.573516845703125\n",
      "epoch:4 batch 1630/2221) Loss:49.433837890625\n",
      "epoch:4 batch 1640/2221) Loss:71.07747650146484\n",
      "epoch:4 batch 1650/2221) Loss:76.03732299804688\n",
      "epoch:4 batch 1660/2221) Loss:10.567092895507812\n",
      "epoch:4 batch 1670/2221) Loss:33.35144805908203\n",
      "epoch:4 batch 1680/2221) Loss:34.530364990234375\n",
      "epoch:4 batch 1690/2221) Loss:27.372520446777344\n",
      "epoch:4 batch 1700/2221) Loss:27.281997680664062\n",
      "epoch:4 batch 1710/2221) Loss:87.57096862792969\n",
      "epoch:4 batch 1720/2221) Loss:35.68492126464844\n",
      "epoch:4 batch 1730/2221) Loss:37.361839294433594\n",
      "epoch:4 batch 1740/2221) Loss:23.619041442871094\n",
      "epoch:4 batch 1750/2221) Loss:27.865219116210938\n",
      "epoch:4 batch 1760/2221) Loss:15.544784545898438\n",
      "epoch:4 batch 1770/2221) Loss:50.16759490966797\n",
      "epoch:4 batch 1780/2221) Loss:31.17437744140625\n",
      "epoch:4 batch 1790/2221) Loss:42.66804504394531\n",
      "epoch:4 batch 1800/2221) Loss:21.830528259277344\n",
      "epoch:4 batch 1810/2221) Loss:27.312713623046875\n",
      "epoch:4 batch 1820/2221) Loss:27.326095581054688\n",
      "epoch:4 batch 1830/2221) Loss:21.00347900390625\n",
      "epoch:4 batch 1840/2221) Loss:29.608016967773438\n",
      "epoch:4 batch 1850/2221) Loss:33.599464416503906\n",
      "epoch:4 batch 1860/2221) Loss:71.05687713623047\n",
      "epoch:4 batch 1870/2221) Loss:25.340614318847656\n",
      "epoch:4 batch 1880/2221) Loss:23.026145935058594\n",
      "epoch:4 batch 1890/2221) Loss:22.594833374023438\n",
      "epoch:4 batch 1900/2221) Loss:25.385154724121094\n",
      "epoch:4 batch 1910/2221) Loss:32.91230773925781\n",
      "epoch:4 batch 1920/2221) Loss:53.89270782470703\n",
      "epoch:4 batch 1930/2221) Loss:22.598976135253906\n",
      "epoch:4 batch 1940/2221) Loss:38.61492156982422\n",
      "epoch:4 batch 1950/2221) Loss:62.291046142578125\n",
      "epoch:4 batch 1960/2221) Loss:47.39439010620117\n",
      "epoch:4 batch 1970/2221) Loss:46.52928161621094\n",
      "epoch:4 batch 1980/2221) Loss:123.47207641601562\n",
      "epoch:4 batch 1990/2221) Loss:42.78849792480469\n",
      "epoch:4 batch 2000/2221) Loss:9.388191223144531\n",
      "epoch:4 batch 2010/2221) Loss:40.76177978515625\n",
      "epoch:4 batch 2020/2221) Loss:36.79026794433594\n",
      "epoch:4 batch 2030/2221) Loss:45.73052978515625\n",
      "epoch:4 batch 2040/2221) Loss:18.75389862060547\n",
      "epoch:4 batch 2050/2221) Loss:19.72711181640625\n",
      "epoch:4 batch 2060/2221) Loss:30.943328857421875\n",
      "epoch:4 batch 2070/2221) Loss:27.51715087890625\n",
      "epoch:4 batch 2080/2221) Loss:61.51079177856445\n",
      "epoch:4 batch 2090/2221) Loss:42.06534957885742\n",
      "epoch:4 batch 2100/2221) Loss:35.73057556152344\n",
      "epoch:4 batch 2110/2221) Loss:52.926666259765625\n",
      "epoch:4 batch 2120/2221) Loss:50.48450469970703\n",
      "epoch:4 batch 2130/2221) Loss:16.90540313720703\n",
      "epoch:4 batch 2140/2221) Loss:54.91596984863281\n",
      "epoch:4 batch 2150/2221) Loss:17.349403381347656\n",
      "epoch:4 batch 2160/2221) Loss:24.47327423095703\n",
      "epoch:4 batch 2170/2221) Loss:47.621856689453125\n",
      "epoch:4 batch 2180/2221) Loss:36.00560760498047\n",
      "epoch:4 batch 2190/2221) Loss:25.0174560546875\n",
      "epoch:4 batch 2200/2221) Loss:30.42615509033203\n",
      "epoch:4 batch 2210/2221) Loss:47.561973571777344\n",
      "epoch:4 batch 2220/2221) Loss:43.842918395996094\n",
      "epoch:4 precision:0.9947817435866754 recall:0.9705654545362555 f1-score:0.9819791927655178\n",
      "epoch:5 batch 1/2221) Loss:31.92852783203125\n",
      "epoch:5 batch 10/2221) Loss:32.258888244628906\n",
      "epoch:5 batch 20/2221) Loss:40.25360107421875\n",
      "epoch:5 batch 30/2221) Loss:33.57813262939453\n",
      "epoch:5 batch 40/2221) Loss:32.51921844482422\n",
      "epoch:5 batch 50/2221) Loss:35.867523193359375\n",
      "epoch:5 batch 60/2221) Loss:45.56245422363281\n",
      "epoch:5 batch 70/2221) Loss:72.4875717163086\n",
      "epoch:5 batch 80/2221) Loss:54.455909729003906\n",
      "epoch:5 batch 90/2221) Loss:19.223709106445312\n",
      "epoch:5 batch 100/2221) Loss:20.202850341796875\n",
      "epoch:5 batch 110/2221) Loss:25.335556030273438\n",
      "epoch:5 batch 120/2221) Loss:27.166107177734375\n",
      "epoch:5 batch 130/2221) Loss:38.663909912109375\n",
      "epoch:5 batch 140/2221) Loss:33.974754333496094\n",
      "epoch:5 batch 150/2221) Loss:21.82697296142578\n",
      "epoch:5 batch 160/2221) Loss:43.70185089111328\n",
      "epoch:5 batch 170/2221) Loss:19.74164581298828\n",
      "epoch:5 batch 180/2221) Loss:33.04505920410156\n",
      "epoch:5 batch 190/2221) Loss:42.878440856933594\n",
      "epoch:5 batch 200/2221) Loss:42.050933837890625\n",
      "epoch:5 batch 210/2221) Loss:66.29149627685547\n",
      "epoch:5 batch 220/2221) Loss:65.47557830810547\n",
      "epoch:5 batch 230/2221) Loss:78.2995376586914\n",
      "epoch:5 batch 240/2221) Loss:13.954483032226562\n",
      "epoch:5 batch 250/2221) Loss:34.255615234375\n",
      "epoch:5 batch 260/2221) Loss:55.24169921875\n",
      "epoch:5 batch 270/2221) Loss:24.9427490234375\n",
      "epoch:5 batch 280/2221) Loss:26.234817504882812\n",
      "epoch:5 batch 290/2221) Loss:18.371551513671875\n",
      "epoch:5 batch 300/2221) Loss:25.173599243164062\n",
      "epoch:5 batch 310/2221) Loss:26.278976440429688\n",
      "epoch:5 batch 320/2221) Loss:18.830398559570312\n",
      "epoch:5 batch 330/2221) Loss:91.4087142944336\n",
      "epoch:5 batch 340/2221) Loss:34.67997741699219\n",
      "epoch:5 batch 350/2221) Loss:37.82451629638672\n",
      "epoch:5 batch 360/2221) Loss:22.59552001953125\n",
      "epoch:5 batch 370/2221) Loss:57.258522033691406\n",
      "epoch:5 batch 380/2221) Loss:19.501617431640625\n",
      "epoch:5 batch 390/2221) Loss:38.898193359375\n",
      "epoch:5 batch 400/2221) Loss:31.210205078125\n",
      "epoch:5 batch 410/2221) Loss:34.33699035644531\n",
      "epoch:5 batch 420/2221) Loss:84.74385070800781\n",
      "epoch:5 batch 430/2221) Loss:48.697296142578125\n",
      "epoch:5 batch 440/2221) Loss:15.578697204589844\n",
      "epoch:5 batch 450/2221) Loss:35.946510314941406\n",
      "epoch:5 batch 460/2221) Loss:13.786651611328125\n",
      "epoch:5 batch 470/2221) Loss:29.76141357421875\n",
      "epoch:5 batch 480/2221) Loss:42.88317108154297\n",
      "epoch:5 batch 490/2221) Loss:63.624420166015625\n",
      "epoch:5 batch 500/2221) Loss:36.2525634765625\n",
      "epoch:5 batch 510/2221) Loss:12.660331726074219\n",
      "epoch:5 batch 520/2221) Loss:15.590866088867188\n",
      "epoch:5 batch 530/2221) Loss:59.216941833496094\n",
      "epoch:5 batch 540/2221) Loss:75.18590545654297\n",
      "epoch:5 batch 550/2221) Loss:45.923858642578125\n",
      "epoch:5 batch 560/2221) Loss:107.40939331054688\n",
      "epoch:5 batch 570/2221) Loss:44.54307556152344\n",
      "epoch:5 batch 580/2221) Loss:15.041969299316406\n",
      "epoch:5 batch 590/2221) Loss:31.00914764404297\n",
      "epoch:5 batch 600/2221) Loss:35.68304443359375\n",
      "epoch:5 batch 610/2221) Loss:33.53620147705078\n",
      "epoch:5 batch 620/2221) Loss:36.65479278564453\n",
      "epoch:5 batch 630/2221) Loss:15.271903991699219\n",
      "epoch:5 batch 640/2221) Loss:29.05834197998047\n",
      "epoch:5 batch 650/2221) Loss:27.08587646484375\n",
      "epoch:5 batch 660/2221) Loss:40.59288024902344\n",
      "epoch:5 batch 670/2221) Loss:58.9176025390625\n",
      "epoch:5 batch 680/2221) Loss:34.699012756347656\n",
      "epoch:5 batch 690/2221) Loss:14.888824462890625\n",
      "epoch:5 batch 700/2221) Loss:7.8369293212890625\n",
      "epoch:5 batch 710/2221) Loss:38.03846740722656\n",
      "epoch:5 batch 720/2221) Loss:12.532638549804688\n",
      "epoch:5 batch 730/2221) Loss:74.09297180175781\n",
      "epoch:5 batch 740/2221) Loss:101.50972747802734\n",
      "epoch:5 batch 750/2221) Loss:71.25167846679688\n",
      "epoch:5 batch 760/2221) Loss:27.89830780029297\n",
      "epoch:5 batch 770/2221) Loss:36.135948181152344\n",
      "epoch:5 batch 780/2221) Loss:27.349380493164062\n",
      "epoch:5 batch 790/2221) Loss:26.475326538085938\n",
      "epoch:5 batch 800/2221) Loss:19.23375701904297\n",
      "epoch:5 batch 810/2221) Loss:59.90216827392578\n",
      "epoch:5 batch 820/2221) Loss:25.368614196777344\n",
      "epoch:5 batch 830/2221) Loss:43.90614318847656\n",
      "epoch:5 batch 840/2221) Loss:31.751907348632812\n",
      "epoch:5 batch 850/2221) Loss:26.578155517578125\n",
      "epoch:5 batch 860/2221) Loss:17.916748046875\n",
      "epoch:5 batch 870/2221) Loss:14.494033813476562\n",
      "epoch:5 batch 880/2221) Loss:18.371475219726562\n",
      "epoch:5 batch 890/2221) Loss:36.43025207519531\n",
      "epoch:5 batch 900/2221) Loss:42.10533905029297\n",
      "epoch:5 batch 910/2221) Loss:27.924522399902344\n",
      "epoch:5 batch 920/2221) Loss:20.304847717285156\n",
      "epoch:5 batch 930/2221) Loss:29.495452880859375\n",
      "epoch:5 batch 940/2221) Loss:58.188446044921875\n",
      "epoch:5 batch 950/2221) Loss:19.492332458496094\n",
      "epoch:5 batch 960/2221) Loss:60.62864685058594\n",
      "epoch:5 batch 970/2221) Loss:26.286453247070312\n",
      "epoch:5 batch 980/2221) Loss:26.700973510742188\n",
      "epoch:5 batch 990/2221) Loss:10.9271240234375\n",
      "epoch:5 batch 1000/2221) Loss:59.244903564453125\n",
      "epoch:5 batch 1010/2221) Loss:24.463844299316406\n",
      "epoch:5 batch 1020/2221) Loss:112.0636215209961\n",
      "epoch:5 batch 1030/2221) Loss:29.581512451171875\n",
      "epoch:5 batch 1040/2221) Loss:122.48357391357422\n",
      "epoch:5 batch 1050/2221) Loss:41.458099365234375\n",
      "epoch:5 batch 1060/2221) Loss:42.485313415527344\n",
      "epoch:5 batch 1070/2221) Loss:28.37541961669922\n",
      "epoch:5 batch 1080/2221) Loss:35.75395202636719\n",
      "epoch:5 batch 1090/2221) Loss:34.591148376464844\n",
      "epoch:5 batch 1100/2221) Loss:28.935531616210938\n",
      "epoch:5 batch 1110/2221) Loss:29.678855895996094\n",
      "epoch:5 batch 1120/2221) Loss:38.01466369628906\n",
      "epoch:5 batch 1130/2221) Loss:48.497840881347656\n",
      "epoch:5 batch 1140/2221) Loss:19.071914672851562\n",
      "epoch:5 batch 1150/2221) Loss:49.592681884765625\n",
      "epoch:5 batch 1160/2221) Loss:44.81395721435547\n",
      "epoch:5 batch 1170/2221) Loss:25.733444213867188\n",
      "epoch:5 batch 1180/2221) Loss:27.210426330566406\n",
      "epoch:5 batch 1190/2221) Loss:36.160247802734375\n",
      "epoch:5 batch 1200/2221) Loss:14.684944152832031\n",
      "epoch:5 batch 1210/2221) Loss:23.794044494628906\n",
      "epoch:5 batch 1220/2221) Loss:42.179443359375\n",
      "epoch:5 batch 1230/2221) Loss:21.551231384277344\n",
      "epoch:5 batch 1240/2221) Loss:36.92657470703125\n",
      "epoch:5 batch 1250/2221) Loss:34.108375549316406\n",
      "epoch:5 batch 1260/2221) Loss:33.12378692626953\n",
      "epoch:5 batch 1270/2221) Loss:19.499404907226562\n",
      "epoch:5 batch 1280/2221) Loss:38.171348571777344\n",
      "epoch:5 batch 1290/2221) Loss:70.54107666015625\n",
      "epoch:5 batch 1300/2221) Loss:58.365394592285156\n",
      "epoch:5 batch 1310/2221) Loss:15.19366455078125\n",
      "epoch:5 batch 1320/2221) Loss:52.89691925048828\n",
      "epoch:5 batch 1330/2221) Loss:29.19378662109375\n",
      "epoch:5 batch 1340/2221) Loss:73.59867095947266\n",
      "epoch:5 batch 1350/2221) Loss:27.922279357910156\n",
      "epoch:5 batch 1360/2221) Loss:17.188095092773438\n",
      "epoch:5 batch 1370/2221) Loss:35.607505798339844\n",
      "epoch:5 batch 1380/2221) Loss:53.08557891845703\n",
      "epoch:5 batch 1390/2221) Loss:20.039871215820312\n",
      "epoch:5 batch 1400/2221) Loss:45.4298095703125\n",
      "epoch:5 batch 1410/2221) Loss:12.125137329101562\n",
      "epoch:5 batch 1420/2221) Loss:10.549346923828125\n",
      "epoch:5 batch 1430/2221) Loss:28.84162139892578\n",
      "epoch:5 batch 1440/2221) Loss:29.265968322753906\n",
      "epoch:5 batch 1450/2221) Loss:23.308135986328125\n",
      "epoch:5 batch 1460/2221) Loss:26.62169647216797\n",
      "epoch:5 batch 1470/2221) Loss:64.17098999023438\n",
      "epoch:5 batch 1480/2221) Loss:24.102699279785156\n",
      "epoch:5 batch 1490/2221) Loss:35.39435577392578\n",
      "epoch:5 batch 1500/2221) Loss:28.743614196777344\n",
      "epoch:5 batch 1510/2221) Loss:68.82223510742188\n",
      "epoch:5 batch 1520/2221) Loss:59.92778015136719\n",
      "epoch:5 batch 1530/2221) Loss:41.08219909667969\n",
      "epoch:5 batch 1540/2221) Loss:18.362152099609375\n",
      "epoch:5 batch 1550/2221) Loss:20.234413146972656\n",
      "epoch:5 batch 1560/2221) Loss:24.50031280517578\n",
      "epoch:5 batch 1570/2221) Loss:13.748611450195312\n",
      "epoch:5 batch 1580/2221) Loss:21.769493103027344\n",
      "epoch:5 batch 1590/2221) Loss:41.88356018066406\n",
      "epoch:5 batch 1600/2221) Loss:21.486007690429688\n",
      "epoch:5 batch 1610/2221) Loss:10.684478759765625\n",
      "epoch:5 batch 1620/2221) Loss:14.109123229980469\n",
      "epoch:5 batch 1630/2221) Loss:33.57488250732422\n",
      "epoch:5 batch 1640/2221) Loss:27.957374572753906\n",
      "epoch:5 batch 1650/2221) Loss:47.483917236328125\n",
      "epoch:5 batch 1660/2221) Loss:26.878189086914062\n",
      "epoch:5 batch 1670/2221) Loss:32.123939514160156\n",
      "epoch:5 batch 1680/2221) Loss:26.270904541015625\n",
      "epoch:5 batch 1690/2221) Loss:28.668807983398438\n",
      "epoch:5 batch 1700/2221) Loss:33.773109436035156\n",
      "epoch:5 batch 1710/2221) Loss:59.19054412841797\n",
      "epoch:5 batch 1720/2221) Loss:10.501045227050781\n",
      "epoch:5 batch 1730/2221) Loss:99.20709991455078\n",
      "epoch:5 batch 1740/2221) Loss:14.822090148925781\n",
      "epoch:5 batch 1750/2221) Loss:28.04442596435547\n",
      "epoch:5 batch 1760/2221) Loss:37.89824676513672\n",
      "epoch:5 batch 1770/2221) Loss:53.531593322753906\n",
      "epoch:5 batch 1780/2221) Loss:28.079360961914062\n",
      "epoch:5 batch 1790/2221) Loss:15.51443862915039\n",
      "epoch:5 batch 1800/2221) Loss:21.87567138671875\n",
      "epoch:5 batch 1810/2221) Loss:20.691139221191406\n",
      "epoch:5 batch 1820/2221) Loss:33.980926513671875\n",
      "epoch:5 batch 1830/2221) Loss:50.951698303222656\n",
      "epoch:5 batch 1840/2221) Loss:17.064777374267578\n",
      "epoch:5 batch 1850/2221) Loss:26.436431884765625\n",
      "epoch:5 batch 1860/2221) Loss:19.844390869140625\n",
      "epoch:5 batch 1870/2221) Loss:9.410797119140625\n",
      "epoch:5 batch 1880/2221) Loss:48.73180389404297\n",
      "epoch:5 batch 1890/2221) Loss:67.45580291748047\n",
      "epoch:5 batch 1900/2221) Loss:25.95032501220703\n",
      "epoch:5 batch 1910/2221) Loss:14.626739501953125\n",
      "epoch:5 batch 1920/2221) Loss:59.690330505371094\n",
      "epoch:5 batch 1930/2221) Loss:37.03856658935547\n",
      "epoch:5 batch 1940/2221) Loss:32.089820861816406\n",
      "epoch:5 batch 1950/2221) Loss:45.83538818359375\n",
      "epoch:5 batch 1960/2221) Loss:19.805099487304688\n",
      "epoch:5 batch 1970/2221) Loss:21.570297241210938\n",
      "epoch:5 batch 1980/2221) Loss:20.875625610351562\n",
      "epoch:5 batch 1990/2221) Loss:13.666069030761719\n",
      "epoch:5 batch 2000/2221) Loss:40.0688362121582\n",
      "epoch:5 batch 2010/2221) Loss:23.207901000976562\n",
      "epoch:5 batch 2020/2221) Loss:18.392684936523438\n",
      "epoch:5 batch 2030/2221) Loss:4.7541656494140625\n",
      "epoch:5 batch 2040/2221) Loss:34.08009338378906\n",
      "epoch:5 batch 2050/2221) Loss:27.127548217773438\n",
      "epoch:5 batch 2060/2221) Loss:43.670448303222656\n",
      "epoch:5 batch 2070/2221) Loss:55.327964782714844\n",
      "epoch:5 batch 2080/2221) Loss:34.4749755859375\n",
      "epoch:5 batch 2090/2221) Loss:37.457191467285156\n",
      "epoch:5 batch 2100/2221) Loss:45.30663299560547\n",
      "epoch:5 batch 2110/2221) Loss:53.90592956542969\n",
      "epoch:5 batch 2120/2221) Loss:39.664703369140625\n",
      "epoch:5 batch 2130/2221) Loss:27.249107360839844\n",
      "epoch:5 batch 2140/2221) Loss:10.501197814941406\n",
      "epoch:5 batch 2150/2221) Loss:24.328033447265625\n",
      "epoch:5 batch 2160/2221) Loss:32.97040557861328\n",
      "epoch:5 batch 2170/2221) Loss:19.2530517578125\n",
      "epoch:5 batch 2180/2221) Loss:52.09999084472656\n",
      "epoch:5 batch 2190/2221) Loss:39.74482727050781\n",
      "epoch:5 batch 2200/2221) Loss:40.84059524536133\n",
      "epoch:5 batch 2210/2221) Loss:26.228317260742188\n",
      "epoch:5 batch 2220/2221) Loss:18.946304321289062\n",
      "epoch:5 precision:0.9960626883098193 recall:0.9739077795041925 f1-score:0.9843760720200772\n",
      "epoch:6 batch 1/2221) Loss:30.84111785888672\n",
      "epoch:6 batch 10/2221) Loss:13.542312622070312\n",
      "epoch:6 batch 20/2221) Loss:10.072235107421875\n",
      "epoch:6 batch 30/2221) Loss:41.20207977294922\n",
      "epoch:6 batch 40/2221) Loss:33.3868408203125\n",
      "epoch:6 batch 50/2221) Loss:22.110252380371094\n",
      "epoch:6 batch 60/2221) Loss:53.501495361328125\n",
      "epoch:6 batch 70/2221) Loss:42.303672790527344\n",
      "epoch:6 batch 80/2221) Loss:14.920265197753906\n",
      "epoch:6 batch 90/2221) Loss:185.98629760742188\n",
      "epoch:6 batch 100/2221) Loss:46.32920837402344\n",
      "epoch:6 batch 110/2221) Loss:34.973670959472656\n",
      "epoch:6 batch 120/2221) Loss:45.464744567871094\n",
      "epoch:6 batch 130/2221) Loss:33.84722137451172\n",
      "epoch:6 batch 140/2221) Loss:36.51544952392578\n",
      "epoch:6 batch 150/2221) Loss:22.04498291015625\n",
      "epoch:6 batch 160/2221) Loss:32.97589874267578\n",
      "epoch:6 batch 170/2221) Loss:24.21625518798828\n",
      "epoch:6 batch 180/2221) Loss:49.604888916015625\n",
      "epoch:6 batch 190/2221) Loss:6.4382781982421875\n",
      "epoch:6 batch 200/2221) Loss:16.712535858154297\n",
      "epoch:6 batch 210/2221) Loss:49.27855682373047\n",
      "epoch:6 batch 220/2221) Loss:17.626876831054688\n",
      "epoch:6 batch 230/2221) Loss:7.878135681152344\n",
      "epoch:6 batch 240/2221) Loss:19.691139221191406\n",
      "epoch:6 batch 250/2221) Loss:17.141212463378906\n",
      "epoch:6 batch 260/2221) Loss:17.82634735107422\n",
      "epoch:6 batch 270/2221) Loss:48.002960205078125\n",
      "epoch:6 batch 280/2221) Loss:56.072967529296875\n",
      "epoch:6 batch 290/2221) Loss:69.7063980102539\n",
      "epoch:6 batch 300/2221) Loss:78.24497985839844\n",
      "epoch:6 batch 310/2221) Loss:44.3408203125\n",
      "epoch:6 batch 320/2221) Loss:24.622215270996094\n",
      "epoch:6 batch 330/2221) Loss:32.00102233886719\n",
      "epoch:6 batch 340/2221) Loss:18.947898864746094\n",
      "epoch:6 batch 350/2221) Loss:22.561965942382812\n",
      "epoch:6 batch 360/2221) Loss:29.00677490234375\n",
      "epoch:6 batch 370/2221) Loss:26.437828063964844\n",
      "epoch:6 batch 380/2221) Loss:35.246116638183594\n",
      "epoch:6 batch 390/2221) Loss:71.76786041259766\n",
      "epoch:6 batch 400/2221) Loss:28.658706665039062\n",
      "epoch:6 batch 410/2221) Loss:19.875686645507812\n",
      "epoch:6 batch 420/2221) Loss:13.34100341796875\n",
      "epoch:6 batch 430/2221) Loss:60.28063201904297\n",
      "epoch:6 batch 440/2221) Loss:54.51258087158203\n",
      "epoch:6 batch 450/2221) Loss:18.24201202392578\n",
      "epoch:6 batch 460/2221) Loss:15.510124206542969\n",
      "epoch:6 batch 470/2221) Loss:33.511383056640625\n",
      "epoch:6 batch 480/2221) Loss:7.172721862792969\n",
      "epoch:6 batch 490/2221) Loss:37.386436462402344\n",
      "epoch:6 batch 500/2221) Loss:41.339500427246094\n",
      "epoch:6 batch 510/2221) Loss:27.91405487060547\n",
      "epoch:6 batch 520/2221) Loss:46.283660888671875\n",
      "epoch:6 batch 530/2221) Loss:50.872474670410156\n",
      "epoch:6 batch 540/2221) Loss:17.945236206054688\n",
      "epoch:6 batch 550/2221) Loss:32.753265380859375\n",
      "epoch:6 batch 560/2221) Loss:11.425621032714844\n",
      "epoch:6 batch 570/2221) Loss:29.095306396484375\n",
      "epoch:6 batch 580/2221) Loss:33.321861267089844\n",
      "epoch:6 batch 590/2221) Loss:36.211700439453125\n",
      "epoch:6 batch 600/2221) Loss:38.013221740722656\n",
      "epoch:6 batch 610/2221) Loss:53.679176330566406\n",
      "epoch:6 batch 620/2221) Loss:34.57643127441406\n",
      "epoch:6 batch 630/2221) Loss:17.89013671875\n",
      "epoch:6 batch 640/2221) Loss:9.355918884277344\n",
      "epoch:6 batch 650/2221) Loss:16.65196990966797\n",
      "epoch:6 batch 660/2221) Loss:19.181411743164062\n",
      "epoch:6 batch 670/2221) Loss:12.625106811523438\n",
      "epoch:6 batch 680/2221) Loss:22.417282104492188\n",
      "epoch:6 batch 690/2221) Loss:74.88565063476562\n",
      "epoch:6 batch 700/2221) Loss:51.04136657714844\n",
      "epoch:6 batch 710/2221) Loss:119.69568634033203\n",
      "epoch:6 batch 720/2221) Loss:37.62946319580078\n",
      "epoch:6 batch 730/2221) Loss:41.912841796875\n",
      "epoch:6 batch 740/2221) Loss:33.88849639892578\n",
      "epoch:6 batch 750/2221) Loss:30.72650909423828\n",
      "epoch:6 batch 760/2221) Loss:11.930953979492188\n",
      "epoch:6 batch 770/2221) Loss:12.955970764160156\n",
      "epoch:6 batch 780/2221) Loss:9.315685272216797\n",
      "epoch:6 batch 790/2221) Loss:16.626052856445312\n",
      "epoch:6 batch 800/2221) Loss:26.13402557373047\n",
      "epoch:6 batch 810/2221) Loss:25.1712646484375\n",
      "epoch:6 batch 820/2221) Loss:37.36216735839844\n",
      "epoch:6 batch 830/2221) Loss:13.46356201171875\n",
      "epoch:6 batch 840/2221) Loss:21.790573120117188\n",
      "epoch:6 batch 850/2221) Loss:32.42059326171875\n",
      "epoch:6 batch 860/2221) Loss:39.59304428100586\n",
      "epoch:6 batch 870/2221) Loss:18.88373565673828\n",
      "epoch:6 batch 880/2221) Loss:19.84050750732422\n",
      "epoch:6 batch 890/2221) Loss:32.53160095214844\n",
      "epoch:6 batch 900/2221) Loss:26.211044311523438\n",
      "epoch:6 batch 910/2221) Loss:9.856399536132812\n",
      "epoch:6 batch 920/2221) Loss:23.305221557617188\n",
      "epoch:6 batch 930/2221) Loss:31.143016815185547\n",
      "epoch:6 batch 940/2221) Loss:36.957481384277344\n",
      "epoch:6 batch 950/2221) Loss:21.110000610351562\n",
      "epoch:6 batch 960/2221) Loss:39.40740966796875\n",
      "epoch:6 batch 970/2221) Loss:31.36919403076172\n",
      "epoch:6 batch 980/2221) Loss:40.80726623535156\n",
      "epoch:6 batch 990/2221) Loss:43.619850158691406\n",
      "epoch:6 batch 1000/2221) Loss:42.003700256347656\n",
      "epoch:6 batch 1010/2221) Loss:20.0196533203125\n",
      "epoch:6 batch 1020/2221) Loss:43.12303161621094\n",
      "epoch:6 batch 1030/2221) Loss:20.22954559326172\n",
      "epoch:6 batch 1040/2221) Loss:55.805381774902344\n",
      "epoch:6 batch 1050/2221) Loss:26.213768005371094\n",
      "epoch:6 batch 1060/2221) Loss:11.529266357421875\n",
      "epoch:6 batch 1070/2221) Loss:28.2115478515625\n",
      "epoch:6 batch 1080/2221) Loss:41.94697570800781\n",
      "epoch:6 batch 1090/2221) Loss:24.657760620117188\n",
      "epoch:6 batch 1100/2221) Loss:11.171653747558594\n",
      "epoch:6 batch 1110/2221) Loss:55.77323913574219\n",
      "epoch:6 batch 1120/2221) Loss:20.270130157470703\n",
      "epoch:6 batch 1130/2221) Loss:10.196678161621094\n",
      "epoch:6 batch 1140/2221) Loss:29.939918518066406\n",
      "epoch:6 batch 1150/2221) Loss:20.271461486816406\n",
      "epoch:6 batch 1160/2221) Loss:22.748825073242188\n",
      "epoch:6 batch 1170/2221) Loss:32.599815368652344\n",
      "epoch:6 batch 1180/2221) Loss:48.99169921875\n",
      "epoch:6 batch 1190/2221) Loss:35.586448669433594\n",
      "epoch:6 batch 1200/2221) Loss:18.473785400390625\n",
      "epoch:6 batch 1210/2221) Loss:25.263748168945312\n",
      "epoch:6 batch 1220/2221) Loss:158.5845947265625\n",
      "epoch:6 batch 1230/2221) Loss:34.59972381591797\n",
      "epoch:6 batch 1240/2221) Loss:24.31517791748047\n",
      "epoch:6 batch 1250/2221) Loss:40.635719299316406\n",
      "epoch:6 batch 1260/2221) Loss:13.766860961914062\n",
      "epoch:6 batch 1270/2221) Loss:19.567955017089844\n",
      "epoch:6 batch 1280/2221) Loss:29.008556365966797\n",
      "epoch:6 batch 1290/2221) Loss:9.415611267089844\n",
      "epoch:6 batch 1300/2221) Loss:16.832046508789062\n",
      "epoch:6 batch 1310/2221) Loss:44.7987060546875\n",
      "epoch:6 batch 1320/2221) Loss:20.495018005371094\n",
      "epoch:6 batch 1330/2221) Loss:6.168468475341797\n",
      "epoch:6 batch 1340/2221) Loss:39.95683288574219\n",
      "epoch:6 batch 1350/2221) Loss:51.23226547241211\n",
      "epoch:6 batch 1360/2221) Loss:12.912849426269531\n",
      "epoch:6 batch 1370/2221) Loss:57.64140319824219\n",
      "epoch:6 batch 1380/2221) Loss:25.697723388671875\n",
      "epoch:6 batch 1390/2221) Loss:28.5927734375\n",
      "epoch:6 batch 1400/2221) Loss:13.373908996582031\n",
      "epoch:6 batch 1410/2221) Loss:10.462295532226562\n",
      "epoch:6 batch 1420/2221) Loss:30.28533172607422\n",
      "epoch:6 batch 1430/2221) Loss:30.60486602783203\n",
      "epoch:6 batch 1440/2221) Loss:36.07650375366211\n",
      "epoch:6 batch 1450/2221) Loss:38.60443878173828\n",
      "epoch:6 batch 1460/2221) Loss:18.57061767578125\n",
      "epoch:6 batch 1470/2221) Loss:37.64329528808594\n",
      "epoch:6 batch 1480/2221) Loss:24.566184997558594\n",
      "epoch:6 batch 1490/2221) Loss:20.29620361328125\n",
      "epoch:6 batch 1500/2221) Loss:22.479446411132812\n",
      "epoch:6 batch 1510/2221) Loss:11.809989929199219\n",
      "epoch:6 batch 1520/2221) Loss:44.08352279663086\n",
      "epoch:6 batch 1530/2221) Loss:16.356536865234375\n",
      "epoch:6 batch 1540/2221) Loss:52.1260871887207\n",
      "epoch:6 batch 1550/2221) Loss:13.672809600830078\n",
      "epoch:6 batch 1560/2221) Loss:59.854530334472656\n",
      "epoch:6 batch 1570/2221) Loss:24.88642120361328\n",
      "epoch:6 batch 1580/2221) Loss:53.73815155029297\n",
      "epoch:6 batch 1590/2221) Loss:43.696128845214844\n",
      "epoch:6 batch 1600/2221) Loss:21.245018005371094\n",
      "epoch:6 batch 1610/2221) Loss:22.33062744140625\n",
      "epoch:6 batch 1620/2221) Loss:38.85621643066406\n",
      "epoch:6 batch 1630/2221) Loss:8.785728454589844\n",
      "epoch:6 batch 1640/2221) Loss:31.78927993774414\n",
      "epoch:6 batch 1650/2221) Loss:29.517929077148438\n",
      "epoch:6 batch 1660/2221) Loss:28.273086547851562\n",
      "epoch:6 batch 1670/2221) Loss:15.883445739746094\n",
      "epoch:6 batch 1680/2221) Loss:13.17578125\n",
      "epoch:6 batch 1690/2221) Loss:13.565544128417969\n",
      "epoch:6 batch 1700/2221) Loss:30.86834716796875\n",
      "epoch:6 batch 1710/2221) Loss:8.866710662841797\n",
      "epoch:6 batch 1720/2221) Loss:27.61235809326172\n",
      "epoch:6 batch 1730/2221) Loss:45.42454147338867\n",
      "epoch:6 batch 1740/2221) Loss:21.545326232910156\n",
      "epoch:6 batch 1750/2221) Loss:19.57543182373047\n",
      "epoch:6 batch 1760/2221) Loss:20.983352661132812\n",
      "epoch:6 batch 1770/2221) Loss:31.136611938476562\n",
      "epoch:6 batch 1780/2221) Loss:49.215911865234375\n",
      "epoch:6 batch 1790/2221) Loss:56.73242950439453\n",
      "epoch:6 batch 1800/2221) Loss:40.951812744140625\n",
      "epoch:6 batch 1810/2221) Loss:28.071025848388672\n",
      "epoch:6 batch 1820/2221) Loss:37.76869201660156\n",
      "epoch:6 batch 1830/2221) Loss:35.416404724121094\n",
      "epoch:6 batch 1840/2221) Loss:17.463356018066406\n",
      "epoch:6 batch 1850/2221) Loss:13.698066711425781\n",
      "epoch:6 batch 1860/2221) Loss:20.447227478027344\n",
      "epoch:6 batch 1870/2221) Loss:33.242027282714844\n",
      "epoch:6 batch 1880/2221) Loss:39.74800109863281\n",
      "epoch:6 batch 1890/2221) Loss:22.990020751953125\n",
      "epoch:6 batch 1900/2221) Loss:10.587474822998047\n",
      "epoch:6 batch 1910/2221) Loss:32.30079650878906\n",
      "epoch:6 batch 1920/2221) Loss:46.378273010253906\n",
      "epoch:6 batch 1930/2221) Loss:8.345123291015625\n",
      "epoch:6 batch 1940/2221) Loss:26.96405792236328\n",
      "epoch:6 batch 1950/2221) Loss:10.645698547363281\n",
      "epoch:6 batch 1960/2221) Loss:36.55464172363281\n",
      "epoch:6 batch 1970/2221) Loss:48.52516174316406\n",
      "epoch:6 batch 1980/2221) Loss:51.962913513183594\n",
      "epoch:6 batch 1990/2221) Loss:15.719711303710938\n",
      "epoch:6 batch 2000/2221) Loss:63.22735595703125\n",
      "epoch:6 batch 2010/2221) Loss:14.78763198852539\n",
      "epoch:6 batch 2020/2221) Loss:42.52989196777344\n",
      "epoch:6 batch 2030/2221) Loss:31.500823974609375\n",
      "epoch:6 batch 2040/2221) Loss:34.3989143371582\n",
      "epoch:6 batch 2050/2221) Loss:25.354206085205078\n",
      "epoch:6 batch 2060/2221) Loss:11.904144287109375\n",
      "epoch:6 batch 2070/2221) Loss:19.427291870117188\n",
      "epoch:6 batch 2080/2221) Loss:59.19892120361328\n",
      "epoch:6 batch 2090/2221) Loss:51.19921875\n",
      "epoch:6 batch 2100/2221) Loss:39.759361267089844\n",
      "epoch:6 batch 2110/2221) Loss:16.81427764892578\n",
      "epoch:6 batch 2120/2221) Loss:19.488117218017578\n",
      "epoch:6 batch 2130/2221) Loss:16.426742553710938\n",
      "epoch:6 batch 2140/2221) Loss:22.953414916992188\n",
      "epoch:6 batch 2150/2221) Loss:11.15279769897461\n",
      "epoch:6 batch 2160/2221) Loss:67.3465576171875\n",
      "epoch:6 batch 2170/2221) Loss:11.669349670410156\n",
      "epoch:6 batch 2180/2221) Loss:9.101619720458984\n",
      "epoch:6 batch 2190/2221) Loss:23.463356018066406\n",
      "epoch:6 batch 2200/2221) Loss:50.95510482788086\n",
      "epoch:6 batch 2210/2221) Loss:53.23069763183594\n",
      "epoch:6 batch 2220/2221) Loss:24.442825317382812\n",
      "epoch:6 precision:0.9974086799452928 recall:0.9751595309937847 f1-score:0.9856557500755241\n",
      "epoch:7 batch 1/2221) Loss:53.97453308105469\n",
      "epoch:7 batch 10/2221) Loss:53.113983154296875\n",
      "epoch:7 batch 20/2221) Loss:14.331321716308594\n",
      "epoch:7 batch 30/2221) Loss:27.393184661865234\n",
      "epoch:7 batch 40/2221) Loss:21.867347717285156\n",
      "epoch:7 batch 50/2221) Loss:31.003604888916016\n",
      "epoch:7 batch 60/2221) Loss:33.608097076416016\n",
      "epoch:7 batch 70/2221) Loss:12.921234130859375\n",
      "epoch:7 batch 80/2221) Loss:30.935379028320312\n",
      "epoch:7 batch 90/2221) Loss:9.348037719726562\n",
      "epoch:7 batch 100/2221) Loss:12.374343872070312\n",
      "epoch:7 batch 110/2221) Loss:25.351585388183594\n",
      "epoch:7 batch 120/2221) Loss:37.67319869995117\n",
      "epoch:7 batch 130/2221) Loss:19.848033905029297\n",
      "epoch:7 batch 140/2221) Loss:17.457603454589844\n",
      "epoch:7 batch 150/2221) Loss:22.992530822753906\n",
      "epoch:7 batch 160/2221) Loss:75.92725372314453\n",
      "epoch:7 batch 170/2221) Loss:26.464630126953125\n",
      "epoch:7 batch 180/2221) Loss:37.36493682861328\n",
      "epoch:7 batch 190/2221) Loss:14.405601501464844\n",
      "epoch:7 batch 200/2221) Loss:14.221458435058594\n",
      "epoch:7 batch 210/2221) Loss:32.229949951171875\n",
      "epoch:7 batch 220/2221) Loss:21.07540512084961\n",
      "epoch:7 batch 230/2221) Loss:4.049053192138672\n",
      "epoch:7 batch 240/2221) Loss:39.80937194824219\n",
      "epoch:7 batch 250/2221) Loss:45.85009002685547\n",
      "epoch:7 batch 260/2221) Loss:18.408119201660156\n",
      "epoch:7 batch 270/2221) Loss:15.905754089355469\n",
      "epoch:7 batch 280/2221) Loss:73.16407775878906\n",
      "epoch:7 batch 290/2221) Loss:34.934608459472656\n",
      "epoch:7 batch 300/2221) Loss:34.58634948730469\n",
      "epoch:7 batch 310/2221) Loss:5.324913024902344\n",
      "epoch:7 batch 320/2221) Loss:17.483661651611328\n",
      "epoch:7 batch 330/2221) Loss:20.406208038330078\n",
      "epoch:7 batch 340/2221) Loss:20.552650451660156\n",
      "epoch:7 batch 350/2221) Loss:29.097999572753906\n",
      "epoch:7 batch 360/2221) Loss:27.630233764648438\n",
      "epoch:7 batch 370/2221) Loss:53.5896110534668\n",
      "epoch:7 batch 380/2221) Loss:27.953842163085938\n",
      "epoch:7 batch 390/2221) Loss:18.28436279296875\n",
      "epoch:7 batch 400/2221) Loss:46.8430290222168\n",
      "epoch:7 batch 410/2221) Loss:24.54114532470703\n",
      "epoch:7 batch 420/2221) Loss:54.634422302246094\n",
      "epoch:7 batch 430/2221) Loss:23.944766998291016\n",
      "epoch:7 batch 440/2221) Loss:14.397850036621094\n",
      "epoch:7 batch 450/2221) Loss:34.83708190917969\n",
      "epoch:7 batch 460/2221) Loss:41.339698791503906\n",
      "epoch:7 batch 470/2221) Loss:24.885814666748047\n",
      "epoch:7 batch 480/2221) Loss:16.71364974975586\n",
      "epoch:7 batch 490/2221) Loss:57.438114166259766\n",
      "epoch:7 batch 500/2221) Loss:16.657699584960938\n",
      "epoch:7 batch 510/2221) Loss:12.358753204345703\n",
      "epoch:7 batch 520/2221) Loss:24.060386657714844\n",
      "epoch:7 batch 530/2221) Loss:68.57681274414062\n",
      "epoch:7 batch 540/2221) Loss:31.218040466308594\n",
      "epoch:7 batch 550/2221) Loss:13.912498474121094\n",
      "epoch:7 batch 560/2221) Loss:10.841777801513672\n",
      "epoch:7 batch 570/2221) Loss:27.829132080078125\n",
      "epoch:7 batch 580/2221) Loss:37.02074432373047\n",
      "epoch:7 batch 590/2221) Loss:63.445335388183594\n",
      "epoch:7 batch 600/2221) Loss:41.69084167480469\n",
      "epoch:7 batch 610/2221) Loss:14.819171905517578\n",
      "epoch:7 batch 620/2221) Loss:43.19874572753906\n",
      "epoch:7 batch 630/2221) Loss:17.91366958618164\n",
      "epoch:7 batch 640/2221) Loss:12.648918151855469\n",
      "epoch:7 batch 650/2221) Loss:76.9256362915039\n",
      "epoch:7 batch 660/2221) Loss:23.471538543701172\n",
      "epoch:7 batch 670/2221) Loss:18.541282653808594\n",
      "epoch:7 batch 680/2221) Loss:19.47684097290039\n",
      "epoch:7 batch 690/2221) Loss:11.793083190917969\n",
      "epoch:7 batch 700/2221) Loss:45.763648986816406\n",
      "epoch:7 batch 710/2221) Loss:44.424407958984375\n",
      "epoch:7 batch 720/2221) Loss:15.34207534790039\n",
      "epoch:7 batch 730/2221) Loss:25.246063232421875\n",
      "epoch:7 batch 740/2221) Loss:10.040718078613281\n",
      "epoch:7 batch 750/2221) Loss:42.56765365600586\n",
      "epoch:7 batch 760/2221) Loss:34.15291976928711\n",
      "epoch:7 batch 770/2221) Loss:15.588508605957031\n",
      "epoch:7 batch 780/2221) Loss:10.178443908691406\n",
      "epoch:7 batch 790/2221) Loss:6.863140106201172\n",
      "epoch:7 batch 800/2221) Loss:30.760562896728516\n",
      "epoch:7 batch 810/2221) Loss:18.764873504638672\n",
      "epoch:7 batch 820/2221) Loss:8.476665496826172\n",
      "epoch:7 batch 830/2221) Loss:23.11785125732422\n",
      "epoch:7 batch 840/2221) Loss:13.392436981201172\n",
      "epoch:7 batch 850/2221) Loss:23.267547607421875\n",
      "epoch:7 batch 860/2221) Loss:47.17864227294922\n",
      "epoch:7 batch 870/2221) Loss:26.587078094482422\n",
      "epoch:7 batch 880/2221) Loss:18.565078735351562\n",
      "epoch:7 batch 890/2221) Loss:16.539596557617188\n",
      "epoch:7 batch 900/2221) Loss:39.86782455444336\n",
      "epoch:7 batch 910/2221) Loss:53.456993103027344\n",
      "epoch:7 batch 920/2221) Loss:14.143318176269531\n",
      "epoch:7 batch 930/2221) Loss:17.276580810546875\n",
      "epoch:7 batch 940/2221) Loss:23.85201644897461\n",
      "epoch:7 batch 950/2221) Loss:10.316570281982422\n",
      "epoch:7 batch 960/2221) Loss:7.6555938720703125\n",
      "epoch:7 batch 970/2221) Loss:11.78719711303711\n",
      "epoch:7 batch 980/2221) Loss:15.037036895751953\n",
      "epoch:7 batch 990/2221) Loss:59.33135986328125\n",
      "epoch:7 batch 1000/2221) Loss:27.20486068725586\n",
      "epoch:7 batch 1010/2221) Loss:28.042705535888672\n",
      "epoch:7 batch 1020/2221) Loss:38.003257751464844\n",
      "epoch:7 batch 1030/2221) Loss:12.859317779541016\n",
      "epoch:7 batch 1040/2221) Loss:36.01579666137695\n",
      "epoch:7 batch 1050/2221) Loss:9.37530517578125\n",
      "epoch:7 batch 1060/2221) Loss:16.117382049560547\n",
      "epoch:7 batch 1070/2221) Loss:53.01291275024414\n",
      "epoch:7 batch 1080/2221) Loss:14.008495330810547\n",
      "epoch:7 batch 1090/2221) Loss:25.141197204589844\n",
      "epoch:7 batch 1100/2221) Loss:31.87273406982422\n",
      "epoch:7 batch 1110/2221) Loss:19.566356658935547\n",
      "epoch:7 batch 1120/2221) Loss:17.51384735107422\n",
      "epoch:7 batch 1130/2221) Loss:24.03213882446289\n",
      "epoch:7 batch 1140/2221) Loss:15.264423370361328\n",
      "epoch:7 batch 1150/2221) Loss:41.123992919921875\n",
      "epoch:7 batch 1160/2221) Loss:43.176231384277344\n",
      "epoch:7 batch 1170/2221) Loss:12.087352752685547\n",
      "epoch:7 batch 1180/2221) Loss:20.80746078491211\n",
      "epoch:7 batch 1190/2221) Loss:19.928607940673828\n",
      "epoch:7 batch 1200/2221) Loss:18.183738708496094\n",
      "epoch:7 batch 1210/2221) Loss:14.13418197631836\n",
      "epoch:7 batch 1220/2221) Loss:19.91986083984375\n",
      "epoch:7 batch 1230/2221) Loss:17.10283660888672\n",
      "epoch:7 batch 1240/2221) Loss:17.057750701904297\n",
      "epoch:7 batch 1250/2221) Loss:84.07826232910156\n",
      "epoch:7 batch 1260/2221) Loss:15.15035629272461\n",
      "epoch:7 batch 1270/2221) Loss:27.910850524902344\n",
      "epoch:7 batch 1280/2221) Loss:19.156673431396484\n",
      "epoch:7 batch 1290/2221) Loss:23.76926040649414\n",
      "epoch:7 batch 1300/2221) Loss:34.293575286865234\n",
      "epoch:7 batch 1310/2221) Loss:32.49123764038086\n",
      "epoch:7 batch 1320/2221) Loss:21.234783172607422\n",
      "epoch:7 batch 1330/2221) Loss:19.160125732421875\n",
      "epoch:7 batch 1340/2221) Loss:5.284706115722656\n",
      "epoch:7 batch 1350/2221) Loss:22.80962371826172\n",
      "epoch:7 batch 1360/2221) Loss:33.81389236450195\n",
      "epoch:7 batch 1370/2221) Loss:3.1876068115234375\n",
      "epoch:7 batch 1380/2221) Loss:24.298274993896484\n",
      "epoch:7 batch 1390/2221) Loss:9.682548522949219\n",
      "epoch:7 batch 1400/2221) Loss:8.825492858886719\n",
      "epoch:7 batch 1410/2221) Loss:19.724193572998047\n",
      "epoch:7 batch 1420/2221) Loss:46.985740661621094\n",
      "epoch:7 batch 1430/2221) Loss:24.533523559570312\n",
      "epoch:7 batch 1440/2221) Loss:17.672569274902344\n",
      "epoch:7 batch 1450/2221) Loss:26.09160614013672\n",
      "epoch:7 batch 1460/2221) Loss:34.463199615478516\n",
      "epoch:7 batch 1470/2221) Loss:25.730270385742188\n",
      "epoch:7 batch 1480/2221) Loss:40.202537536621094\n",
      "epoch:7 batch 1490/2221) Loss:30.55127716064453\n",
      "epoch:7 batch 1500/2221) Loss:17.742034912109375\n",
      "epoch:7 batch 1510/2221) Loss:15.05367660522461\n",
      "epoch:7 batch 1520/2221) Loss:57.18498992919922\n",
      "epoch:7 batch 1530/2221) Loss:36.00986099243164\n",
      "epoch:7 batch 1540/2221) Loss:79.19902801513672\n",
      "epoch:7 batch 1550/2221) Loss:22.681663513183594\n",
      "epoch:7 batch 1560/2221) Loss:27.986377716064453\n",
      "epoch:7 batch 1570/2221) Loss:14.922035217285156\n",
      "epoch:7 batch 1580/2221) Loss:53.185791015625\n",
      "epoch:7 batch 1590/2221) Loss:29.081218719482422\n",
      "epoch:7 batch 1600/2221) Loss:36.28520965576172\n",
      "epoch:7 batch 1610/2221) Loss:18.038631439208984\n",
      "epoch:7 batch 1620/2221) Loss:22.25265884399414\n",
      "epoch:7 batch 1630/2221) Loss:24.81943130493164\n",
      "epoch:7 batch 1640/2221) Loss:26.58527374267578\n",
      "epoch:7 batch 1650/2221) Loss:57.07346725463867\n",
      "epoch:7 batch 1660/2221) Loss:51.63039016723633\n",
      "epoch:7 batch 1670/2221) Loss:35.11635971069336\n",
      "epoch:7 batch 1680/2221) Loss:12.926017761230469\n",
      "epoch:7 batch 1690/2221) Loss:46.54610824584961\n",
      "epoch:7 batch 1700/2221) Loss:14.332740783691406\n",
      "epoch:7 batch 1710/2221) Loss:14.13614273071289\n",
      "epoch:7 batch 1720/2221) Loss:17.167259216308594\n",
      "epoch:7 batch 1730/2221) Loss:26.337177276611328\n",
      "epoch:7 batch 1740/2221) Loss:21.85269546508789\n",
      "epoch:7 batch 1750/2221) Loss:34.6577262878418\n",
      "epoch:7 batch 1760/2221) Loss:33.293312072753906\n",
      "epoch:7 batch 1770/2221) Loss:20.91006088256836\n",
      "epoch:7 batch 1780/2221) Loss:35.595306396484375\n",
      "epoch:7 batch 1790/2221) Loss:39.29147720336914\n",
      "epoch:7 batch 1800/2221) Loss:39.0267448425293\n",
      "epoch:7 batch 1810/2221) Loss:19.09089469909668\n",
      "epoch:7 batch 1820/2221) Loss:18.399490356445312\n",
      "epoch:7 batch 1830/2221) Loss:17.55142593383789\n",
      "epoch:7 batch 1840/2221) Loss:46.105106353759766\n",
      "epoch:7 batch 1850/2221) Loss:18.752761840820312\n",
      "epoch:7 batch 1860/2221) Loss:14.579437255859375\n",
      "epoch:7 batch 1870/2221) Loss:27.129961013793945\n",
      "epoch:7 batch 1880/2221) Loss:14.622398376464844\n",
      "epoch:7 batch 1890/2221) Loss:15.841287612915039\n",
      "epoch:7 batch 1900/2221) Loss:27.90740203857422\n",
      "epoch:7 batch 1910/2221) Loss:23.489242553710938\n",
      "epoch:7 batch 1920/2221) Loss:15.54733657836914\n",
      "epoch:7 batch 1930/2221) Loss:18.15298843383789\n",
      "epoch:7 batch 1940/2221) Loss:53.02751159667969\n",
      "epoch:7 batch 1950/2221) Loss:55.92920684814453\n",
      "epoch:7 batch 1960/2221) Loss:15.20656967163086\n",
      "epoch:7 batch 1970/2221) Loss:26.605449676513672\n",
      "epoch:7 batch 1980/2221) Loss:12.858684539794922\n",
      "epoch:7 batch 1990/2221) Loss:29.71404266357422\n",
      "epoch:7 batch 2000/2221) Loss:43.465091705322266\n",
      "epoch:7 batch 2010/2221) Loss:27.960681915283203\n",
      "epoch:7 batch 2020/2221) Loss:20.034149169921875\n",
      "epoch:7 batch 2030/2221) Loss:21.783782958984375\n",
      "epoch:7 batch 2040/2221) Loss:15.4375\n",
      "epoch:7 batch 2050/2221) Loss:53.31306076049805\n",
      "epoch:7 batch 2060/2221) Loss:27.20523452758789\n",
      "epoch:7 batch 2070/2221) Loss:20.959835052490234\n",
      "epoch:7 batch 2080/2221) Loss:23.541423797607422\n",
      "epoch:7 batch 2090/2221) Loss:45.224456787109375\n",
      "epoch:7 batch 2100/2221) Loss:30.923656463623047\n",
      "epoch:7 batch 2110/2221) Loss:15.415164947509766\n",
      "epoch:7 batch 2120/2221) Loss:17.549991607666016\n",
      "epoch:7 batch 2130/2221) Loss:44.906532287597656\n",
      "epoch:7 batch 2140/2221) Loss:16.239105224609375\n",
      "epoch:7 batch 2150/2221) Loss:21.085800170898438\n",
      "epoch:7 batch 2160/2221) Loss:15.78915786743164\n",
      "epoch:7 batch 2170/2221) Loss:34.62516784667969\n",
      "epoch:7 batch 2180/2221) Loss:21.261280059814453\n",
      "epoch:7 batch 2190/2221) Loss:87.43582153320312\n",
      "epoch:7 batch 2200/2221) Loss:44.21969985961914\n",
      "epoch:7 batch 2210/2221) Loss:17.238262176513672\n",
      "epoch:7 batch 2220/2221) Loss:31.80718994140625\n",
      "epoch:7 precision:0.9976093071822651 recall:0.9753218280905545 f1-score:0.9859236359779759\n",
      "epoch:8 batch 1/2221) Loss:8.925098419189453\n",
      "epoch:8 batch 10/2221) Loss:40.81739807128906\n",
      "epoch:8 batch 20/2221) Loss:34.25157928466797\n",
      "epoch:8 batch 30/2221) Loss:42.498008728027344\n",
      "epoch:8 batch 40/2221) Loss:9.629951477050781\n",
      "epoch:8 batch 50/2221) Loss:11.53249740600586\n",
      "epoch:8 batch 60/2221) Loss:18.6617431640625\n",
      "epoch:8 batch 70/2221) Loss:5.916072845458984\n",
      "epoch:8 batch 80/2221) Loss:19.26589584350586\n",
      "epoch:8 batch 90/2221) Loss:12.734542846679688\n",
      "epoch:8 batch 100/2221) Loss:18.577327728271484\n",
      "epoch:8 batch 110/2221) Loss:21.71131134033203\n",
      "epoch:8 batch 120/2221) Loss:45.615665435791016\n",
      "epoch:8 batch 130/2221) Loss:13.328315734863281\n",
      "epoch:8 batch 140/2221) Loss:34.56782150268555\n",
      "epoch:8 batch 150/2221) Loss:21.79253387451172\n",
      "epoch:8 batch 160/2221) Loss:17.747081756591797\n",
      "epoch:8 batch 170/2221) Loss:19.764083862304688\n",
      "epoch:8 batch 180/2221) Loss:6.424045562744141\n",
      "epoch:8 batch 190/2221) Loss:10.135723114013672\n",
      "epoch:8 batch 200/2221) Loss:10.99533462524414\n",
      "epoch:8 batch 210/2221) Loss:15.646533966064453\n",
      "epoch:8 batch 220/2221) Loss:10.723564147949219\n",
      "epoch:8 batch 230/2221) Loss:25.19326400756836\n",
      "epoch:8 batch 240/2221) Loss:12.86358642578125\n",
      "epoch:8 batch 250/2221) Loss:85.17941284179688\n",
      "epoch:8 batch 260/2221) Loss:40.164066314697266\n",
      "epoch:8 batch 270/2221) Loss:13.367267608642578\n",
      "epoch:8 batch 280/2221) Loss:16.223663330078125\n",
      "epoch:8 batch 290/2221) Loss:23.789012908935547\n",
      "epoch:8 batch 300/2221) Loss:41.39457321166992\n",
      "epoch:8 batch 310/2221) Loss:15.698600769042969\n",
      "epoch:8 batch 320/2221) Loss:25.859085083007812\n",
      "epoch:8 batch 330/2221) Loss:18.63051986694336\n",
      "epoch:8 batch 340/2221) Loss:12.50155258178711\n",
      "epoch:8 batch 350/2221) Loss:7.822490692138672\n",
      "epoch:8 batch 360/2221) Loss:8.377662658691406\n",
      "epoch:8 batch 370/2221) Loss:19.74695587158203\n",
      "epoch:8 batch 380/2221) Loss:23.227203369140625\n",
      "epoch:8 batch 390/2221) Loss:41.87593460083008\n",
      "epoch:8 batch 400/2221) Loss:22.347362518310547\n",
      "epoch:8 batch 410/2221) Loss:45.65534210205078\n",
      "epoch:8 batch 420/2221) Loss:38.65433883666992\n",
      "epoch:8 batch 430/2221) Loss:17.202674865722656\n",
      "epoch:8 batch 440/2221) Loss:16.399978637695312\n",
      "epoch:8 batch 450/2221) Loss:16.692569732666016\n",
      "epoch:8 batch 460/2221) Loss:21.51679229736328\n",
      "epoch:8 batch 470/2221) Loss:30.297473907470703\n",
      "epoch:8 batch 480/2221) Loss:27.519725799560547\n",
      "epoch:8 batch 490/2221) Loss:22.36553955078125\n",
      "epoch:8 batch 500/2221) Loss:43.09159851074219\n",
      "epoch:8 batch 510/2221) Loss:15.516532897949219\n",
      "epoch:8 batch 520/2221) Loss:28.06258773803711\n",
      "epoch:8 batch 530/2221) Loss:15.580352783203125\n",
      "epoch:8 batch 540/2221) Loss:32.788963317871094\n",
      "epoch:8 batch 550/2221) Loss:33.550933837890625\n",
      "epoch:8 batch 560/2221) Loss:7.953151702880859\n",
      "epoch:8 batch 570/2221) Loss:11.901412963867188\n",
      "epoch:8 batch 580/2221) Loss:6.338569641113281\n",
      "epoch:8 batch 590/2221) Loss:28.785747528076172\n",
      "epoch:8 batch 600/2221) Loss:8.839645385742188\n",
      "epoch:8 batch 610/2221) Loss:46.81257247924805\n",
      "epoch:8 batch 620/2221) Loss:34.35335159301758\n",
      "epoch:8 batch 630/2221) Loss:28.42203140258789\n",
      "epoch:8 batch 640/2221) Loss:8.022666931152344\n",
      "epoch:8 batch 650/2221) Loss:30.5111083984375\n",
      "epoch:8 batch 660/2221) Loss:14.568695068359375\n",
      "epoch:8 batch 670/2221) Loss:8.309173583984375\n",
      "epoch:8 batch 680/2221) Loss:22.60940170288086\n",
      "epoch:8 batch 690/2221) Loss:24.002304077148438\n",
      "epoch:8 batch 700/2221) Loss:19.735076904296875\n",
      "epoch:8 batch 710/2221) Loss:42.25834655761719\n",
      "epoch:8 batch 720/2221) Loss:24.42791748046875\n",
      "epoch:8 batch 730/2221) Loss:14.616069793701172\n",
      "epoch:8 batch 740/2221) Loss:31.143829345703125\n",
      "epoch:8 batch 750/2221) Loss:6.915679931640625\n",
      "epoch:8 batch 760/2221) Loss:45.34470748901367\n",
      "epoch:8 batch 770/2221) Loss:18.046146392822266\n",
      "epoch:8 batch 780/2221) Loss:8.90877914428711\n",
      "epoch:8 batch 790/2221) Loss:21.011775970458984\n",
      "epoch:8 batch 800/2221) Loss:30.159446716308594\n",
      "epoch:8 batch 810/2221) Loss:13.466960906982422\n",
      "epoch:8 batch 820/2221) Loss:35.607059478759766\n",
      "epoch:8 batch 830/2221) Loss:25.845951080322266\n",
      "epoch:8 batch 840/2221) Loss:10.14617919921875\n",
      "epoch:8 batch 850/2221) Loss:16.145896911621094\n",
      "epoch:8 batch 860/2221) Loss:13.53713607788086\n",
      "epoch:8 batch 870/2221) Loss:56.52933883666992\n",
      "epoch:8 batch 880/2221) Loss:19.91608428955078\n",
      "epoch:8 batch 890/2221) Loss:14.802494049072266\n",
      "epoch:8 batch 900/2221) Loss:29.539989471435547\n",
      "epoch:8 batch 910/2221) Loss:34.587890625\n",
      "epoch:8 batch 920/2221) Loss:20.07998275756836\n",
      "epoch:8 batch 930/2221) Loss:9.743133544921875\n",
      "epoch:8 batch 940/2221) Loss:9.793941497802734\n",
      "epoch:8 batch 950/2221) Loss:42.657257080078125\n",
      "epoch:8 batch 960/2221) Loss:4.198387145996094\n",
      "epoch:8 batch 970/2221) Loss:19.59038543701172\n",
      "epoch:8 batch 980/2221) Loss:8.750274658203125\n",
      "epoch:8 batch 990/2221) Loss:60.00797653198242\n",
      "epoch:8 batch 1000/2221) Loss:19.600582122802734\n",
      "epoch:8 batch 1010/2221) Loss:15.795730590820312\n",
      "epoch:8 batch 1020/2221) Loss:14.365489959716797\n",
      "epoch:8 batch 1030/2221) Loss:5.716892242431641\n",
      "epoch:8 batch 1040/2221) Loss:46.46910095214844\n",
      "epoch:8 batch 1050/2221) Loss:14.324281692504883\n",
      "epoch:8 batch 1060/2221) Loss:32.57709503173828\n",
      "epoch:8 batch 1070/2221) Loss:11.065177917480469\n",
      "epoch:8 batch 1080/2221) Loss:39.7103271484375\n",
      "epoch:8 batch 1090/2221) Loss:14.244644165039062\n",
      "epoch:8 batch 1100/2221) Loss:20.7103271484375\n",
      "epoch:8 batch 1110/2221) Loss:32.96907424926758\n",
      "epoch:8 batch 1120/2221) Loss:20.798240661621094\n",
      "epoch:8 batch 1130/2221) Loss:3.303356170654297\n",
      "epoch:8 batch 1140/2221) Loss:31.67035675048828\n",
      "epoch:8 batch 1150/2221) Loss:17.229007720947266\n",
      "epoch:8 batch 1160/2221) Loss:39.584049224853516\n",
      "epoch:8 batch 1170/2221) Loss:36.28692626953125\n",
      "epoch:8 batch 1180/2221) Loss:24.986751556396484\n",
      "epoch:8 batch 1190/2221) Loss:23.301006317138672\n",
      "epoch:8 batch 1200/2221) Loss:16.575424194335938\n",
      "epoch:8 batch 1210/2221) Loss:37.97822570800781\n",
      "epoch:8 batch 1220/2221) Loss:16.94232177734375\n",
      "epoch:8 batch 1230/2221) Loss:22.91305160522461\n",
      "epoch:8 batch 1240/2221) Loss:17.08416748046875\n",
      "epoch:8 batch 1250/2221) Loss:26.962806701660156\n",
      "epoch:8 batch 1260/2221) Loss:18.705448150634766\n",
      "epoch:8 batch 1270/2221) Loss:31.072189331054688\n",
      "epoch:8 batch 1280/2221) Loss:13.946525573730469\n",
      "epoch:8 batch 1290/2221) Loss:53.742366790771484\n",
      "epoch:8 batch 1300/2221) Loss:32.51554489135742\n",
      "epoch:8 batch 1310/2221) Loss:17.704303741455078\n",
      "epoch:8 batch 1320/2221) Loss:23.169879913330078\n",
      "epoch:8 batch 1330/2221) Loss:7.7962646484375\n",
      "epoch:8 batch 1340/2221) Loss:12.509666442871094\n",
      "epoch:8 batch 1350/2221) Loss:10.458786010742188\n",
      "epoch:8 batch 1360/2221) Loss:58.780845642089844\n",
      "epoch:8 batch 1370/2221) Loss:20.080963134765625\n",
      "epoch:8 batch 1380/2221) Loss:12.551090240478516\n",
      "epoch:8 batch 1390/2221) Loss:42.1765022277832\n",
      "epoch:8 batch 1400/2221) Loss:21.662208557128906\n",
      "epoch:8 batch 1410/2221) Loss:35.93128204345703\n",
      "epoch:8 batch 1420/2221) Loss:13.00238037109375\n",
      "epoch:8 batch 1430/2221) Loss:35.16705322265625\n",
      "epoch:8 batch 1440/2221) Loss:31.60019302368164\n",
      "epoch:8 batch 1450/2221) Loss:31.360801696777344\n",
      "epoch:8 batch 1460/2221) Loss:20.185901641845703\n",
      "epoch:8 batch 1470/2221) Loss:11.266887664794922\n",
      "epoch:8 batch 1480/2221) Loss:27.089969635009766\n",
      "epoch:8 batch 1490/2221) Loss:16.104564666748047\n",
      "epoch:8 batch 1500/2221) Loss:110.94920349121094\n",
      "epoch:8 batch 1510/2221) Loss:18.234230041503906\n",
      "epoch:8 batch 1520/2221) Loss:15.140613555908203\n",
      "epoch:8 batch 1530/2221) Loss:14.858406066894531\n",
      "epoch:8 batch 1540/2221) Loss:24.372020721435547\n",
      "epoch:8 batch 1550/2221) Loss:19.657630920410156\n",
      "epoch:8 batch 1560/2221) Loss:28.448280334472656\n",
      "epoch:8 batch 1570/2221) Loss:29.356170654296875\n",
      "epoch:8 batch 1580/2221) Loss:54.17023468017578\n",
      "epoch:8 batch 1590/2221) Loss:68.43385314941406\n",
      "epoch:8 batch 1600/2221) Loss:12.725963592529297\n",
      "epoch:8 batch 1610/2221) Loss:33.83271789550781\n",
      "epoch:8 batch 1620/2221) Loss:17.145599365234375\n",
      "epoch:8 batch 1630/2221) Loss:18.35250473022461\n",
      "epoch:8 batch 1640/2221) Loss:13.91800308227539\n",
      "epoch:8 batch 1650/2221) Loss:14.548748016357422\n",
      "epoch:8 batch 1660/2221) Loss:8.864982604980469\n",
      "epoch:8 batch 1670/2221) Loss:38.49413299560547\n",
      "epoch:8 batch 1680/2221) Loss:24.32332992553711\n",
      "epoch:8 batch 1690/2221) Loss:33.415584564208984\n",
      "epoch:8 batch 1700/2221) Loss:23.139389038085938\n",
      "epoch:8 batch 1710/2221) Loss:25.22250747680664\n",
      "epoch:8 batch 1720/2221) Loss:48.339088439941406\n",
      "epoch:8 batch 1730/2221) Loss:19.76702880859375\n",
      "epoch:8 batch 1740/2221) Loss:10.238700866699219\n",
      "epoch:8 batch 1750/2221) Loss:14.684898376464844\n",
      "epoch:8 batch 1760/2221) Loss:7.453857421875\n",
      "epoch:8 batch 1770/2221) Loss:25.187427520751953\n",
      "epoch:8 batch 1780/2221) Loss:12.927772521972656\n",
      "epoch:8 batch 1790/2221) Loss:10.154884338378906\n",
      "epoch:8 batch 1800/2221) Loss:9.119033813476562\n",
      "epoch:8 batch 1810/2221) Loss:9.549049377441406\n",
      "epoch:8 batch 1820/2221) Loss:11.686355590820312\n",
      "epoch:8 batch 1830/2221) Loss:11.225772857666016\n",
      "epoch:8 batch 1840/2221) Loss:32.23482894897461\n",
      "epoch:8 batch 1850/2221) Loss:32.165157318115234\n",
      "epoch:8 batch 1860/2221) Loss:23.293628692626953\n",
      "epoch:8 batch 1870/2221) Loss:3.374530792236328\n",
      "epoch:8 batch 1880/2221) Loss:12.073596954345703\n",
      "epoch:8 batch 1890/2221) Loss:24.033329010009766\n",
      "epoch:8 batch 1900/2221) Loss:21.480369567871094\n",
      "epoch:8 batch 1910/2221) Loss:23.293670654296875\n",
      "epoch:8 batch 1920/2221) Loss:36.38436508178711\n",
      "epoch:8 batch 1930/2221) Loss:3.0145416259765625\n",
      "epoch:8 batch 1940/2221) Loss:8.947792053222656\n",
      "epoch:8 batch 1950/2221) Loss:30.06623077392578\n",
      "epoch:8 batch 1960/2221) Loss:11.184425354003906\n",
      "epoch:8 batch 1970/2221) Loss:34.375022888183594\n",
      "epoch:8 batch 1980/2221) Loss:16.41582489013672\n",
      "epoch:8 batch 1990/2221) Loss:11.211135864257812\n",
      "epoch:8 batch 2000/2221) Loss:5.626308441162109\n",
      "epoch:8 batch 2010/2221) Loss:15.133155822753906\n",
      "epoch:8 batch 2020/2221) Loss:13.786624908447266\n",
      "epoch:8 batch 2030/2221) Loss:56.078575134277344\n",
      "epoch:8 batch 2040/2221) Loss:45.877525329589844\n",
      "epoch:8 batch 2050/2221) Loss:3.343151092529297\n",
      "epoch:8 batch 2060/2221) Loss:21.37356185913086\n",
      "epoch:8 batch 2070/2221) Loss:17.102256774902344\n",
      "epoch:8 batch 2080/2221) Loss:16.617473602294922\n",
      "epoch:8 batch 2090/2221) Loss:32.63136291503906\n",
      "epoch:8 batch 2100/2221) Loss:25.321449279785156\n",
      "epoch:8 batch 2110/2221) Loss:26.345291137695312\n",
      "epoch:8 batch 2120/2221) Loss:9.2122802734375\n",
      "epoch:8 batch 2130/2221) Loss:21.93136215209961\n",
      "epoch:8 batch 2140/2221) Loss:25.568119049072266\n",
      "epoch:8 batch 2150/2221) Loss:65.82489776611328\n",
      "epoch:8 batch 2160/2221) Loss:26.15271759033203\n",
      "epoch:8 batch 2170/2221) Loss:25.97234344482422\n",
      "epoch:8 batch 2180/2221) Loss:35.949913024902344\n",
      "epoch:8 batch 2190/2221) Loss:4.9708709716796875\n",
      "epoch:8 batch 2200/2221) Loss:19.11209487915039\n",
      "epoch:8 batch 2210/2221) Loss:18.484840393066406\n",
      "epoch:8 batch 2220/2221) Loss:32.27204132080078\n",
      "epoch:8 precision:0.9979076710296424 recall:0.9774455810052525 f1-score:0.9871312325513589\n",
      "epoch:9 batch 1/2221) Loss:35.91100311279297\n",
      "epoch:9 batch 10/2221) Loss:6.483249664306641\n",
      "epoch:9 batch 20/2221) Loss:61.525264739990234\n",
      "epoch:9 batch 30/2221) Loss:9.80105972290039\n",
      "epoch:9 batch 40/2221) Loss:15.010459899902344\n",
      "epoch:9 batch 50/2221) Loss:17.651569366455078\n",
      "epoch:9 batch 60/2221) Loss:15.010276794433594\n",
      "epoch:9 batch 70/2221) Loss:23.757522583007812\n",
      "epoch:9 batch 80/2221) Loss:33.20133972167969\n",
      "epoch:9 batch 90/2221) Loss:7.837196350097656\n",
      "epoch:9 batch 100/2221) Loss:25.2762451171875\n",
      "epoch:9 batch 110/2221) Loss:35.38114929199219\n",
      "epoch:9 batch 120/2221) Loss:23.316028594970703\n",
      "epoch:9 batch 130/2221) Loss:14.160346984863281\n",
      "epoch:9 batch 140/2221) Loss:14.03317642211914\n",
      "epoch:9 batch 150/2221) Loss:11.203895568847656\n",
      "epoch:9 batch 160/2221) Loss:42.00253677368164\n",
      "epoch:9 batch 170/2221) Loss:17.3273983001709\n",
      "epoch:9 batch 180/2221) Loss:30.915542602539062\n",
      "epoch:9 batch 190/2221) Loss:15.194103240966797\n",
      "epoch:9 batch 200/2221) Loss:15.715805053710938\n",
      "epoch:9 batch 210/2221) Loss:18.56439971923828\n",
      "epoch:9 batch 220/2221) Loss:13.22299575805664\n",
      "epoch:9 batch 230/2221) Loss:57.618045806884766\n",
      "epoch:9 batch 240/2221) Loss:9.173858642578125\n",
      "epoch:9 batch 250/2221) Loss:34.74147415161133\n",
      "epoch:9 batch 260/2221) Loss:21.536014556884766\n",
      "epoch:9 batch 270/2221) Loss:23.569469451904297\n",
      "epoch:9 batch 280/2221) Loss:44.62156677246094\n",
      "epoch:9 batch 290/2221) Loss:43.613887786865234\n",
      "epoch:9 batch 300/2221) Loss:50.617393493652344\n",
      "epoch:9 batch 310/2221) Loss:21.543315887451172\n",
      "epoch:9 batch 320/2221) Loss:9.439266204833984\n",
      "epoch:9 batch 330/2221) Loss:11.608997344970703\n",
      "epoch:9 batch 340/2221) Loss:26.041526794433594\n",
      "epoch:9 batch 350/2221) Loss:29.95608139038086\n",
      "epoch:9 batch 360/2221) Loss:18.208744049072266\n",
      "epoch:9 batch 370/2221) Loss:17.42957878112793\n",
      "epoch:9 batch 380/2221) Loss:32.905548095703125\n",
      "epoch:9 batch 390/2221) Loss:18.405601501464844\n",
      "epoch:9 batch 400/2221) Loss:12.12308120727539\n",
      "epoch:9 batch 410/2221) Loss:29.500957489013672\n",
      "epoch:9 batch 420/2221) Loss:19.342689514160156\n",
      "epoch:9 batch 430/2221) Loss:21.169780731201172\n",
      "epoch:9 batch 440/2221) Loss:4.827383041381836\n",
      "epoch:9 batch 450/2221) Loss:24.187915802001953\n",
      "epoch:9 batch 460/2221) Loss:8.979846954345703\n",
      "epoch:9 batch 470/2221) Loss:16.18450927734375\n",
      "epoch:9 batch 480/2221) Loss:44.46095275878906\n",
      "epoch:9 batch 490/2221) Loss:26.94601821899414\n",
      "epoch:9 batch 500/2221) Loss:31.952709197998047\n",
      "epoch:9 batch 510/2221) Loss:13.029472351074219\n",
      "epoch:9 batch 520/2221) Loss:15.538036346435547\n",
      "epoch:9 batch 530/2221) Loss:17.268415451049805\n",
      "epoch:9 batch 540/2221) Loss:15.5313720703125\n",
      "epoch:9 batch 550/2221) Loss:10.578010559082031\n",
      "epoch:9 batch 560/2221) Loss:31.689922332763672\n",
      "epoch:9 batch 570/2221) Loss:31.84765625\n",
      "epoch:9 batch 580/2221) Loss:11.87918472290039\n",
      "epoch:9 batch 590/2221) Loss:12.595840454101562\n",
      "epoch:9 batch 600/2221) Loss:17.660625457763672\n",
      "epoch:9 batch 610/2221) Loss:19.400970458984375\n",
      "epoch:9 batch 620/2221) Loss:33.06939697265625\n",
      "epoch:9 batch 630/2221) Loss:15.20498275756836\n",
      "epoch:9 batch 640/2221) Loss:18.16225814819336\n",
      "epoch:9 batch 650/2221) Loss:22.453746795654297\n",
      "epoch:9 batch 660/2221) Loss:19.121036529541016\n",
      "epoch:9 batch 670/2221) Loss:34.225257873535156\n",
      "epoch:9 batch 680/2221) Loss:13.050819396972656\n",
      "epoch:9 batch 690/2221) Loss:5.006809234619141\n",
      "epoch:9 batch 700/2221) Loss:13.359657287597656\n",
      "epoch:9 batch 710/2221) Loss:15.864383697509766\n",
      "epoch:9 batch 720/2221) Loss:15.023189544677734\n",
      "epoch:9 batch 730/2221) Loss:24.13302230834961\n",
      "epoch:9 batch 740/2221) Loss:16.436513900756836\n",
      "epoch:9 batch 750/2221) Loss:42.14490509033203\n",
      "epoch:9 batch 760/2221) Loss:23.40796661376953\n",
      "epoch:9 batch 770/2221) Loss:22.15838623046875\n",
      "epoch:9 batch 780/2221) Loss:12.952919006347656\n",
      "epoch:9 batch 790/2221) Loss:18.732196807861328\n",
      "epoch:9 batch 800/2221) Loss:11.750186920166016\n",
      "epoch:9 batch 810/2221) Loss:23.06964874267578\n",
      "epoch:9 batch 820/2221) Loss:21.118335723876953\n",
      "epoch:9 batch 830/2221) Loss:20.805622100830078\n",
      "epoch:9 batch 840/2221) Loss:24.908336639404297\n",
      "epoch:9 batch 850/2221) Loss:48.73005294799805\n",
      "epoch:9 batch 860/2221) Loss:10.422521591186523\n",
      "epoch:9 batch 870/2221) Loss:7.832828521728516\n",
      "epoch:9 batch 880/2221) Loss:30.689594268798828\n",
      "epoch:9 batch 890/2221) Loss:10.888614654541016\n",
      "epoch:9 batch 900/2221) Loss:29.951805114746094\n",
      "epoch:9 batch 910/2221) Loss:27.151039123535156\n",
      "epoch:9 batch 920/2221) Loss:27.21894645690918\n",
      "epoch:9 batch 930/2221) Loss:14.289543151855469\n",
      "epoch:9 batch 940/2221) Loss:16.034561157226562\n",
      "epoch:9 batch 950/2221) Loss:56.170326232910156\n",
      "epoch:9 batch 960/2221) Loss:43.707122802734375\n",
      "epoch:9 batch 970/2221) Loss:21.644882202148438\n",
      "epoch:9 batch 980/2221) Loss:26.257129669189453\n",
      "epoch:9 batch 990/2221) Loss:18.621116638183594\n",
      "epoch:9 batch 1000/2221) Loss:20.5140438079834\n",
      "epoch:9 batch 1010/2221) Loss:34.56658935546875\n",
      "epoch:9 batch 1020/2221) Loss:15.261520385742188\n",
      "epoch:9 batch 1030/2221) Loss:12.341941833496094\n",
      "epoch:9 batch 1040/2221) Loss:21.9146728515625\n",
      "epoch:9 batch 1050/2221) Loss:21.523590087890625\n",
      "epoch:9 batch 1060/2221) Loss:19.81214141845703\n",
      "epoch:9 batch 1070/2221) Loss:10.600826263427734\n",
      "epoch:9 batch 1080/2221) Loss:12.466106414794922\n",
      "epoch:9 batch 1090/2221) Loss:28.76798439025879\n",
      "epoch:9 batch 1100/2221) Loss:25.001361846923828\n",
      "epoch:9 batch 1110/2221) Loss:25.335147857666016\n",
      "epoch:9 batch 1120/2221) Loss:47.02002716064453\n",
      "epoch:9 batch 1130/2221) Loss:23.886707305908203\n",
      "epoch:9 batch 1140/2221) Loss:11.291336059570312\n",
      "epoch:9 batch 1150/2221) Loss:9.088006973266602\n",
      "epoch:9 batch 1160/2221) Loss:25.33448028564453\n",
      "epoch:9 batch 1170/2221) Loss:9.54623031616211\n",
      "epoch:9 batch 1180/2221) Loss:12.538532257080078\n",
      "epoch:9 batch 1190/2221) Loss:29.385940551757812\n",
      "epoch:9 batch 1200/2221) Loss:19.496864318847656\n",
      "epoch:9 batch 1210/2221) Loss:60.88717269897461\n",
      "epoch:9 batch 1220/2221) Loss:9.65509033203125\n",
      "epoch:9 batch 1230/2221) Loss:9.578388214111328\n",
      "epoch:9 batch 1240/2221) Loss:16.577049255371094\n",
      "epoch:9 batch 1250/2221) Loss:14.564451217651367\n",
      "epoch:9 batch 1260/2221) Loss:8.449886322021484\n",
      "epoch:9 batch 1270/2221) Loss:14.770732879638672\n",
      "epoch:9 batch 1280/2221) Loss:26.160675048828125\n",
      "epoch:9 batch 1290/2221) Loss:34.00022888183594\n",
      "epoch:9 batch 1300/2221) Loss:4.122653961181641\n",
      "epoch:9 batch 1310/2221) Loss:11.187431335449219\n",
      "epoch:9 batch 1320/2221) Loss:12.367742538452148\n",
      "epoch:9 batch 1330/2221) Loss:30.387653350830078\n",
      "epoch:9 batch 1340/2221) Loss:14.068004608154297\n",
      "epoch:9 batch 1350/2221) Loss:14.220294952392578\n",
      "epoch:9 batch 1360/2221) Loss:5.681741714477539\n",
      "epoch:9 batch 1370/2221) Loss:12.475006103515625\n",
      "epoch:9 batch 1380/2221) Loss:43.867637634277344\n",
      "epoch:9 batch 1390/2221) Loss:19.359342575073242\n",
      "epoch:9 batch 1400/2221) Loss:24.132831573486328\n",
      "epoch:9 batch 1410/2221) Loss:19.25334930419922\n",
      "epoch:9 batch 1420/2221) Loss:28.77379035949707\n",
      "epoch:9 batch 1430/2221) Loss:21.11083984375\n",
      "epoch:9 batch 1440/2221) Loss:30.953044891357422\n",
      "epoch:9 batch 1450/2221) Loss:18.61742401123047\n",
      "epoch:9 batch 1460/2221) Loss:43.92378234863281\n",
      "epoch:9 batch 1470/2221) Loss:23.912841796875\n",
      "epoch:9 batch 1480/2221) Loss:30.62744140625\n",
      "epoch:9 batch 1490/2221) Loss:23.69424819946289\n",
      "epoch:9 batch 1500/2221) Loss:12.333026885986328\n",
      "epoch:9 batch 1510/2221) Loss:30.656810760498047\n",
      "epoch:9 batch 1520/2221) Loss:29.613155364990234\n",
      "epoch:9 batch 1530/2221) Loss:21.943634033203125\n",
      "epoch:9 batch 1540/2221) Loss:38.91747283935547\n",
      "epoch:9 batch 1550/2221) Loss:15.862485885620117\n",
      "epoch:9 batch 1560/2221) Loss:24.552188873291016\n",
      "epoch:9 batch 1570/2221) Loss:30.654170989990234\n",
      "epoch:9 batch 1580/2221) Loss:27.028057098388672\n",
      "epoch:9 batch 1590/2221) Loss:23.971546173095703\n",
      "epoch:9 batch 1600/2221) Loss:14.922121047973633\n",
      "epoch:9 batch 1610/2221) Loss:25.092823028564453\n",
      "epoch:9 batch 1620/2221) Loss:12.89126205444336\n",
      "epoch:9 batch 1630/2221) Loss:8.220382690429688\n",
      "epoch:9 batch 1640/2221) Loss:10.911170959472656\n",
      "epoch:9 batch 1650/2221) Loss:19.971599578857422\n",
      "epoch:9 batch 1660/2221) Loss:23.37942123413086\n",
      "epoch:9 batch 1670/2221) Loss:11.9013671875\n",
      "epoch:9 batch 1680/2221) Loss:4.785762786865234\n",
      "epoch:9 batch 1690/2221) Loss:64.03602600097656\n",
      "epoch:9 batch 1700/2221) Loss:18.93341064453125\n",
      "epoch:9 batch 1710/2221) Loss:24.084653854370117\n",
      "epoch:9 batch 1720/2221) Loss:26.49242401123047\n",
      "epoch:9 batch 1730/2221) Loss:15.91783332824707\n",
      "epoch:9 batch 1740/2221) Loss:22.63275909423828\n",
      "epoch:9 batch 1750/2221) Loss:13.223983764648438\n",
      "epoch:9 batch 1760/2221) Loss:52.9981689453125\n",
      "epoch:9 batch 1770/2221) Loss:18.05512046813965\n",
      "epoch:9 batch 1780/2221) Loss:9.152616500854492\n",
      "epoch:9 batch 1790/2221) Loss:32.06667709350586\n",
      "epoch:9 batch 1800/2221) Loss:14.58984375\n",
      "epoch:9 batch 1810/2221) Loss:51.4252815246582\n",
      "epoch:9 batch 1820/2221) Loss:10.768440246582031\n",
      "epoch:9 batch 1830/2221) Loss:26.452919006347656\n",
      "epoch:9 batch 1840/2221) Loss:36.8941650390625\n",
      "epoch:9 batch 1850/2221) Loss:12.773635864257812\n",
      "epoch:9 batch 1860/2221) Loss:24.52630615234375\n",
      "epoch:9 batch 1870/2221) Loss:22.38308334350586\n",
      "epoch:9 batch 1880/2221) Loss:20.416812896728516\n",
      "epoch:9 batch 1890/2221) Loss:4.707271575927734\n",
      "epoch:9 batch 1900/2221) Loss:5.810253143310547\n",
      "epoch:9 batch 1910/2221) Loss:42.962379455566406\n",
      "epoch:9 batch 1920/2221) Loss:11.066064834594727\n",
      "epoch:9 batch 1930/2221) Loss:52.71891403198242\n",
      "epoch:9 batch 1940/2221) Loss:19.408803939819336\n",
      "epoch:9 batch 1950/2221) Loss:14.92569351196289\n",
      "epoch:9 batch 1960/2221) Loss:8.899833679199219\n",
      "epoch:9 batch 1970/2221) Loss:3.95458984375\n",
      "epoch:9 batch 1980/2221) Loss:7.386909484863281\n",
      "epoch:9 batch 1990/2221) Loss:36.278343200683594\n",
      "epoch:9 batch 2000/2221) Loss:13.854364395141602\n",
      "epoch:9 batch 2010/2221) Loss:9.872699737548828\n",
      "epoch:9 batch 2020/2221) Loss:14.730987548828125\n",
      "epoch:9 batch 2030/2221) Loss:24.109725952148438\n",
      "epoch:9 batch 2040/2221) Loss:15.44656753540039\n",
      "epoch:9 batch 2050/2221) Loss:16.278223037719727\n",
      "epoch:9 batch 2060/2221) Loss:11.723472595214844\n",
      "epoch:9 batch 2070/2221) Loss:11.441368103027344\n",
      "epoch:9 batch 2080/2221) Loss:24.278104782104492\n",
      "epoch:9 batch 2090/2221) Loss:24.053714752197266\n",
      "epoch:9 batch 2100/2221) Loss:21.2547607421875\n",
      "epoch:9 batch 2110/2221) Loss:62.61184310913086\n",
      "epoch:9 batch 2120/2221) Loss:42.76540756225586\n",
      "epoch:9 batch 2130/2221) Loss:11.77365493774414\n",
      "epoch:9 batch 2140/2221) Loss:9.317398071289062\n",
      "epoch:9 batch 2150/2221) Loss:19.06641387939453\n",
      "epoch:9 batch 2160/2221) Loss:26.026824951171875\n",
      "epoch:9 batch 2170/2221) Loss:14.65594482421875\n",
      "epoch:9 batch 2180/2221) Loss:28.24679183959961\n",
      "epoch:9 batch 2190/2221) Loss:26.245384216308594\n",
      "epoch:9 batch 2200/2221) Loss:7.839916229248047\n",
      "epoch:9 batch 2210/2221) Loss:10.69210433959961\n",
      "epoch:9 batch 2220/2221) Loss:33.229827880859375\n",
      "epoch:9 precision:0.9980648207454793 recall:0.9786124365019842 f1-score:0.9878700600971743\n",
      "epoch:10 batch 1/2221) Loss:12.428661346435547\n",
      "epoch:10 batch 10/2221) Loss:6.515693664550781\n",
      "epoch:10 batch 20/2221) Loss:16.818645477294922\n",
      "epoch:10 batch 30/2221) Loss:15.875040054321289\n",
      "epoch:10 batch 40/2221) Loss:45.771385192871094\n",
      "epoch:10 batch 50/2221) Loss:18.59304428100586\n",
      "epoch:10 batch 60/2221) Loss:24.03484344482422\n",
      "epoch:10 batch 70/2221) Loss:8.716150283813477\n",
      "epoch:10 batch 80/2221) Loss:29.933761596679688\n",
      "epoch:10 batch 90/2221) Loss:18.308116912841797\n",
      "epoch:10 batch 100/2221) Loss:55.68885803222656\n",
      "epoch:10 batch 110/2221) Loss:11.032234191894531\n",
      "epoch:10 batch 120/2221) Loss:11.828445434570312\n",
      "epoch:10 batch 130/2221) Loss:34.032562255859375\n",
      "epoch:10 batch 140/2221) Loss:13.262632369995117\n",
      "epoch:10 batch 150/2221) Loss:34.47585678100586\n",
      "epoch:10 batch 160/2221) Loss:11.315662384033203\n",
      "epoch:10 batch 170/2221) Loss:17.374618530273438\n",
      "epoch:10 batch 180/2221) Loss:16.438350677490234\n",
      "epoch:10 batch 190/2221) Loss:5.5264434814453125\n",
      "epoch:10 batch 200/2221) Loss:12.928369522094727\n",
      "epoch:10 batch 210/2221) Loss:8.529401779174805\n",
      "epoch:10 batch 220/2221) Loss:19.692169189453125\n",
      "epoch:10 batch 230/2221) Loss:8.375789642333984\n",
      "epoch:10 batch 240/2221) Loss:37.422489166259766\n",
      "epoch:10 batch 250/2221) Loss:16.545921325683594\n",
      "epoch:10 batch 260/2221) Loss:34.98457336425781\n",
      "epoch:10 batch 270/2221) Loss:37.055877685546875\n",
      "epoch:10 batch 280/2221) Loss:24.761375427246094\n",
      "epoch:10 batch 290/2221) Loss:23.974084854125977\n",
      "epoch:10 batch 300/2221) Loss:18.493968963623047\n",
      "epoch:10 batch 310/2221) Loss:9.074615478515625\n",
      "epoch:10 batch 320/2221) Loss:6.11210823059082\n",
      "epoch:10 batch 330/2221) Loss:14.050588607788086\n",
      "epoch:10 batch 340/2221) Loss:21.10489845275879\n",
      "epoch:10 batch 350/2221) Loss:34.569244384765625\n",
      "epoch:10 batch 360/2221) Loss:12.603754043579102\n",
      "epoch:10 batch 370/2221) Loss:27.07196807861328\n",
      "epoch:10 batch 380/2221) Loss:35.537322998046875\n",
      "epoch:10 batch 390/2221) Loss:15.933002471923828\n",
      "epoch:10 batch 400/2221) Loss:37.51234817504883\n",
      "epoch:10 batch 410/2221) Loss:11.167396545410156\n",
      "epoch:10 batch 420/2221) Loss:50.11568832397461\n",
      "epoch:10 batch 430/2221) Loss:22.603958129882812\n",
      "epoch:10 batch 440/2221) Loss:15.605812072753906\n",
      "epoch:10 batch 450/2221) Loss:10.911407470703125\n",
      "epoch:10 batch 460/2221) Loss:16.20774269104004\n",
      "epoch:10 batch 470/2221) Loss:22.907474517822266\n",
      "epoch:10 batch 480/2221) Loss:22.187223434448242\n",
      "epoch:10 batch 490/2221) Loss:23.0389461517334\n",
      "epoch:10 batch 500/2221) Loss:32.43110275268555\n",
      "epoch:10 batch 510/2221) Loss:7.334077835083008\n",
      "epoch:10 batch 520/2221) Loss:16.524761199951172\n",
      "epoch:10 batch 530/2221) Loss:16.54355812072754\n",
      "epoch:10 batch 540/2221) Loss:54.26786804199219\n",
      "epoch:10 batch 550/2221) Loss:5.106380462646484\n",
      "epoch:10 batch 560/2221) Loss:7.781312942504883\n",
      "epoch:10 batch 570/2221) Loss:25.71735382080078\n",
      "epoch:10 batch 580/2221) Loss:18.887224197387695\n",
      "epoch:10 batch 590/2221) Loss:7.4464111328125\n",
      "epoch:10 batch 600/2221) Loss:11.255481719970703\n",
      "epoch:10 batch 610/2221) Loss:14.96560287475586\n",
      "epoch:10 batch 620/2221) Loss:24.952938079833984\n",
      "epoch:10 batch 630/2221) Loss:13.372018814086914\n",
      "epoch:10 batch 640/2221) Loss:12.314691543579102\n",
      "epoch:10 batch 650/2221) Loss:21.384885787963867\n",
      "epoch:10 batch 660/2221) Loss:22.89807891845703\n",
      "epoch:10 batch 670/2221) Loss:13.998832702636719\n",
      "epoch:10 batch 680/2221) Loss:22.94681167602539\n",
      "epoch:10 batch 690/2221) Loss:21.665851593017578\n",
      "epoch:10 batch 700/2221) Loss:22.639142990112305\n",
      "epoch:10 batch 710/2221) Loss:26.443649291992188\n",
      "epoch:10 batch 720/2221) Loss:17.45008087158203\n",
      "epoch:10 batch 730/2221) Loss:15.731122970581055\n",
      "epoch:10 batch 740/2221) Loss:22.716434478759766\n",
      "epoch:10 batch 750/2221) Loss:24.59725570678711\n",
      "epoch:10 batch 760/2221) Loss:8.099376678466797\n",
      "epoch:10 batch 770/2221) Loss:21.220687866210938\n",
      "epoch:10 batch 780/2221) Loss:21.7989559173584\n",
      "epoch:10 batch 790/2221) Loss:12.66646957397461\n",
      "epoch:10 batch 800/2221) Loss:13.187309265136719\n",
      "epoch:10 batch 810/2221) Loss:33.000205993652344\n",
      "epoch:10 batch 820/2221) Loss:49.79875946044922\n",
      "epoch:10 batch 830/2221) Loss:29.705036163330078\n",
      "epoch:10 batch 840/2221) Loss:7.667026519775391\n",
      "epoch:10 batch 850/2221) Loss:28.94384002685547\n",
      "epoch:10 batch 860/2221) Loss:17.407350540161133\n",
      "epoch:10 batch 870/2221) Loss:32.331382751464844\n",
      "epoch:10 batch 880/2221) Loss:8.273189544677734\n",
      "epoch:10 batch 890/2221) Loss:5.7628631591796875\n",
      "epoch:10 batch 900/2221) Loss:23.920490264892578\n",
      "epoch:10 batch 910/2221) Loss:23.035106658935547\n",
      "epoch:10 batch 920/2221) Loss:13.490676879882812\n",
      "epoch:10 batch 930/2221) Loss:19.053329467773438\n",
      "epoch:10 batch 940/2221) Loss:25.31395721435547\n",
      "epoch:10 batch 950/2221) Loss:5.327548980712891\n",
      "epoch:10 batch 960/2221) Loss:10.161392211914062\n",
      "epoch:10 batch 970/2221) Loss:7.565343856811523\n",
      "epoch:10 batch 980/2221) Loss:3.745269775390625\n",
      "epoch:10 batch 990/2221) Loss:11.67938232421875\n",
      "epoch:10 batch 1000/2221) Loss:18.640216827392578\n",
      "epoch:10 batch 1010/2221) Loss:10.950429916381836\n",
      "epoch:10 batch 1020/2221) Loss:16.568695068359375\n",
      "epoch:10 batch 1030/2221) Loss:10.741512298583984\n",
      "epoch:10 batch 1040/2221) Loss:35.95002746582031\n",
      "epoch:10 batch 1050/2221) Loss:26.515830993652344\n",
      "epoch:10 batch 1060/2221) Loss:11.490409851074219\n",
      "epoch:10 batch 1070/2221) Loss:18.234750747680664\n",
      "epoch:10 batch 1080/2221) Loss:13.550851821899414\n",
      "epoch:10 batch 1090/2221) Loss:21.699508666992188\n",
      "epoch:10 batch 1100/2221) Loss:34.88557052612305\n",
      "epoch:10 batch 1110/2221) Loss:18.72756576538086\n",
      "epoch:10 batch 1120/2221) Loss:4.546836853027344\n",
      "epoch:10 batch 1130/2221) Loss:12.662986755371094\n",
      "epoch:10 batch 1140/2221) Loss:18.21866226196289\n",
      "epoch:10 batch 1150/2221) Loss:16.844884872436523\n",
      "epoch:10 batch 1160/2221) Loss:20.986934661865234\n",
      "epoch:10 batch 1170/2221) Loss:11.575096130371094\n",
      "epoch:10 batch 1180/2221) Loss:9.92548942565918\n",
      "epoch:10 batch 1190/2221) Loss:23.203643798828125\n",
      "epoch:10 batch 1200/2221) Loss:93.32398986816406\n",
      "epoch:10 batch 1210/2221) Loss:2.0114707946777344\n",
      "epoch:10 batch 1220/2221) Loss:28.365150451660156\n",
      "epoch:10 batch 1230/2221) Loss:30.86066246032715\n",
      "epoch:10 batch 1240/2221) Loss:32.10236358642578\n",
      "epoch:10 batch 1250/2221) Loss:12.086488723754883\n",
      "epoch:10 batch 1260/2221) Loss:19.2237606048584\n",
      "epoch:10 batch 1270/2221) Loss:28.662349700927734\n",
      "epoch:10 batch 1280/2221) Loss:28.28709602355957\n",
      "epoch:10 batch 1290/2221) Loss:35.349342346191406\n",
      "epoch:10 batch 1300/2221) Loss:16.5672550201416\n",
      "epoch:10 batch 1310/2221) Loss:31.48769760131836\n",
      "epoch:10 batch 1320/2221) Loss:2.4608001708984375\n",
      "epoch:10 batch 1330/2221) Loss:21.12708282470703\n",
      "epoch:10 batch 1340/2221) Loss:7.929365158081055\n",
      "epoch:10 batch 1350/2221) Loss:20.637401580810547\n",
      "epoch:10 batch 1360/2221) Loss:8.684061050415039\n",
      "epoch:10 batch 1370/2221) Loss:20.125852584838867\n",
      "epoch:10 batch 1380/2221) Loss:40.83081817626953\n",
      "epoch:10 batch 1390/2221) Loss:43.27294921875\n",
      "epoch:10 batch 1400/2221) Loss:44.38419723510742\n",
      "epoch:10 batch 1410/2221) Loss:21.057626724243164\n",
      "epoch:10 batch 1420/2221) Loss:6.304096221923828\n",
      "epoch:10 batch 1430/2221) Loss:6.661493301391602\n",
      "epoch:10 batch 1440/2221) Loss:32.57191467285156\n",
      "epoch:10 batch 1450/2221) Loss:18.200040817260742\n",
      "epoch:10 batch 1460/2221) Loss:18.497446060180664\n",
      "epoch:10 batch 1470/2221) Loss:9.228876113891602\n",
      "epoch:10 batch 1480/2221) Loss:9.933563232421875\n",
      "epoch:10 batch 1490/2221) Loss:24.63258171081543\n",
      "epoch:10 batch 1500/2221) Loss:7.445833206176758\n",
      "epoch:10 batch 1510/2221) Loss:8.480323791503906\n",
      "epoch:10 batch 1520/2221) Loss:15.324562072753906\n",
      "epoch:10 batch 1530/2221) Loss:9.728145599365234\n",
      "epoch:10 batch 1540/2221) Loss:16.33161735534668\n",
      "epoch:10 batch 1550/2221) Loss:18.771881103515625\n",
      "epoch:10 batch 1560/2221) Loss:13.72216796875\n",
      "epoch:10 batch 1570/2221) Loss:13.519098281860352\n",
      "epoch:10 batch 1580/2221) Loss:13.135448455810547\n",
      "epoch:10 batch 1590/2221) Loss:33.62316131591797\n",
      "epoch:10 batch 1600/2221) Loss:22.46617889404297\n",
      "epoch:10 batch 1610/2221) Loss:5.033632278442383\n",
      "epoch:10 batch 1620/2221) Loss:6.916706085205078\n",
      "epoch:10 batch 1630/2221) Loss:36.87167739868164\n",
      "epoch:10 batch 1640/2221) Loss:28.189979553222656\n",
      "epoch:10 batch 1650/2221) Loss:24.474451065063477\n",
      "epoch:10 batch 1660/2221) Loss:8.701387405395508\n",
      "epoch:10 batch 1670/2221) Loss:6.21807861328125\n",
      "epoch:10 batch 1680/2221) Loss:14.747949600219727\n",
      "epoch:10 batch 1690/2221) Loss:21.035926818847656\n",
      "epoch:10 batch 1700/2221) Loss:24.965986251831055\n",
      "epoch:10 batch 1710/2221) Loss:6.997747421264648\n",
      "epoch:10 batch 1720/2221) Loss:3.4995346069335938\n",
      "epoch:10 batch 1730/2221) Loss:18.522178649902344\n",
      "epoch:10 batch 1740/2221) Loss:8.354837417602539\n",
      "epoch:10 batch 1750/2221) Loss:10.67254638671875\n",
      "epoch:10 batch 1760/2221) Loss:34.71710968017578\n",
      "epoch:10 batch 1770/2221) Loss:9.814994812011719\n",
      "epoch:10 batch 1780/2221) Loss:22.29861831665039\n",
      "epoch:10 batch 1790/2221) Loss:13.23369026184082\n",
      "epoch:10 batch 1800/2221) Loss:7.760599136352539\n",
      "epoch:10 batch 1810/2221) Loss:6.510395050048828\n",
      "epoch:10 batch 1820/2221) Loss:10.020566940307617\n",
      "epoch:10 batch 1830/2221) Loss:29.886335372924805\n",
      "epoch:10 batch 1840/2221) Loss:25.965906143188477\n",
      "epoch:10 batch 1850/2221) Loss:11.372472763061523\n",
      "epoch:10 batch 1860/2221) Loss:26.840347290039062\n",
      "epoch:10 batch 1870/2221) Loss:23.151546478271484\n",
      "epoch:10 batch 1880/2221) Loss:29.485862731933594\n",
      "epoch:10 batch 1890/2221) Loss:11.419782638549805\n",
      "epoch:10 batch 1900/2221) Loss:18.1103458404541\n",
      "epoch:10 batch 1910/2221) Loss:21.067241668701172\n",
      "epoch:10 batch 1920/2221) Loss:6.852375030517578\n",
      "epoch:10 batch 1930/2221) Loss:18.34813117980957\n",
      "epoch:10 batch 1940/2221) Loss:13.651422500610352\n",
      "epoch:10 batch 1950/2221) Loss:20.384674072265625\n",
      "epoch:10 batch 1960/2221) Loss:50.066593170166016\n",
      "epoch:10 batch 1970/2221) Loss:21.4985408782959\n",
      "epoch:10 batch 1980/2221) Loss:15.096982955932617\n",
      "epoch:10 batch 1990/2221) Loss:18.5792179107666\n",
      "epoch:10 batch 2000/2221) Loss:21.862667083740234\n",
      "epoch:10 batch 2010/2221) Loss:13.119466781616211\n",
      "epoch:10 batch 2020/2221) Loss:22.727521896362305\n",
      "epoch:10 batch 2030/2221) Loss:19.43647003173828\n",
      "epoch:10 batch 2040/2221) Loss:17.155635833740234\n",
      "epoch:10 batch 2050/2221) Loss:9.974445343017578\n",
      "epoch:10 batch 2060/2221) Loss:11.522117614746094\n",
      "epoch:10 batch 2070/2221) Loss:32.77668762207031\n",
      "epoch:10 batch 2080/2221) Loss:5.741455078125\n",
      "epoch:10 batch 2090/2221) Loss:25.243507385253906\n",
      "epoch:10 batch 2100/2221) Loss:31.82940101623535\n",
      "epoch:10 batch 2110/2221) Loss:28.184484481811523\n",
      "epoch:10 batch 2120/2221) Loss:14.832391738891602\n",
      "epoch:10 batch 2130/2221) Loss:27.145036697387695\n",
      "epoch:10 batch 2140/2221) Loss:27.361520767211914\n",
      "epoch:10 batch 2150/2221) Loss:9.68881607055664\n",
      "epoch:10 batch 2160/2221) Loss:39.173973083496094\n",
      "epoch:10 batch 2170/2221) Loss:30.402971267700195\n",
      "epoch:10 batch 2180/2221) Loss:8.468818664550781\n",
      "epoch:10 batch 2190/2221) Loss:48.666404724121094\n",
      "epoch:10 batch 2200/2221) Loss:26.96408462524414\n",
      "epoch:10 batch 2210/2221) Loss:8.694536209106445\n",
      "epoch:10 batch 2220/2221) Loss:9.216224670410156\n",
      "epoch:10 precision:0.9967110971298894 recall:0.9792943674657757 f1-score:0.9875902394398649\n",
      "epoch:11 batch 1/2221) Loss:16.581430435180664\n",
      "epoch:11 batch 10/2221) Loss:12.605283737182617\n",
      "epoch:11 batch 20/2221) Loss:20.615354537963867\n",
      "epoch:11 batch 30/2221) Loss:36.31658172607422\n",
      "epoch:11 batch 40/2221) Loss:27.309492111206055\n",
      "epoch:11 batch 50/2221) Loss:3.23370361328125\n",
      "epoch:11 batch 60/2221) Loss:17.98697853088379\n",
      "epoch:11 batch 70/2221) Loss:18.945636749267578\n",
      "epoch:11 batch 80/2221) Loss:2.196779251098633\n",
      "epoch:11 batch 90/2221) Loss:6.717639923095703\n",
      "epoch:11 batch 100/2221) Loss:13.404495239257812\n",
      "epoch:11 batch 110/2221) Loss:29.005287170410156\n",
      "epoch:11 batch 120/2221) Loss:18.166423797607422\n",
      "epoch:11 batch 130/2221) Loss:14.668540954589844\n",
      "epoch:11 batch 140/2221) Loss:20.310110092163086\n",
      "epoch:11 batch 150/2221) Loss:20.662681579589844\n",
      "epoch:11 batch 160/2221) Loss:27.073644638061523\n",
      "epoch:11 batch 170/2221) Loss:25.495615005493164\n",
      "epoch:11 batch 180/2221) Loss:12.637826919555664\n",
      "epoch:11 batch 190/2221) Loss:4.511386871337891\n",
      "epoch:11 batch 200/2221) Loss:104.56183624267578\n",
      "epoch:11 batch 210/2221) Loss:5.283390045166016\n",
      "epoch:11 batch 220/2221) Loss:34.476524353027344\n",
      "epoch:11 batch 230/2221) Loss:31.851791381835938\n",
      "epoch:11 batch 240/2221) Loss:11.657751083374023\n",
      "epoch:11 batch 250/2221) Loss:47.21415710449219\n",
      "epoch:11 batch 260/2221) Loss:13.662710189819336\n",
      "epoch:11 batch 270/2221) Loss:20.356578826904297\n",
      "epoch:11 batch 280/2221) Loss:15.694000244140625\n",
      "epoch:11 batch 290/2221) Loss:33.02790832519531\n",
      "epoch:11 batch 300/2221) Loss:11.201642990112305\n",
      "epoch:11 batch 310/2221) Loss:11.11899185180664\n",
      "epoch:11 batch 320/2221) Loss:9.78150749206543\n",
      "epoch:11 batch 330/2221) Loss:2.892915725708008\n",
      "epoch:11 batch 340/2221) Loss:10.746047973632812\n",
      "epoch:11 batch 350/2221) Loss:16.594921112060547\n",
      "epoch:11 batch 360/2221) Loss:15.854440689086914\n",
      "epoch:11 batch 370/2221) Loss:8.147420883178711\n",
      "epoch:11 batch 380/2221) Loss:22.196109771728516\n",
      "epoch:11 batch 390/2221) Loss:13.717254638671875\n",
      "epoch:11 batch 400/2221) Loss:20.827322006225586\n",
      "epoch:11 batch 410/2221) Loss:37.73788833618164\n",
      "epoch:11 batch 420/2221) Loss:16.296850204467773\n",
      "epoch:11 batch 430/2221) Loss:10.300241470336914\n",
      "epoch:11 batch 440/2221) Loss:14.718950271606445\n",
      "epoch:11 batch 450/2221) Loss:7.940944671630859\n",
      "epoch:11 batch 460/2221) Loss:12.54399299621582\n",
      "epoch:11 batch 470/2221) Loss:17.93093490600586\n",
      "epoch:11 batch 480/2221) Loss:30.025131225585938\n",
      "epoch:11 batch 490/2221) Loss:10.219839096069336\n",
      "epoch:11 batch 500/2221) Loss:15.259092330932617\n",
      "epoch:11 batch 510/2221) Loss:16.87357521057129\n",
      "epoch:11 batch 520/2221) Loss:3.5889225006103516\n",
      "epoch:11 batch 530/2221) Loss:13.729219436645508\n",
      "epoch:11 batch 540/2221) Loss:11.036056518554688\n",
      "epoch:11 batch 550/2221) Loss:10.713766098022461\n",
      "epoch:11 batch 560/2221) Loss:16.631702423095703\n",
      "epoch:11 batch 570/2221) Loss:11.479059219360352\n",
      "epoch:11 batch 580/2221) Loss:31.500011444091797\n",
      "epoch:11 batch 590/2221) Loss:12.59129524230957\n",
      "epoch:11 batch 600/2221) Loss:20.38821792602539\n",
      "epoch:11 batch 610/2221) Loss:10.675270080566406\n",
      "epoch:11 batch 620/2221) Loss:12.561180114746094\n",
      "epoch:11 batch 630/2221) Loss:30.943862915039062\n",
      "epoch:11 batch 640/2221) Loss:3.8742599487304688\n",
      "epoch:11 batch 650/2221) Loss:14.877204895019531\n",
      "epoch:11 batch 660/2221) Loss:38.79765319824219\n",
      "epoch:11 batch 670/2221) Loss:10.351556777954102\n",
      "epoch:11 batch 680/2221) Loss:39.57267761230469\n",
      "epoch:11 batch 690/2221) Loss:13.270120620727539\n",
      "epoch:11 batch 700/2221) Loss:5.156412124633789\n",
      "epoch:11 batch 710/2221) Loss:16.09294319152832\n",
      "epoch:11 batch 720/2221) Loss:17.583091735839844\n",
      "epoch:11 batch 730/2221) Loss:13.480443954467773\n",
      "epoch:11 batch 740/2221) Loss:13.449073791503906\n",
      "epoch:11 batch 750/2221) Loss:21.044466018676758\n",
      "epoch:11 batch 760/2221) Loss:13.606653213500977\n",
      "epoch:11 batch 770/2221) Loss:27.81840705871582\n",
      "epoch:11 batch 780/2221) Loss:23.010007858276367\n",
      "epoch:11 batch 790/2221) Loss:61.53456115722656\n",
      "epoch:11 batch 800/2221) Loss:17.858423233032227\n",
      "epoch:11 batch 810/2221) Loss:8.331872940063477\n",
      "epoch:11 batch 820/2221) Loss:62.84101867675781\n",
      "epoch:11 batch 830/2221) Loss:15.493356704711914\n",
      "epoch:11 batch 840/2221) Loss:11.016130447387695\n",
      "epoch:11 batch 850/2221) Loss:26.94227409362793\n",
      "epoch:11 batch 860/2221) Loss:12.07453727722168\n",
      "epoch:11 batch 870/2221) Loss:13.343456268310547\n",
      "epoch:11 batch 880/2221) Loss:26.396753311157227\n",
      "epoch:11 batch 890/2221) Loss:15.777994155883789\n",
      "epoch:11 batch 900/2221) Loss:15.283306121826172\n",
      "epoch:11 batch 910/2221) Loss:13.184024810791016\n",
      "epoch:11 batch 920/2221) Loss:16.8606014251709\n",
      "epoch:11 batch 930/2221) Loss:3.812681198120117\n",
      "epoch:11 batch 940/2221) Loss:38.26850128173828\n",
      "epoch:11 batch 950/2221) Loss:11.395082473754883\n",
      "epoch:11 batch 960/2221) Loss:17.219280242919922\n",
      "epoch:11 batch 970/2221) Loss:24.15840721130371\n",
      "epoch:11 batch 980/2221) Loss:18.271305084228516\n",
      "epoch:11 batch 990/2221) Loss:39.91643524169922\n",
      "epoch:11 batch 1000/2221) Loss:11.07371711730957\n",
      "epoch:11 batch 1010/2221) Loss:17.547760009765625\n",
      "epoch:11 batch 1020/2221) Loss:14.314876556396484\n",
      "epoch:11 batch 1030/2221) Loss:14.733339309692383\n",
      "epoch:11 batch 1040/2221) Loss:38.46910095214844\n",
      "epoch:11 batch 1050/2221) Loss:17.23441505432129\n",
      "epoch:11 batch 1060/2221) Loss:4.149503707885742\n",
      "epoch:11 batch 1070/2221) Loss:9.120891571044922\n",
      "epoch:11 batch 1080/2221) Loss:16.520416259765625\n",
      "epoch:11 batch 1090/2221) Loss:18.64739990234375\n",
      "epoch:11 batch 1100/2221) Loss:15.099605560302734\n",
      "epoch:11 batch 1110/2221) Loss:14.695566177368164\n",
      "epoch:11 batch 1120/2221) Loss:32.7078857421875\n",
      "epoch:11 batch 1130/2221) Loss:36.367889404296875\n",
      "epoch:11 batch 1140/2221) Loss:13.279727935791016\n",
      "epoch:11 batch 1150/2221) Loss:6.1889801025390625\n",
      "epoch:11 batch 1160/2221) Loss:9.920858383178711\n",
      "epoch:11 batch 1170/2221) Loss:19.093236923217773\n",
      "epoch:11 batch 1180/2221) Loss:2.626993179321289\n",
      "epoch:11 batch 1190/2221) Loss:8.006282806396484\n",
      "epoch:11 batch 1200/2221) Loss:14.684871673583984\n",
      "epoch:11 batch 1210/2221) Loss:13.60324478149414\n",
      "epoch:11 batch 1220/2221) Loss:22.374671936035156\n",
      "epoch:11 batch 1230/2221) Loss:7.794260025024414\n",
      "epoch:11 batch 1240/2221) Loss:11.14669418334961\n",
      "epoch:11 batch 1250/2221) Loss:6.289369583129883\n",
      "epoch:11 batch 1260/2221) Loss:6.912355422973633\n",
      "epoch:11 batch 1270/2221) Loss:31.938940048217773\n",
      "epoch:11 batch 1280/2221) Loss:5.689144134521484\n",
      "epoch:11 batch 1290/2221) Loss:17.192401885986328\n",
      "epoch:11 batch 1300/2221) Loss:11.4510498046875\n",
      "epoch:11 batch 1310/2221) Loss:18.32562828063965\n",
      "epoch:11 batch 1320/2221) Loss:18.465686798095703\n",
      "epoch:11 batch 1330/2221) Loss:15.31190299987793\n",
      "epoch:11 batch 1340/2221) Loss:24.301424026489258\n",
      "epoch:11 batch 1350/2221) Loss:11.882118225097656\n",
      "epoch:11 batch 1360/2221) Loss:35.47526168823242\n",
      "epoch:11 batch 1370/2221) Loss:10.070581436157227\n",
      "epoch:11 batch 1380/2221) Loss:9.662191390991211\n",
      "epoch:11 batch 1390/2221) Loss:8.063880920410156\n",
      "epoch:11 batch 1400/2221) Loss:9.245647430419922\n",
      "epoch:11 batch 1410/2221) Loss:24.515575408935547\n",
      "epoch:11 batch 1420/2221) Loss:6.6345062255859375\n",
      "epoch:11 batch 1430/2221) Loss:50.279258728027344\n",
      "epoch:11 batch 1440/2221) Loss:27.73213768005371\n",
      "epoch:11 batch 1450/2221) Loss:9.91533088684082\n",
      "epoch:11 batch 1460/2221) Loss:15.764068603515625\n",
      "epoch:11 batch 1470/2221) Loss:16.938108444213867\n",
      "epoch:11 batch 1480/2221) Loss:19.331193923950195\n",
      "epoch:11 batch 1490/2221) Loss:8.252458572387695\n",
      "epoch:11 batch 1500/2221) Loss:32.327659606933594\n",
      "epoch:11 batch 1510/2221) Loss:23.95513343811035\n",
      "epoch:11 batch 1520/2221) Loss:10.754301071166992\n",
      "epoch:11 batch 1530/2221) Loss:19.214080810546875\n",
      "epoch:11 batch 1540/2221) Loss:7.454811096191406\n",
      "epoch:11 batch 1550/2221) Loss:6.071260452270508\n",
      "epoch:11 batch 1560/2221) Loss:10.481651306152344\n",
      "epoch:11 batch 1570/2221) Loss:18.47036361694336\n",
      "epoch:11 batch 1580/2221) Loss:22.214773178100586\n",
      "epoch:11 batch 1590/2221) Loss:29.000930786132812\n",
      "epoch:11 batch 1600/2221) Loss:8.468936920166016\n",
      "epoch:11 batch 1610/2221) Loss:17.03949737548828\n",
      "epoch:11 batch 1620/2221) Loss:13.413894653320312\n",
      "epoch:11 batch 1630/2221) Loss:36.89667510986328\n",
      "epoch:11 batch 1640/2221) Loss:14.487543106079102\n",
      "epoch:11 batch 1650/2221) Loss:9.482158660888672\n",
      "epoch:11 batch 1660/2221) Loss:24.366865158081055\n",
      "epoch:11 batch 1670/2221) Loss:23.832721710205078\n",
      "epoch:11 batch 1680/2221) Loss:7.961391448974609\n",
      "epoch:11 batch 1690/2221) Loss:16.4953670501709\n",
      "epoch:11 batch 1700/2221) Loss:17.368040084838867\n",
      "epoch:11 batch 1710/2221) Loss:20.951059341430664\n",
      "epoch:11 batch 1720/2221) Loss:23.695411682128906\n",
      "epoch:11 batch 1730/2221) Loss:33.44070816040039\n",
      "epoch:11 batch 1740/2221) Loss:28.109663009643555\n",
      "epoch:11 batch 1750/2221) Loss:3.8002281188964844\n",
      "epoch:11 batch 1760/2221) Loss:18.102325439453125\n",
      "epoch:11 batch 1770/2221) Loss:34.796913146972656\n",
      "epoch:11 batch 1780/2221) Loss:11.71722412109375\n",
      "epoch:11 batch 1790/2221) Loss:5.614419937133789\n",
      "epoch:11 batch 1800/2221) Loss:26.968008041381836\n",
      "epoch:11 batch 1810/2221) Loss:14.110710144042969\n",
      "epoch:11 batch 1820/2221) Loss:14.63801383972168\n",
      "epoch:11 batch 1830/2221) Loss:9.079813003540039\n",
      "epoch:11 batch 1840/2221) Loss:15.427637100219727\n",
      "epoch:11 batch 1850/2221) Loss:34.887672424316406\n",
      "epoch:11 batch 1860/2221) Loss:23.681804656982422\n",
      "epoch:11 batch 1870/2221) Loss:33.056209564208984\n",
      "epoch:11 batch 1880/2221) Loss:4.193672180175781\n",
      "epoch:11 batch 1890/2221) Loss:18.86239242553711\n",
      "epoch:11 batch 1900/2221) Loss:22.066614151000977\n",
      "epoch:11 batch 1910/2221) Loss:12.32998275756836\n",
      "epoch:11 batch 1920/2221) Loss:15.25922966003418\n",
      "epoch:11 batch 1930/2221) Loss:13.504125595092773\n",
      "epoch:11 batch 1940/2221) Loss:7.814262390136719\n",
      "epoch:11 batch 1950/2221) Loss:14.513205528259277\n",
      "epoch:11 batch 1960/2221) Loss:18.32546615600586\n",
      "epoch:11 batch 1970/2221) Loss:14.751705169677734\n",
      "epoch:11 batch 1980/2221) Loss:26.026451110839844\n",
      "epoch:11 batch 1990/2221) Loss:17.129371643066406\n",
      "epoch:11 batch 2000/2221) Loss:14.373489379882812\n",
      "epoch:11 batch 2010/2221) Loss:7.426853179931641\n",
      "epoch:11 batch 2020/2221) Loss:14.217729568481445\n",
      "epoch:11 batch 2030/2221) Loss:28.348983764648438\n",
      "epoch:11 batch 2040/2221) Loss:22.987674713134766\n",
      "epoch:11 batch 2050/2221) Loss:3.299867630004883\n",
      "epoch:11 batch 2060/2221) Loss:22.701602935791016\n",
      "epoch:11 batch 2070/2221) Loss:4.156493186950684\n",
      "epoch:11 batch 2080/2221) Loss:4.575307846069336\n",
      "epoch:11 batch 2090/2221) Loss:9.246784210205078\n",
      "epoch:11 batch 2100/2221) Loss:7.0350341796875\n",
      "epoch:11 batch 2110/2221) Loss:35.71014404296875\n",
      "epoch:11 batch 2120/2221) Loss:9.88981819152832\n",
      "epoch:11 batch 2130/2221) Loss:6.069007873535156\n",
      "epoch:11 batch 2140/2221) Loss:23.645565032958984\n",
      "epoch:11 batch 2150/2221) Loss:12.711591720581055\n",
      "epoch:11 batch 2160/2221) Loss:27.717296600341797\n",
      "epoch:11 batch 2170/2221) Loss:25.078475952148438\n",
      "epoch:11 batch 2180/2221) Loss:11.497365951538086\n",
      "epoch:11 batch 2190/2221) Loss:12.98682975769043\n",
      "epoch:11 batch 2200/2221) Loss:8.812835693359375\n",
      "epoch:11 batch 2210/2221) Loss:10.996465682983398\n",
      "epoch:11 batch 2220/2221) Loss:25.343812942504883\n",
      "epoch:11 precision:0.9968472740347394 recall:0.9816212423908482 f1-score:0.988901287307626\n",
      "epoch:12 batch 1/2221) Loss:21.666366577148438\n",
      "epoch:12 batch 10/2221) Loss:14.35641098022461\n",
      "epoch:12 batch 20/2221) Loss:37.148983001708984\n",
      "epoch:12 batch 30/2221) Loss:22.38043212890625\n",
      "epoch:12 batch 40/2221) Loss:27.76595687866211\n",
      "epoch:12 batch 50/2221) Loss:25.224332809448242\n",
      "epoch:12 batch 60/2221) Loss:28.150928497314453\n",
      "epoch:12 batch 70/2221) Loss:4.992420196533203\n",
      "epoch:12 batch 80/2221) Loss:14.109762191772461\n",
      "epoch:12 batch 90/2221) Loss:9.339944839477539\n",
      "epoch:12 batch 100/2221) Loss:18.566837310791016\n",
      "epoch:12 batch 110/2221) Loss:17.736989974975586\n",
      "epoch:12 batch 120/2221) Loss:33.95130920410156\n",
      "epoch:12 batch 130/2221) Loss:10.913106918334961\n",
      "epoch:12 batch 140/2221) Loss:3.8578643798828125\n",
      "epoch:12 batch 150/2221) Loss:4.350957870483398\n",
      "epoch:12 batch 160/2221) Loss:30.854103088378906\n",
      "epoch:12 batch 170/2221) Loss:13.700668334960938\n",
      "epoch:12 batch 180/2221) Loss:43.361854553222656\n",
      "epoch:12 batch 190/2221) Loss:7.342153549194336\n",
      "epoch:12 batch 200/2221) Loss:25.61908531188965\n",
      "epoch:12 batch 210/2221) Loss:19.452091217041016\n",
      "epoch:12 batch 220/2221) Loss:3.125051498413086\n",
      "epoch:12 batch 230/2221) Loss:14.030149459838867\n",
      "epoch:12 batch 240/2221) Loss:12.156717300415039\n",
      "epoch:12 batch 250/2221) Loss:12.377330780029297\n",
      "epoch:12 batch 260/2221) Loss:5.993036270141602\n",
      "epoch:12 batch 270/2221) Loss:6.855073928833008\n",
      "epoch:12 batch 280/2221) Loss:16.668102264404297\n",
      "epoch:12 batch 290/2221) Loss:7.466337203979492\n",
      "epoch:12 batch 300/2221) Loss:26.98067283630371\n",
      "epoch:12 batch 310/2221) Loss:17.530031204223633\n",
      "epoch:12 batch 320/2221) Loss:19.665311813354492\n",
      "epoch:12 batch 330/2221) Loss:22.763927459716797\n",
      "epoch:12 batch 340/2221) Loss:27.632213592529297\n",
      "epoch:12 batch 350/2221) Loss:20.790931701660156\n",
      "epoch:12 batch 360/2221) Loss:8.50181770324707\n",
      "epoch:12 batch 370/2221) Loss:7.362646102905273\n",
      "epoch:12 batch 380/2221) Loss:31.21866798400879\n",
      "epoch:12 batch 390/2221) Loss:40.99227523803711\n",
      "epoch:12 batch 400/2221) Loss:10.335469245910645\n",
      "epoch:12 batch 410/2221) Loss:22.646390914916992\n",
      "epoch:12 batch 420/2221) Loss:9.628206253051758\n",
      "epoch:12 batch 430/2221) Loss:13.102510452270508\n",
      "epoch:12 batch 440/2221) Loss:20.430299758911133\n",
      "epoch:12 batch 450/2221) Loss:11.48440933227539\n",
      "epoch:12 batch 460/2221) Loss:15.857833862304688\n",
      "epoch:12 batch 470/2221) Loss:14.961723327636719\n",
      "epoch:12 batch 480/2221) Loss:25.854219436645508\n",
      "epoch:12 batch 490/2221) Loss:47.583396911621094\n",
      "epoch:12 batch 500/2221) Loss:20.361209869384766\n",
      "epoch:12 batch 510/2221) Loss:15.617666244506836\n",
      "epoch:12 batch 520/2221) Loss:22.179506301879883\n",
      "epoch:12 batch 530/2221) Loss:11.978250503540039\n",
      "epoch:12 batch 540/2221) Loss:7.083103179931641\n",
      "epoch:12 batch 550/2221) Loss:20.68560028076172\n",
      "epoch:12 batch 560/2221) Loss:24.013442993164062\n",
      "epoch:12 batch 570/2221) Loss:15.799253463745117\n",
      "epoch:12 batch 580/2221) Loss:15.702108383178711\n",
      "epoch:12 batch 590/2221) Loss:17.60147476196289\n",
      "epoch:12 batch 600/2221) Loss:28.20169448852539\n",
      "epoch:12 batch 610/2221) Loss:23.795812606811523\n",
      "epoch:12 batch 620/2221) Loss:15.742595672607422\n",
      "epoch:12 batch 630/2221) Loss:19.18093490600586\n",
      "epoch:12 batch 640/2221) Loss:31.12007713317871\n",
      "epoch:12 batch 650/2221) Loss:10.717611312866211\n",
      "epoch:12 batch 660/2221) Loss:12.641044616699219\n",
      "epoch:12 batch 670/2221) Loss:31.446929931640625\n",
      "epoch:12 batch 680/2221) Loss:21.20918846130371\n",
      "epoch:12 batch 690/2221) Loss:12.854455947875977\n",
      "epoch:12 batch 700/2221) Loss:2.875551223754883\n",
      "epoch:12 batch 710/2221) Loss:7.228109836578369\n",
      "epoch:12 batch 720/2221) Loss:15.750329971313477\n",
      "epoch:12 batch 730/2221) Loss:22.1527099609375\n",
      "epoch:12 batch 740/2221) Loss:36.079071044921875\n",
      "epoch:12 batch 750/2221) Loss:23.223703384399414\n",
      "epoch:12 batch 760/2221) Loss:26.789560317993164\n",
      "epoch:12 batch 770/2221) Loss:23.234771728515625\n",
      "epoch:12 batch 780/2221) Loss:28.123695373535156\n",
      "epoch:12 batch 790/2221) Loss:16.031890869140625\n",
      "epoch:12 batch 800/2221) Loss:3.982389450073242\n",
      "epoch:12 batch 810/2221) Loss:1.3448238372802734\n",
      "epoch:12 batch 820/2221) Loss:13.318115234375\n",
      "epoch:12 batch 830/2221) Loss:14.127910614013672\n",
      "epoch:12 batch 840/2221) Loss:14.062723159790039\n",
      "epoch:12 batch 850/2221) Loss:10.177186965942383\n",
      "epoch:12 batch 860/2221) Loss:12.247980117797852\n",
      "epoch:12 batch 870/2221) Loss:22.67517852783203\n",
      "epoch:12 batch 880/2221) Loss:5.411489486694336\n",
      "epoch:12 batch 890/2221) Loss:9.582633972167969\n",
      "epoch:12 batch 900/2221) Loss:14.20897102355957\n",
      "epoch:12 batch 910/2221) Loss:56.69630432128906\n",
      "epoch:12 batch 920/2221) Loss:54.30318069458008\n",
      "epoch:12 batch 930/2221) Loss:59.6460075378418\n",
      "epoch:12 batch 940/2221) Loss:18.47943878173828\n",
      "epoch:12 batch 950/2221) Loss:5.273377418518066\n",
      "epoch:12 batch 960/2221) Loss:14.906007766723633\n",
      "epoch:12 batch 970/2221) Loss:4.072748184204102\n",
      "epoch:12 batch 980/2221) Loss:17.526824951171875\n",
      "epoch:12 batch 990/2221) Loss:21.63233184814453\n",
      "epoch:12 batch 1000/2221) Loss:13.932266235351562\n",
      "epoch:12 batch 1010/2221) Loss:39.102962493896484\n",
      "epoch:12 batch 1020/2221) Loss:28.845731735229492\n",
      "epoch:12 batch 1030/2221) Loss:23.703678131103516\n",
      "epoch:12 batch 1040/2221) Loss:13.077201843261719\n",
      "epoch:12 batch 1050/2221) Loss:17.041486740112305\n",
      "epoch:12 batch 1060/2221) Loss:1.491312026977539\n",
      "epoch:12 batch 1070/2221) Loss:9.566728591918945\n",
      "epoch:12 batch 1080/2221) Loss:33.31153869628906\n",
      "epoch:12 batch 1090/2221) Loss:24.618732452392578\n",
      "epoch:12 batch 1100/2221) Loss:23.151594161987305\n",
      "epoch:12 batch 1110/2221) Loss:24.542978286743164\n",
      "epoch:12 batch 1120/2221) Loss:14.992496490478516\n",
      "epoch:12 batch 1130/2221) Loss:11.758245468139648\n",
      "epoch:12 batch 1140/2221) Loss:23.450584411621094\n",
      "epoch:12 batch 1150/2221) Loss:7.537811279296875\n",
      "epoch:12 batch 1160/2221) Loss:30.789663314819336\n",
      "epoch:12 batch 1170/2221) Loss:20.595922470092773\n",
      "epoch:12 batch 1180/2221) Loss:7.653951644897461\n",
      "epoch:12 batch 1190/2221) Loss:43.26511001586914\n",
      "epoch:12 batch 1200/2221) Loss:3.201841354370117\n",
      "epoch:12 batch 1210/2221) Loss:16.17959976196289\n",
      "epoch:12 batch 1220/2221) Loss:41.72230529785156\n",
      "epoch:12 batch 1230/2221) Loss:15.600753784179688\n",
      "epoch:12 batch 1240/2221) Loss:12.994976043701172\n",
      "epoch:12 batch 1250/2221) Loss:14.119094848632812\n",
      "epoch:12 batch 1260/2221) Loss:22.63251495361328\n",
      "epoch:12 batch 1270/2221) Loss:14.275896072387695\n",
      "epoch:12 batch 1280/2221) Loss:12.639217376708984\n",
      "epoch:12 batch 1290/2221) Loss:6.072055816650391\n",
      "epoch:12 batch 1300/2221) Loss:11.695066452026367\n",
      "epoch:12 batch 1310/2221) Loss:19.297691345214844\n",
      "epoch:12 batch 1320/2221) Loss:12.724004745483398\n",
      "epoch:12 batch 1330/2221) Loss:14.6050386428833\n",
      "epoch:12 batch 1340/2221) Loss:7.840343475341797\n",
      "epoch:12 batch 1350/2221) Loss:27.831039428710938\n",
      "epoch:12 batch 1360/2221) Loss:18.49127769470215\n",
      "epoch:12 batch 1370/2221) Loss:20.40098762512207\n",
      "epoch:12 batch 1380/2221) Loss:13.75340461730957\n",
      "epoch:12 batch 1390/2221) Loss:8.698698043823242\n",
      "epoch:12 batch 1400/2221) Loss:12.934829711914062\n",
      "epoch:12 batch 1410/2221) Loss:18.61163902282715\n",
      "epoch:12 batch 1420/2221) Loss:19.69772720336914\n",
      "epoch:12 batch 1430/2221) Loss:3.9072723388671875\n",
      "epoch:12 batch 1440/2221) Loss:21.65252113342285\n",
      "epoch:12 batch 1450/2221) Loss:16.681045532226562\n",
      "epoch:12 batch 1460/2221) Loss:19.570634841918945\n",
      "epoch:12 batch 1470/2221) Loss:12.027381896972656\n",
      "epoch:12 batch 1480/2221) Loss:8.868602752685547\n",
      "epoch:12 batch 1490/2221) Loss:56.240234375\n",
      "epoch:12 batch 1500/2221) Loss:5.619010925292969\n",
      "epoch:12 batch 1510/2221) Loss:16.90023422241211\n",
      "epoch:12 batch 1520/2221) Loss:26.841020584106445\n",
      "epoch:12 batch 1530/2221) Loss:18.576913833618164\n",
      "epoch:12 batch 1540/2221) Loss:5.675233840942383\n",
      "epoch:12 batch 1550/2221) Loss:8.59451675415039\n",
      "epoch:12 batch 1560/2221) Loss:17.318105697631836\n",
      "epoch:12 batch 1570/2221) Loss:10.17536735534668\n",
      "epoch:12 batch 1580/2221) Loss:15.617144584655762\n",
      "epoch:12 batch 1590/2221) Loss:7.314184188842773\n",
      "epoch:12 batch 1600/2221) Loss:22.404176712036133\n",
      "epoch:12 batch 1610/2221) Loss:14.326576232910156\n",
      "epoch:12 batch 1620/2221) Loss:30.964962005615234\n",
      "epoch:12 batch 1630/2221) Loss:26.96578598022461\n",
      "epoch:12 batch 1640/2221) Loss:17.170053482055664\n",
      "epoch:12 batch 1650/2221) Loss:39.38134002685547\n",
      "epoch:12 batch 1660/2221) Loss:12.59766960144043\n",
      "epoch:12 batch 1670/2221) Loss:48.64406967163086\n",
      "epoch:12 batch 1680/2221) Loss:16.995140075683594\n",
      "epoch:12 batch 1690/2221) Loss:17.887056350708008\n",
      "epoch:12 batch 1700/2221) Loss:22.589035034179688\n",
      "epoch:12 batch 1710/2221) Loss:19.264219284057617\n",
      "epoch:12 batch 1720/2221) Loss:9.604715347290039\n",
      "epoch:12 batch 1730/2221) Loss:3.7524852752685547\n",
      "epoch:12 batch 1740/2221) Loss:4.425954818725586\n",
      "epoch:12 batch 1750/2221) Loss:36.6681022644043\n",
      "epoch:12 batch 1760/2221) Loss:10.187275886535645\n",
      "epoch:12 batch 1770/2221) Loss:35.48507308959961\n",
      "epoch:12 batch 1780/2221) Loss:11.781135559082031\n",
      "epoch:12 batch 1790/2221) Loss:12.221724510192871\n",
      "epoch:12 batch 1800/2221) Loss:22.581806182861328\n",
      "epoch:12 batch 1810/2221) Loss:16.803415298461914\n",
      "epoch:12 batch 1820/2221) Loss:16.235166549682617\n",
      "epoch:12 batch 1830/2221) Loss:23.894655227661133\n",
      "epoch:12 batch 1840/2221) Loss:5.465274810791016\n",
      "epoch:12 batch 1850/2221) Loss:18.019062042236328\n",
      "epoch:12 batch 1860/2221) Loss:10.744545936584473\n",
      "epoch:12 batch 1870/2221) Loss:68.59793090820312\n",
      "epoch:12 batch 1880/2221) Loss:7.376490592956543\n",
      "epoch:12 batch 1890/2221) Loss:35.808074951171875\n",
      "epoch:12 batch 1900/2221) Loss:20.600257873535156\n",
      "epoch:12 batch 1910/2221) Loss:10.626319885253906\n",
      "epoch:12 batch 1920/2221) Loss:12.883604049682617\n",
      "epoch:12 batch 1930/2221) Loss:14.686234474182129\n",
      "epoch:12 batch 1940/2221) Loss:9.78732681274414\n",
      "epoch:12 batch 1950/2221) Loss:18.733579635620117\n",
      "epoch:12 batch 1960/2221) Loss:20.83235740661621\n",
      "epoch:12 batch 1970/2221) Loss:4.0737457275390625\n",
      "epoch:12 batch 1980/2221) Loss:7.247642517089844\n",
      "epoch:12 batch 1990/2221) Loss:19.1014404296875\n",
      "epoch:12 batch 2000/2221) Loss:27.559152603149414\n",
      "epoch:12 batch 2010/2221) Loss:15.901052474975586\n",
      "epoch:12 batch 2020/2221) Loss:3.960407257080078\n",
      "epoch:12 batch 2030/2221) Loss:10.697002410888672\n",
      "epoch:12 batch 2040/2221) Loss:23.59114646911621\n",
      "epoch:12 batch 2050/2221) Loss:25.441326141357422\n",
      "epoch:12 batch 2060/2221) Loss:18.09465980529785\n",
      "epoch:12 batch 2070/2221) Loss:21.246795654296875\n",
      "epoch:12 batch 2080/2221) Loss:16.24641227722168\n",
      "epoch:12 batch 2090/2221) Loss:15.055368423461914\n",
      "epoch:12 batch 2100/2221) Loss:27.630849838256836\n",
      "epoch:12 batch 2110/2221) Loss:12.843814849853516\n",
      "epoch:12 batch 2120/2221) Loss:13.736968994140625\n",
      "epoch:12 batch 2130/2221) Loss:10.45193862915039\n",
      "epoch:12 batch 2140/2221) Loss:17.950439453125\n",
      "epoch:12 batch 2150/2221) Loss:14.649150848388672\n",
      "epoch:12 batch 2160/2221) Loss:22.453880310058594\n",
      "epoch:12 batch 2170/2221) Loss:12.983131408691406\n",
      "epoch:12 batch 2180/2221) Loss:17.90862274169922\n",
      "epoch:12 batch 2190/2221) Loss:17.726226806640625\n",
      "epoch:12 batch 2200/2221) Loss:6.50030517578125\n",
      "epoch:12 batch 2210/2221) Loss:3.0777626037597656\n",
      "epoch:12 batch 2220/2221) Loss:17.57723045349121\n",
      "epoch:12 precision:0.998592538190333 recall:0.9792603227410966 f1-score:0.9885304781260024\n",
      "epoch:13 batch 1/2221) Loss:13.7589693069458\n",
      "epoch:13 batch 10/2221) Loss:12.769533157348633\n",
      "epoch:13 batch 20/2221) Loss:32.460113525390625\n",
      "epoch:13 batch 30/2221) Loss:30.754777908325195\n",
      "epoch:13 batch 40/2221) Loss:3.624176025390625\n",
      "epoch:13 batch 50/2221) Loss:10.454946517944336\n",
      "epoch:13 batch 60/2221) Loss:45.33319854736328\n",
      "epoch:13 batch 70/2221) Loss:45.00157928466797\n",
      "epoch:13 batch 80/2221) Loss:15.347197532653809\n",
      "epoch:13 batch 90/2221) Loss:12.990968704223633\n",
      "epoch:13 batch 100/2221) Loss:4.842324256896973\n",
      "epoch:13 batch 110/2221) Loss:21.951507568359375\n",
      "epoch:13 batch 120/2221) Loss:20.31816291809082\n",
      "epoch:13 batch 130/2221) Loss:5.964217185974121\n",
      "epoch:13 batch 140/2221) Loss:7.615901947021484\n",
      "epoch:13 batch 150/2221) Loss:9.875526428222656\n",
      "epoch:13 batch 160/2221) Loss:12.494518280029297\n",
      "epoch:13 batch 170/2221) Loss:13.585895538330078\n",
      "epoch:13 batch 180/2221) Loss:16.40291976928711\n",
      "epoch:13 batch 190/2221) Loss:22.405826568603516\n",
      "epoch:13 batch 200/2221) Loss:16.786928176879883\n",
      "epoch:13 batch 210/2221) Loss:17.76787567138672\n",
      "epoch:13 batch 220/2221) Loss:13.024505615234375\n",
      "epoch:13 batch 230/2221) Loss:18.25883674621582\n",
      "epoch:13 batch 240/2221) Loss:20.001893997192383\n",
      "epoch:13 batch 250/2221) Loss:19.111011505126953\n",
      "epoch:13 batch 260/2221) Loss:12.668596267700195\n",
      "epoch:13 batch 270/2221) Loss:4.495580673217773\n",
      "epoch:13 batch 280/2221) Loss:23.81315803527832\n",
      "epoch:13 batch 290/2221) Loss:11.33260726928711\n",
      "epoch:13 batch 300/2221) Loss:1.4585371017456055\n",
      "epoch:13 batch 310/2221) Loss:12.512837409973145\n",
      "epoch:13 batch 320/2221) Loss:29.097463607788086\n",
      "epoch:13 batch 330/2221) Loss:21.440887451171875\n",
      "epoch:13 batch 340/2221) Loss:15.14726448059082\n",
      "epoch:13 batch 350/2221) Loss:29.502838134765625\n",
      "epoch:13 batch 360/2221) Loss:7.130840301513672\n",
      "epoch:13 batch 370/2221) Loss:26.628019332885742\n",
      "epoch:13 batch 380/2221) Loss:15.971124649047852\n",
      "epoch:13 batch 390/2221) Loss:11.081476211547852\n",
      "epoch:13 batch 400/2221) Loss:12.54293441772461\n",
      "epoch:13 batch 410/2221) Loss:17.84042739868164\n",
      "epoch:13 batch 420/2221) Loss:5.667079925537109\n",
      "epoch:13 batch 430/2221) Loss:22.618486404418945\n",
      "epoch:13 batch 440/2221) Loss:6.918937683105469\n",
      "epoch:13 batch 450/2221) Loss:10.562292098999023\n",
      "epoch:13 batch 460/2221) Loss:5.457574844360352\n",
      "epoch:13 batch 470/2221) Loss:71.69464111328125\n",
      "epoch:13 batch 480/2221) Loss:14.886646270751953\n",
      "epoch:13 batch 490/2221) Loss:4.268872261047363\n",
      "epoch:13 batch 500/2221) Loss:15.309015274047852\n",
      "epoch:13 batch 510/2221) Loss:52.419490814208984\n",
      "epoch:13 batch 520/2221) Loss:21.602489471435547\n",
      "epoch:13 batch 530/2221) Loss:19.43415069580078\n",
      "epoch:13 batch 540/2221) Loss:15.125288009643555\n",
      "epoch:13 batch 550/2221) Loss:16.439199447631836\n",
      "epoch:13 batch 560/2221) Loss:5.519620895385742\n",
      "epoch:13 batch 570/2221) Loss:12.439643859863281\n",
      "epoch:13 batch 580/2221) Loss:16.73647117614746\n",
      "epoch:13 batch 590/2221) Loss:11.032550811767578\n",
      "epoch:13 batch 600/2221) Loss:38.78340148925781\n",
      "epoch:13 batch 610/2221) Loss:11.953500747680664\n",
      "epoch:13 batch 620/2221) Loss:51.564300537109375\n",
      "epoch:13 batch 630/2221) Loss:27.267122268676758\n",
      "epoch:13 batch 640/2221) Loss:25.554704666137695\n",
      "epoch:13 batch 650/2221) Loss:16.067747116088867\n",
      "epoch:13 batch 660/2221) Loss:28.451805114746094\n",
      "epoch:13 batch 670/2221) Loss:21.40731430053711\n",
      "epoch:13 batch 680/2221) Loss:40.74518585205078\n",
      "epoch:13 batch 690/2221) Loss:45.037208557128906\n",
      "epoch:13 batch 700/2221) Loss:11.264963150024414\n",
      "epoch:13 batch 710/2221) Loss:6.131614685058594\n",
      "epoch:13 batch 720/2221) Loss:14.3328857421875\n",
      "epoch:13 batch 730/2221) Loss:19.94159698486328\n",
      "epoch:13 batch 740/2221) Loss:27.42898941040039\n",
      "epoch:13 batch 750/2221) Loss:3.2630062103271484\n",
      "epoch:13 batch 760/2221) Loss:27.097442626953125\n",
      "epoch:13 batch 770/2221) Loss:5.735137939453125\n",
      "epoch:13 batch 780/2221) Loss:12.188065528869629\n",
      "epoch:13 batch 790/2221) Loss:17.807233810424805\n",
      "epoch:13 batch 800/2221) Loss:8.51011848449707\n",
      "epoch:13 batch 810/2221) Loss:19.114755630493164\n",
      "epoch:13 batch 820/2221) Loss:16.693939208984375\n",
      "epoch:13 batch 830/2221) Loss:18.655717849731445\n",
      "epoch:13 batch 840/2221) Loss:5.698427200317383\n",
      "epoch:13 batch 850/2221) Loss:10.264310836791992\n",
      "epoch:13 batch 860/2221) Loss:21.754993438720703\n",
      "epoch:13 batch 870/2221) Loss:11.249975204467773\n",
      "epoch:13 batch 880/2221) Loss:33.62261199951172\n",
      "epoch:13 batch 890/2221) Loss:20.88423728942871\n",
      "epoch:13 batch 900/2221) Loss:25.9930477142334\n",
      "epoch:13 batch 910/2221) Loss:8.122257232666016\n",
      "epoch:13 batch 920/2221) Loss:3.6166114807128906\n",
      "epoch:13 batch 930/2221) Loss:10.341459274291992\n",
      "epoch:13 batch 940/2221) Loss:9.544139862060547\n",
      "epoch:13 batch 950/2221) Loss:21.532506942749023\n",
      "epoch:13 batch 960/2221) Loss:8.40487289428711\n",
      "epoch:13 batch 970/2221) Loss:7.280860900878906\n",
      "epoch:13 batch 980/2221) Loss:11.942642211914062\n",
      "epoch:13 batch 990/2221) Loss:27.152690887451172\n",
      "epoch:13 batch 1000/2221) Loss:12.959429740905762\n",
      "epoch:13 batch 1010/2221) Loss:2.0484371185302734\n",
      "epoch:13 batch 1020/2221) Loss:30.648576736450195\n",
      "epoch:13 batch 1030/2221) Loss:13.756427764892578\n",
      "epoch:13 batch 1040/2221) Loss:11.982332229614258\n",
      "epoch:13 batch 1050/2221) Loss:16.031984329223633\n",
      "epoch:13 batch 1060/2221) Loss:5.144868850708008\n",
      "epoch:13 batch 1070/2221) Loss:24.582542419433594\n",
      "epoch:13 batch 1080/2221) Loss:11.312549591064453\n",
      "epoch:13 batch 1090/2221) Loss:16.498855590820312\n",
      "epoch:13 batch 1100/2221) Loss:9.515233039855957\n",
      "epoch:13 batch 1110/2221) Loss:26.756994247436523\n",
      "epoch:13 batch 1120/2221) Loss:10.676229476928711\n",
      "epoch:13 batch 1130/2221) Loss:13.722623825073242\n",
      "epoch:13 batch 1140/2221) Loss:13.700685501098633\n",
      "epoch:13 batch 1150/2221) Loss:20.773422241210938\n",
      "epoch:13 batch 1160/2221) Loss:27.54074478149414\n",
      "epoch:13 batch 1170/2221) Loss:4.078245162963867\n",
      "epoch:13 batch 1180/2221) Loss:31.02668571472168\n",
      "epoch:13 batch 1190/2221) Loss:1.522726058959961\n",
      "epoch:13 batch 1200/2221) Loss:12.096647262573242\n",
      "epoch:13 batch 1210/2221) Loss:1.4896020889282227\n",
      "epoch:13 batch 1220/2221) Loss:12.922685623168945\n",
      "epoch:13 batch 1230/2221) Loss:25.261735916137695\n",
      "epoch:13 batch 1240/2221) Loss:8.903658866882324\n",
      "epoch:13 batch 1250/2221) Loss:2.7032699584960938\n",
      "epoch:13 batch 1260/2221) Loss:16.04974365234375\n",
      "epoch:13 batch 1270/2221) Loss:18.994159698486328\n",
      "epoch:13 batch 1280/2221) Loss:5.186614990234375\n",
      "epoch:13 batch 1290/2221) Loss:37.23550796508789\n",
      "epoch:13 batch 1300/2221) Loss:21.389183044433594\n",
      "epoch:13 batch 1310/2221) Loss:11.812759399414062\n",
      "epoch:13 batch 1320/2221) Loss:21.347747802734375\n",
      "epoch:13 batch 1330/2221) Loss:11.420196533203125\n",
      "epoch:13 batch 1340/2221) Loss:26.689741134643555\n",
      "epoch:13 batch 1350/2221) Loss:28.168460845947266\n",
      "epoch:13 batch 1360/2221) Loss:7.533836364746094\n",
      "epoch:13 batch 1370/2221) Loss:13.936600685119629\n",
      "epoch:13 batch 1380/2221) Loss:30.282711029052734\n",
      "epoch:13 batch 1390/2221) Loss:8.310352325439453\n",
      "epoch:13 batch 1400/2221) Loss:4.16209602355957\n",
      "epoch:13 batch 1410/2221) Loss:6.041042327880859\n",
      "epoch:13 batch 1420/2221) Loss:35.191043853759766\n",
      "epoch:13 batch 1430/2221) Loss:4.867254257202148\n",
      "epoch:13 batch 1440/2221) Loss:24.189104080200195\n",
      "epoch:13 batch 1450/2221) Loss:11.971336364746094\n",
      "epoch:13 batch 1460/2221) Loss:8.459344863891602\n",
      "epoch:13 batch 1470/2221) Loss:6.448275566101074\n",
      "epoch:13 batch 1480/2221) Loss:13.907489776611328\n",
      "epoch:13 batch 1490/2221) Loss:4.362726211547852\n",
      "epoch:13 batch 1500/2221) Loss:33.98937225341797\n",
      "epoch:13 batch 1510/2221) Loss:33.23261260986328\n",
      "epoch:13 batch 1520/2221) Loss:18.15949249267578\n",
      "epoch:13 batch 1530/2221) Loss:13.714259147644043\n",
      "epoch:13 batch 1540/2221) Loss:22.69782066345215\n",
      "epoch:13 batch 1550/2221) Loss:6.963083267211914\n",
      "epoch:13 batch 1560/2221) Loss:25.39113426208496\n",
      "epoch:13 batch 1570/2221) Loss:16.70716094970703\n",
      "epoch:13 batch 1580/2221) Loss:26.355268478393555\n",
      "epoch:13 batch 1590/2221) Loss:12.032601356506348\n",
      "epoch:13 batch 1600/2221) Loss:20.366928100585938\n",
      "epoch:13 batch 1610/2221) Loss:16.689727783203125\n",
      "epoch:13 batch 1620/2221) Loss:12.547491073608398\n",
      "epoch:13 batch 1630/2221) Loss:17.238767623901367\n",
      "epoch:13 batch 1640/2221) Loss:12.218027114868164\n",
      "epoch:13 batch 1650/2221) Loss:19.667984008789062\n",
      "epoch:13 batch 1660/2221) Loss:12.767793655395508\n",
      "epoch:13 batch 1670/2221) Loss:13.69389820098877\n",
      "epoch:13 batch 1680/2221) Loss:24.36145782470703\n",
      "epoch:13 batch 1690/2221) Loss:8.734670639038086\n",
      "epoch:13 batch 1700/2221) Loss:5.7684173583984375\n",
      "epoch:13 batch 1710/2221) Loss:4.546087265014648\n",
      "epoch:13 batch 1720/2221) Loss:12.442001342773438\n",
      "epoch:13 batch 1730/2221) Loss:15.563091278076172\n",
      "epoch:13 batch 1740/2221) Loss:32.07737731933594\n",
      "epoch:13 batch 1750/2221) Loss:11.471059799194336\n",
      "epoch:13 batch 1760/2221) Loss:10.350442886352539\n",
      "epoch:13 batch 1770/2221) Loss:33.242652893066406\n",
      "epoch:13 batch 1780/2221) Loss:23.182275772094727\n",
      "epoch:13 batch 1790/2221) Loss:14.392480850219727\n",
      "epoch:13 batch 1800/2221) Loss:14.921191215515137\n",
      "epoch:13 batch 1810/2221) Loss:15.402824401855469\n",
      "epoch:13 batch 1820/2221) Loss:11.233526229858398\n",
      "epoch:13 batch 1830/2221) Loss:8.463556289672852\n",
      "epoch:13 batch 1840/2221) Loss:7.39260196685791\n",
      "epoch:13 batch 1850/2221) Loss:19.73491668701172\n",
      "epoch:13 batch 1860/2221) Loss:16.70243263244629\n",
      "epoch:13 batch 1870/2221) Loss:11.626771926879883\n",
      "epoch:13 batch 1880/2221) Loss:15.374359130859375\n",
      "epoch:13 batch 1890/2221) Loss:12.974637985229492\n",
      "epoch:13 batch 1900/2221) Loss:3.2314014434814453\n",
      "epoch:13 batch 1910/2221) Loss:31.419748306274414\n",
      "epoch:13 batch 1920/2221) Loss:1.670236587524414\n",
      "epoch:13 batch 1930/2221) Loss:7.12949275970459\n",
      "epoch:13 batch 1940/2221) Loss:26.895389556884766\n",
      "epoch:13 batch 1950/2221) Loss:15.43303394317627\n",
      "epoch:13 batch 1960/2221) Loss:27.74148941040039\n",
      "epoch:13 batch 1970/2221) Loss:29.028907775878906\n",
      "epoch:13 batch 1980/2221) Loss:8.40650749206543\n",
      "epoch:13 batch 1990/2221) Loss:9.116140365600586\n",
      "epoch:13 batch 2000/2221) Loss:24.713090896606445\n",
      "epoch:13 batch 2010/2221) Loss:22.703248977661133\n",
      "epoch:13 batch 2020/2221) Loss:7.164769172668457\n",
      "epoch:13 batch 2030/2221) Loss:5.3431806564331055\n",
      "epoch:13 batch 2040/2221) Loss:26.8076171875\n",
      "epoch:13 batch 2050/2221) Loss:17.8002872467041\n",
      "epoch:13 batch 2060/2221) Loss:22.291492462158203\n",
      "epoch:13 batch 2070/2221) Loss:15.853673934936523\n",
      "epoch:13 batch 2080/2221) Loss:11.568461418151855\n",
      "epoch:13 batch 2090/2221) Loss:15.725756645202637\n",
      "epoch:13 batch 2100/2221) Loss:22.378076553344727\n",
      "epoch:13 batch 2110/2221) Loss:29.113008499145508\n",
      "epoch:13 batch 2120/2221) Loss:9.366573333740234\n",
      "epoch:13 batch 2130/2221) Loss:7.126043319702148\n",
      "epoch:13 batch 2140/2221) Loss:14.56454849243164\n",
      "epoch:13 batch 2150/2221) Loss:16.47928237915039\n",
      "epoch:13 batch 2160/2221) Loss:10.529459953308105\n",
      "epoch:13 batch 2170/2221) Loss:16.673416137695312\n",
      "epoch:13 batch 2180/2221) Loss:2.6447677612304688\n",
      "epoch:13 batch 2190/2221) Loss:15.00699234008789\n",
      "epoch:13 batch 2200/2221) Loss:13.58416748046875\n",
      "epoch:13 batch 2210/2221) Loss:20.201932907104492\n",
      "epoch:13 batch 2220/2221) Loss:2.3587026596069336\n",
      "epoch:13 precision:0.9977120811482384 recall:0.9813694969400827 f1-score:0.9891896698666341\n",
      "epoch:14 batch 1/2221) Loss:22.571487426757812\n",
      "epoch:14 batch 10/2221) Loss:7.956001281738281\n",
      "epoch:14 batch 20/2221) Loss:13.928130149841309\n",
      "epoch:14 batch 30/2221) Loss:19.33847427368164\n",
      "epoch:14 batch 40/2221) Loss:19.632423400878906\n",
      "epoch:14 batch 50/2221) Loss:11.895645141601562\n",
      "epoch:14 batch 60/2221) Loss:14.223604202270508\n",
      "epoch:14 batch 70/2221) Loss:2.320150375366211\n",
      "epoch:14 batch 80/2221) Loss:13.854415893554688\n",
      "epoch:14 batch 90/2221) Loss:9.687308311462402\n",
      "epoch:14 batch 100/2221) Loss:22.303119659423828\n",
      "epoch:14 batch 110/2221) Loss:13.904022216796875\n",
      "epoch:14 batch 120/2221) Loss:19.301191329956055\n",
      "epoch:14 batch 130/2221) Loss:4.011761665344238\n",
      "epoch:14 batch 140/2221) Loss:3.070254325866699\n",
      "epoch:14 batch 150/2221) Loss:38.226806640625\n",
      "epoch:14 batch 160/2221) Loss:3.764659881591797\n",
      "epoch:14 batch 170/2221) Loss:12.48781681060791\n",
      "epoch:14 batch 180/2221) Loss:5.897153854370117\n",
      "epoch:14 batch 190/2221) Loss:30.98489761352539\n",
      "epoch:14 batch 200/2221) Loss:37.606834411621094\n",
      "epoch:14 batch 210/2221) Loss:19.195068359375\n",
      "epoch:14 batch 220/2221) Loss:4.394750595092773\n",
      "epoch:14 batch 230/2221) Loss:25.03144073486328\n",
      "epoch:14 batch 240/2221) Loss:14.395394325256348\n",
      "epoch:14 batch 250/2221) Loss:25.464252471923828\n",
      "epoch:14 batch 260/2221) Loss:30.448787689208984\n",
      "epoch:14 batch 270/2221) Loss:16.009246826171875\n",
      "epoch:14 batch 280/2221) Loss:9.0240478515625\n",
      "epoch:14 batch 290/2221) Loss:30.924488067626953\n",
      "epoch:14 batch 300/2221) Loss:17.303157806396484\n",
      "epoch:14 batch 310/2221) Loss:35.8352165222168\n",
      "epoch:14 batch 320/2221) Loss:4.91823673248291\n",
      "epoch:14 batch 330/2221) Loss:10.294609069824219\n",
      "epoch:14 batch 340/2221) Loss:8.686281204223633\n",
      "epoch:14 batch 350/2221) Loss:6.813320159912109\n",
      "epoch:14 batch 360/2221) Loss:16.196514129638672\n",
      "epoch:14 batch 370/2221) Loss:5.427417755126953\n",
      "epoch:14 batch 380/2221) Loss:9.996146202087402\n",
      "epoch:14 batch 390/2221) Loss:21.827272415161133\n",
      "epoch:14 batch 400/2221) Loss:29.251708984375\n",
      "epoch:14 batch 410/2221) Loss:4.644265174865723\n",
      "epoch:14 batch 420/2221) Loss:1.2082757949829102\n",
      "epoch:14 batch 430/2221) Loss:7.880854606628418\n",
      "epoch:14 batch 440/2221) Loss:14.606195449829102\n",
      "epoch:14 batch 450/2221) Loss:31.1246280670166\n",
      "epoch:14 batch 460/2221) Loss:10.40776252746582\n",
      "epoch:14 batch 470/2221) Loss:14.114517211914062\n",
      "epoch:14 batch 480/2221) Loss:15.004203796386719\n",
      "epoch:14 batch 490/2221) Loss:11.512720108032227\n",
      "epoch:14 batch 500/2221) Loss:2.9714412689208984\n",
      "epoch:14 batch 510/2221) Loss:4.584980010986328\n",
      "epoch:14 batch 520/2221) Loss:25.29141616821289\n",
      "epoch:14 batch 530/2221) Loss:5.337728500366211\n",
      "epoch:14 batch 540/2221) Loss:9.883867263793945\n",
      "epoch:14 batch 550/2221) Loss:11.588354110717773\n",
      "epoch:14 batch 560/2221) Loss:42.48323059082031\n",
      "epoch:14 batch 570/2221) Loss:14.380026817321777\n",
      "epoch:14 batch 580/2221) Loss:19.563491821289062\n",
      "epoch:14 batch 590/2221) Loss:24.839614868164062\n",
      "epoch:14 batch 600/2221) Loss:16.947067260742188\n",
      "epoch:14 batch 610/2221) Loss:19.607301712036133\n",
      "epoch:14 batch 620/2221) Loss:8.218990325927734\n",
      "epoch:14 batch 630/2221) Loss:18.749221801757812\n",
      "epoch:14 batch 640/2221) Loss:10.275283813476562\n",
      "epoch:14 batch 650/2221) Loss:37.856117248535156\n",
      "epoch:14 batch 660/2221) Loss:3.958078384399414\n",
      "epoch:14 batch 670/2221) Loss:8.163558006286621\n",
      "epoch:14 batch 680/2221) Loss:25.499467849731445\n",
      "epoch:14 batch 690/2221) Loss:7.071941375732422\n",
      "epoch:14 batch 700/2221) Loss:16.36758804321289\n",
      "epoch:14 batch 710/2221) Loss:37.17988586425781\n",
      "epoch:14 batch 720/2221) Loss:7.901981353759766\n",
      "epoch:14 batch 730/2221) Loss:15.361967086791992\n",
      "epoch:14 batch 740/2221) Loss:9.924680709838867\n",
      "epoch:14 batch 750/2221) Loss:7.411252021789551\n",
      "epoch:14 batch 760/2221) Loss:23.085411071777344\n",
      "epoch:14 batch 770/2221) Loss:25.87299919128418\n",
      "epoch:14 batch 780/2221) Loss:13.375513076782227\n",
      "epoch:14 batch 790/2221) Loss:8.53375244140625\n",
      "epoch:14 batch 800/2221) Loss:18.09271240234375\n",
      "epoch:14 batch 810/2221) Loss:8.292418479919434\n",
      "epoch:14 batch 820/2221) Loss:9.670377731323242\n",
      "epoch:14 batch 830/2221) Loss:3.5904808044433594\n",
      "epoch:14 batch 840/2221) Loss:21.31142807006836\n",
      "epoch:14 batch 850/2221) Loss:19.663211822509766\n",
      "epoch:14 batch 860/2221) Loss:17.845834732055664\n",
      "epoch:14 batch 870/2221) Loss:11.768173217773438\n",
      "epoch:14 batch 880/2221) Loss:6.2622880935668945\n",
      "epoch:14 batch 890/2221) Loss:21.744699478149414\n",
      "epoch:14 batch 900/2221) Loss:7.997356414794922\n",
      "epoch:14 batch 910/2221) Loss:23.681209564208984\n",
      "epoch:14 batch 920/2221) Loss:10.295339584350586\n",
      "epoch:14 batch 930/2221) Loss:22.073078155517578\n",
      "epoch:14 batch 940/2221) Loss:11.86761474609375\n",
      "epoch:14 batch 950/2221) Loss:18.253355026245117\n",
      "epoch:14 batch 960/2221) Loss:19.308156967163086\n",
      "epoch:14 batch 970/2221) Loss:13.682600975036621\n",
      "epoch:14 batch 980/2221) Loss:13.79704475402832\n",
      "epoch:14 batch 990/2221) Loss:14.792557716369629\n",
      "epoch:14 batch 1000/2221) Loss:25.835737228393555\n",
      "epoch:14 batch 1010/2221) Loss:18.361682891845703\n",
      "epoch:14 batch 1020/2221) Loss:28.401771545410156\n",
      "epoch:14 batch 1030/2221) Loss:8.544296264648438\n",
      "epoch:14 batch 1040/2221) Loss:7.112081527709961\n",
      "epoch:14 batch 1050/2221) Loss:3.8528594970703125\n",
      "epoch:14 batch 1060/2221) Loss:18.546466827392578\n",
      "epoch:14 batch 1070/2221) Loss:9.30427360534668\n",
      "epoch:14 batch 1080/2221) Loss:16.919898986816406\n",
      "epoch:14 batch 1090/2221) Loss:21.097370147705078\n",
      "epoch:14 batch 1100/2221) Loss:14.393017768859863\n",
      "epoch:14 batch 1110/2221) Loss:14.98477840423584\n",
      "epoch:14 batch 1120/2221) Loss:41.75925827026367\n",
      "epoch:14 batch 1130/2221) Loss:11.134923934936523\n",
      "epoch:14 batch 1140/2221) Loss:26.40502166748047\n",
      "epoch:14 batch 1150/2221) Loss:5.197879791259766\n",
      "epoch:14 batch 1160/2221) Loss:23.96289825439453\n",
      "epoch:14 batch 1170/2221) Loss:11.87767219543457\n",
      "epoch:14 batch 1180/2221) Loss:9.3659029006958\n",
      "epoch:14 batch 1190/2221) Loss:8.918364524841309\n",
      "epoch:14 batch 1200/2221) Loss:8.848578453063965\n",
      "epoch:14 batch 1210/2221) Loss:13.505152702331543\n",
      "epoch:14 batch 1220/2221) Loss:24.506576538085938\n",
      "epoch:14 batch 1230/2221) Loss:18.494213104248047\n",
      "epoch:14 batch 1240/2221) Loss:12.73514461517334\n",
      "epoch:14 batch 1250/2221) Loss:8.697604179382324\n",
      "epoch:14 batch 1260/2221) Loss:13.973234176635742\n",
      "epoch:14 batch 1270/2221) Loss:18.520370483398438\n",
      "epoch:14 batch 1280/2221) Loss:22.982213973999023\n",
      "epoch:14 batch 1290/2221) Loss:13.959627151489258\n",
      "epoch:14 batch 1300/2221) Loss:13.313861846923828\n",
      "epoch:14 batch 1310/2221) Loss:41.93293762207031\n",
      "epoch:14 batch 1320/2221) Loss:16.99334144592285\n",
      "epoch:14 batch 1330/2221) Loss:14.69571304321289\n",
      "epoch:14 batch 1340/2221) Loss:21.523557662963867\n",
      "epoch:14 batch 1350/2221) Loss:27.814712524414062\n",
      "epoch:14 batch 1360/2221) Loss:19.160491943359375\n",
      "epoch:14 batch 1370/2221) Loss:13.610526084899902\n",
      "epoch:14 batch 1380/2221) Loss:33.53436279296875\n",
      "epoch:14 batch 1390/2221) Loss:18.026399612426758\n",
      "epoch:14 batch 1400/2221) Loss:5.220677375793457\n",
      "epoch:14 batch 1410/2221) Loss:17.644813537597656\n",
      "epoch:14 batch 1420/2221) Loss:10.679608345031738\n",
      "epoch:14 batch 1430/2221) Loss:24.206851959228516\n",
      "epoch:14 batch 1440/2221) Loss:7.880196571350098\n",
      "epoch:14 batch 1450/2221) Loss:14.43637466430664\n",
      "epoch:14 batch 1460/2221) Loss:11.006070137023926\n",
      "epoch:14 batch 1470/2221) Loss:5.939095497131348\n",
      "epoch:14 batch 1480/2221) Loss:29.725358963012695\n",
      "epoch:14 batch 1490/2221) Loss:14.918527603149414\n",
      "epoch:14 batch 1500/2221) Loss:6.504583358764648\n",
      "epoch:14 batch 1510/2221) Loss:6.695996284484863\n",
      "epoch:14 batch 1520/2221) Loss:15.959284782409668\n",
      "epoch:14 batch 1530/2221) Loss:30.19950294494629\n",
      "epoch:14 batch 1540/2221) Loss:6.252995491027832\n",
      "epoch:14 batch 1550/2221) Loss:10.054601669311523\n",
      "epoch:14 batch 1560/2221) Loss:13.024925231933594\n",
      "epoch:14 batch 1570/2221) Loss:18.00928497314453\n",
      "epoch:14 batch 1580/2221) Loss:8.680109024047852\n",
      "epoch:14 batch 1590/2221) Loss:11.367289543151855\n",
      "epoch:14 batch 1600/2221) Loss:2.109273910522461\n",
      "epoch:14 batch 1610/2221) Loss:12.628194808959961\n",
      "epoch:14 batch 1620/2221) Loss:9.708904266357422\n",
      "epoch:14 batch 1630/2221) Loss:9.137104988098145\n",
      "epoch:14 batch 1640/2221) Loss:31.520437240600586\n",
      "epoch:14 batch 1650/2221) Loss:26.520843505859375\n",
      "epoch:14 batch 1660/2221) Loss:17.908672332763672\n",
      "epoch:14 batch 1670/2221) Loss:19.12180519104004\n",
      "epoch:14 batch 1680/2221) Loss:14.709979057312012\n",
      "epoch:14 batch 1690/2221) Loss:8.541790962219238\n",
      "epoch:14 batch 1700/2221) Loss:21.8653621673584\n",
      "epoch:14 batch 1710/2221) Loss:24.02493667602539\n",
      "epoch:14 batch 1720/2221) Loss:19.836505889892578\n",
      "epoch:14 batch 1730/2221) Loss:5.86605167388916\n",
      "epoch:14 batch 1740/2221) Loss:23.586875915527344\n",
      "epoch:14 batch 1750/2221) Loss:17.644821166992188\n",
      "epoch:14 batch 1760/2221) Loss:3.6552839279174805\n",
      "epoch:14 batch 1770/2221) Loss:33.13789749145508\n",
      "epoch:14 batch 1780/2221) Loss:8.71231746673584\n",
      "epoch:14 batch 1790/2221) Loss:26.105485916137695\n",
      "epoch:14 batch 1800/2221) Loss:24.374731063842773\n",
      "epoch:14 batch 1810/2221) Loss:28.649991989135742\n",
      "epoch:14 batch 1820/2221) Loss:21.776660919189453\n",
      "epoch:14 batch 1830/2221) Loss:22.94666862487793\n",
      "epoch:14 batch 1840/2221) Loss:20.195022583007812\n",
      "epoch:14 batch 1850/2221) Loss:13.403749465942383\n",
      "epoch:14 batch 1860/2221) Loss:2.1010513305664062\n",
      "epoch:14 batch 1870/2221) Loss:18.174331665039062\n",
      "epoch:14 batch 1880/2221) Loss:24.311134338378906\n",
      "epoch:14 batch 1890/2221) Loss:19.046579360961914\n",
      "epoch:14 batch 1900/2221) Loss:16.5081844329834\n",
      "epoch:14 batch 1910/2221) Loss:2.459331512451172\n",
      "epoch:14 batch 1920/2221) Loss:26.954120635986328\n",
      "epoch:14 batch 1930/2221) Loss:28.848506927490234\n",
      "epoch:14 batch 1940/2221) Loss:15.272843360900879\n",
      "epoch:14 batch 1950/2221) Loss:15.707267761230469\n",
      "epoch:14 batch 1960/2221) Loss:6.963132858276367\n",
      "epoch:14 batch 1970/2221) Loss:15.162008285522461\n",
      "epoch:14 batch 1980/2221) Loss:11.208698272705078\n",
      "epoch:14 batch 1990/2221) Loss:26.832111358642578\n",
      "epoch:14 batch 2000/2221) Loss:5.574673652648926\n",
      "epoch:14 batch 2010/2221) Loss:13.055790901184082\n",
      "epoch:14 batch 2020/2221) Loss:15.79064655303955\n",
      "epoch:14 batch 2030/2221) Loss:4.7597808837890625\n",
      "epoch:14 batch 2040/2221) Loss:34.92344284057617\n",
      "epoch:14 batch 2050/2221) Loss:9.296695709228516\n",
      "epoch:14 batch 2060/2221) Loss:12.714808464050293\n",
      "epoch:14 batch 2070/2221) Loss:2.029994010925293\n",
      "epoch:14 batch 2080/2221) Loss:12.527216911315918\n",
      "epoch:14 batch 2090/2221) Loss:13.3196382522583\n",
      "epoch:14 batch 2100/2221) Loss:21.864803314208984\n",
      "epoch:14 batch 2110/2221) Loss:3.812366485595703\n",
      "epoch:14 batch 2120/2221) Loss:23.907699584960938\n",
      "epoch:14 batch 2130/2221) Loss:17.34410858154297\n",
      "epoch:14 batch 2140/2221) Loss:18.10068130493164\n",
      "epoch:14 batch 2150/2221) Loss:7.876040458679199\n",
      "epoch:14 batch 2160/2221) Loss:2.2655935287475586\n",
      "epoch:14 batch 2170/2221) Loss:5.298620223999023\n",
      "epoch:14 batch 2180/2221) Loss:40.56806564331055\n",
      "epoch:14 batch 2190/2221) Loss:14.033933639526367\n",
      "epoch:14 batch 2200/2221) Loss:5.409454345703125\n",
      "epoch:14 batch 2210/2221) Loss:6.186491966247559\n",
      "epoch:14 batch 2220/2221) Loss:11.840015411376953\n",
      "epoch:14 precision:0.9963686778756468 recall:0.9829301106015171 f1-score:0.9894160368952761\n",
      "epoch:15 batch 1/2221) Loss:21.919471740722656\n",
      "epoch:15 batch 10/2221) Loss:21.065990447998047\n",
      "epoch:15 batch 20/2221) Loss:18.017898559570312\n",
      "epoch:15 batch 30/2221) Loss:13.194819450378418\n",
      "epoch:15 batch 40/2221) Loss:1.8748912811279297\n",
      "epoch:15 batch 50/2221) Loss:25.974712371826172\n",
      "epoch:15 batch 60/2221) Loss:13.553975105285645\n",
      "epoch:15 batch 70/2221) Loss:4.329442024230957\n",
      "epoch:15 batch 80/2221) Loss:5.778764724731445\n",
      "epoch:15 batch 90/2221) Loss:12.431465148925781\n",
      "epoch:15 batch 100/2221) Loss:7.508181571960449\n",
      "epoch:15 batch 110/2221) Loss:33.4602165222168\n",
      "epoch:15 batch 120/2221) Loss:19.66753387451172\n",
      "epoch:15 batch 130/2221) Loss:10.8176908493042\n",
      "epoch:15 batch 140/2221) Loss:8.524598121643066\n",
      "epoch:15 batch 150/2221) Loss:14.95882797241211\n",
      "epoch:15 batch 160/2221) Loss:13.759560585021973\n",
      "epoch:15 batch 170/2221) Loss:24.913148880004883\n",
      "epoch:15 batch 180/2221) Loss:8.385621070861816\n",
      "epoch:15 batch 190/2221) Loss:10.24468994140625\n",
      "epoch:15 batch 200/2221) Loss:19.133838653564453\n",
      "epoch:15 batch 210/2221) Loss:30.580181121826172\n",
      "epoch:15 batch 220/2221) Loss:16.73516273498535\n",
      "epoch:15 batch 230/2221) Loss:5.39031982421875\n",
      "epoch:15 batch 240/2221) Loss:1.5878925323486328\n",
      "epoch:15 batch 250/2221) Loss:13.20386028289795\n",
      "epoch:15 batch 260/2221) Loss:16.234922409057617\n",
      "epoch:15 batch 270/2221) Loss:12.51488971710205\n",
      "epoch:15 batch 280/2221) Loss:21.534631729125977\n",
      "epoch:15 batch 290/2221) Loss:8.86375904083252\n",
      "epoch:15 batch 300/2221) Loss:18.48680877685547\n",
      "epoch:15 batch 310/2221) Loss:13.444920539855957\n",
      "epoch:15 batch 320/2221) Loss:36.095848083496094\n",
      "epoch:15 batch 330/2221) Loss:8.469919204711914\n",
      "epoch:15 batch 340/2221) Loss:10.477638244628906\n",
      "epoch:15 batch 350/2221) Loss:6.338955879211426\n",
      "epoch:15 batch 360/2221) Loss:16.820945739746094\n",
      "epoch:15 batch 370/2221) Loss:23.099979400634766\n",
      "epoch:15 batch 380/2221) Loss:17.411090850830078\n",
      "epoch:15 batch 390/2221) Loss:8.764082908630371\n",
      "epoch:15 batch 400/2221) Loss:32.22864532470703\n",
      "epoch:15 batch 410/2221) Loss:12.218915939331055\n",
      "epoch:15 batch 420/2221) Loss:12.696745872497559\n",
      "epoch:15 batch 430/2221) Loss:10.110861778259277\n",
      "epoch:15 batch 440/2221) Loss:3.302382469177246\n",
      "epoch:15 batch 450/2221) Loss:17.20364761352539\n",
      "epoch:15 batch 460/2221) Loss:30.2188720703125\n",
      "epoch:15 batch 470/2221) Loss:26.82378387451172\n",
      "epoch:15 batch 480/2221) Loss:15.638153076171875\n",
      "epoch:15 batch 490/2221) Loss:31.51262664794922\n",
      "epoch:15 batch 500/2221) Loss:6.895717620849609\n",
      "epoch:15 batch 510/2221) Loss:26.462860107421875\n",
      "epoch:15 batch 520/2221) Loss:9.872010231018066\n",
      "epoch:15 batch 530/2221) Loss:4.2865190505981445\n",
      "epoch:15 batch 540/2221) Loss:21.043445587158203\n",
      "epoch:15 batch 550/2221) Loss:28.42416000366211\n",
      "epoch:15 batch 560/2221) Loss:5.740141868591309\n",
      "epoch:15 batch 570/2221) Loss:32.529293060302734\n",
      "epoch:15 batch 580/2221) Loss:11.115548133850098\n",
      "epoch:15 batch 590/2221) Loss:46.31137466430664\n",
      "epoch:15 batch 600/2221) Loss:29.409526824951172\n",
      "epoch:15 batch 610/2221) Loss:3.221057891845703\n",
      "epoch:15 batch 620/2221) Loss:25.40444564819336\n",
      "epoch:15 batch 630/2221) Loss:17.89093017578125\n",
      "epoch:15 batch 640/2221) Loss:9.607165336608887\n",
      "epoch:15 batch 650/2221) Loss:3.648556709289551\n",
      "epoch:15 batch 660/2221) Loss:22.46919059753418\n",
      "epoch:15 batch 670/2221) Loss:15.378238677978516\n",
      "epoch:15 batch 680/2221) Loss:5.1669464111328125\n",
      "epoch:15 batch 690/2221) Loss:8.14963150024414\n",
      "epoch:15 batch 700/2221) Loss:11.913435935974121\n",
      "epoch:15 batch 710/2221) Loss:37.39408874511719\n",
      "epoch:15 batch 720/2221) Loss:14.445561408996582\n",
      "epoch:15 batch 730/2221) Loss:29.753314971923828\n",
      "epoch:15 batch 740/2221) Loss:11.12757396697998\n",
      "epoch:15 batch 750/2221) Loss:24.956037521362305\n",
      "epoch:15 batch 760/2221) Loss:10.334029197692871\n",
      "epoch:15 batch 770/2221) Loss:10.158552169799805\n",
      "epoch:15 batch 780/2221) Loss:11.586313247680664\n",
      "epoch:15 batch 790/2221) Loss:2.830373764038086\n",
      "epoch:15 batch 800/2221) Loss:6.460763931274414\n",
      "epoch:15 batch 810/2221) Loss:23.61164665222168\n",
      "epoch:15 batch 820/2221) Loss:22.87115478515625\n",
      "epoch:15 batch 830/2221) Loss:29.30274200439453\n",
      "epoch:15 batch 840/2221) Loss:12.545462608337402\n",
      "epoch:15 batch 850/2221) Loss:15.483339309692383\n",
      "epoch:15 batch 860/2221) Loss:22.313655853271484\n",
      "epoch:15 batch 870/2221) Loss:3.4668960571289062\n",
      "epoch:15 batch 880/2221) Loss:10.464936256408691\n",
      "epoch:15 batch 890/2221) Loss:7.239023208618164\n",
      "epoch:15 batch 900/2221) Loss:3.869913101196289\n",
      "epoch:15 batch 910/2221) Loss:21.518173217773438\n",
      "epoch:15 batch 920/2221) Loss:8.574317932128906\n",
      "epoch:15 batch 930/2221) Loss:10.553202629089355\n",
      "epoch:15 batch 940/2221) Loss:2.914064407348633\n",
      "epoch:15 batch 950/2221) Loss:19.830852508544922\n",
      "epoch:15 batch 960/2221) Loss:6.656668663024902\n",
      "epoch:15 batch 970/2221) Loss:14.822975158691406\n",
      "epoch:15 batch 980/2221) Loss:2.031968116760254\n",
      "epoch:15 batch 990/2221) Loss:14.947731971740723\n",
      "epoch:15 batch 1000/2221) Loss:7.699861526489258\n",
      "epoch:15 batch 1010/2221) Loss:9.939409255981445\n",
      "epoch:15 batch 1020/2221) Loss:30.389610290527344\n",
      "epoch:15 batch 1030/2221) Loss:9.253000259399414\n",
      "epoch:15 batch 1040/2221) Loss:16.986385345458984\n",
      "epoch:15 batch 1050/2221) Loss:30.787405014038086\n",
      "epoch:15 batch 1060/2221) Loss:13.254066467285156\n",
      "epoch:15 batch 1070/2221) Loss:19.684444427490234\n",
      "epoch:15 batch 1080/2221) Loss:37.57329559326172\n",
      "epoch:15 batch 1090/2221) Loss:2.6335573196411133\n",
      "epoch:15 batch 1100/2221) Loss:38.42137145996094\n",
      "epoch:15 batch 1110/2221) Loss:16.382591247558594\n",
      "epoch:15 batch 1120/2221) Loss:10.218117713928223\n",
      "epoch:15 batch 1130/2221) Loss:46.038272857666016\n",
      "epoch:15 batch 1140/2221) Loss:6.677104949951172\n",
      "epoch:15 batch 1150/2221) Loss:28.571683883666992\n",
      "epoch:15 batch 1160/2221) Loss:21.125080108642578\n",
      "epoch:15 batch 1170/2221) Loss:15.088245391845703\n",
      "epoch:15 batch 1180/2221) Loss:13.934281349182129\n",
      "epoch:15 batch 1190/2221) Loss:9.455146789550781\n",
      "epoch:15 batch 1200/2221) Loss:9.247631072998047\n",
      "epoch:15 batch 1210/2221) Loss:2.2466611862182617\n",
      "epoch:15 batch 1220/2221) Loss:2.6809892654418945\n",
      "epoch:15 batch 1230/2221) Loss:20.070606231689453\n",
      "epoch:15 batch 1240/2221) Loss:30.211795806884766\n",
      "epoch:15 batch 1250/2221) Loss:29.322134017944336\n",
      "epoch:15 batch 1260/2221) Loss:11.06761646270752\n",
      "epoch:15 batch 1270/2221) Loss:13.071406364440918\n",
      "epoch:15 batch 1280/2221) Loss:13.961708068847656\n",
      "epoch:15 batch 1290/2221) Loss:25.19905662536621\n",
      "epoch:15 batch 1300/2221) Loss:8.862213134765625\n",
      "epoch:15 batch 1310/2221) Loss:17.451988220214844\n",
      "epoch:15 batch 1320/2221) Loss:15.97005844116211\n",
      "epoch:15 batch 1330/2221) Loss:20.01111602783203\n",
      "epoch:15 batch 1340/2221) Loss:8.098618507385254\n",
      "epoch:15 batch 1350/2221) Loss:38.10502243041992\n",
      "epoch:15 batch 1360/2221) Loss:7.349017143249512\n",
      "epoch:15 batch 1370/2221) Loss:28.84429931640625\n",
      "epoch:15 batch 1380/2221) Loss:32.38534164428711\n",
      "epoch:15 batch 1390/2221) Loss:17.615060806274414\n",
      "epoch:15 batch 1400/2221) Loss:41.63511276245117\n",
      "epoch:15 batch 1410/2221) Loss:13.256627082824707\n",
      "epoch:15 batch 1420/2221) Loss:6.238430023193359\n",
      "epoch:15 batch 1430/2221) Loss:15.675782203674316\n",
      "epoch:15 batch 1440/2221) Loss:24.092445373535156\n",
      "epoch:15 batch 1450/2221) Loss:18.480510711669922\n",
      "epoch:15 batch 1460/2221) Loss:5.333906173706055\n",
      "epoch:15 batch 1470/2221) Loss:23.085296630859375\n",
      "epoch:15 batch 1480/2221) Loss:6.092824935913086\n",
      "epoch:15 batch 1490/2221) Loss:34.171119689941406\n",
      "epoch:15 batch 1500/2221) Loss:9.718194961547852\n",
      "epoch:15 batch 1510/2221) Loss:6.324138641357422\n",
      "epoch:15 batch 1520/2221) Loss:7.778773307800293\n",
      "epoch:15 batch 1530/2221) Loss:11.74938678741455\n",
      "epoch:15 batch 1540/2221) Loss:9.752898216247559\n",
      "epoch:15 batch 1550/2221) Loss:24.153793334960938\n",
      "epoch:15 batch 1560/2221) Loss:8.173584938049316\n",
      "epoch:15 batch 1570/2221) Loss:8.37112808227539\n",
      "epoch:15 batch 1580/2221) Loss:21.815034866333008\n",
      "epoch:15 batch 1590/2221) Loss:12.784626960754395\n",
      "epoch:15 batch 1600/2221) Loss:38.65144729614258\n",
      "epoch:15 batch 1610/2221) Loss:15.723565101623535\n",
      "epoch:15 batch 1620/2221) Loss:20.46654510498047\n",
      "epoch:15 batch 1630/2221) Loss:16.119239807128906\n",
      "epoch:15 batch 1640/2221) Loss:19.06584930419922\n",
      "epoch:15 batch 1650/2221) Loss:36.3546028137207\n",
      "epoch:15 batch 1660/2221) Loss:22.32415008544922\n",
      "epoch:15 batch 1670/2221) Loss:4.473860740661621\n",
      "epoch:15 batch 1680/2221) Loss:4.498801231384277\n",
      "epoch:15 batch 1690/2221) Loss:5.889558792114258\n",
      "epoch:15 batch 1700/2221) Loss:10.843328475952148\n",
      "epoch:15 batch 1710/2221) Loss:29.869464874267578\n",
      "epoch:15 batch 1720/2221) Loss:3.0199413299560547\n",
      "epoch:15 batch 1730/2221) Loss:33.97038269042969\n",
      "epoch:15 batch 1740/2221) Loss:37.57191467285156\n",
      "epoch:15 batch 1750/2221) Loss:5.406511306762695\n",
      "epoch:15 batch 1760/2221) Loss:9.885348320007324\n",
      "epoch:15 batch 1770/2221) Loss:29.725967407226562\n",
      "epoch:15 batch 1780/2221) Loss:2.3068366050720215\n",
      "epoch:15 batch 1790/2221) Loss:12.05331039428711\n",
      "epoch:15 batch 1800/2221) Loss:12.401984214782715\n",
      "epoch:15 batch 1810/2221) Loss:12.726662635803223\n",
      "epoch:15 batch 1820/2221) Loss:15.542203903198242\n",
      "epoch:15 batch 1830/2221) Loss:43.49235916137695\n",
      "epoch:15 batch 1840/2221) Loss:34.98118591308594\n",
      "epoch:15 batch 1850/2221) Loss:14.0596923828125\n",
      "epoch:15 batch 1860/2221) Loss:16.08208656311035\n",
      "epoch:15 batch 1870/2221) Loss:12.127328872680664\n",
      "epoch:15 batch 1880/2221) Loss:17.816068649291992\n",
      "epoch:15 batch 1890/2221) Loss:6.153224945068359\n",
      "epoch:15 batch 1900/2221) Loss:24.228984832763672\n",
      "epoch:15 batch 1910/2221) Loss:3.4468259811401367\n",
      "epoch:15 batch 1920/2221) Loss:16.42790412902832\n",
      "epoch:15 batch 1930/2221) Loss:5.996932029724121\n",
      "epoch:15 batch 1940/2221) Loss:7.029819488525391\n",
      "epoch:15 batch 1950/2221) Loss:12.461804389953613\n",
      "epoch:15 batch 1960/2221) Loss:31.687755584716797\n",
      "epoch:15 batch 1970/2221) Loss:6.537017822265625\n",
      "epoch:15 batch 1980/2221) Loss:13.057631492614746\n",
      "epoch:15 batch 1990/2221) Loss:14.75329303741455\n",
      "epoch:15 batch 2000/2221) Loss:6.659150123596191\n",
      "epoch:15 batch 2010/2221) Loss:18.037893295288086\n",
      "epoch:15 batch 2020/2221) Loss:7.403730392456055\n",
      "epoch:15 batch 2030/2221) Loss:5.281425476074219\n",
      "epoch:15 batch 2040/2221) Loss:30.01702117919922\n",
      "epoch:15 batch 2050/2221) Loss:13.630297660827637\n",
      "epoch:15 batch 2060/2221) Loss:9.191276550292969\n",
      "epoch:15 batch 2070/2221) Loss:11.092462539672852\n",
      "epoch:15 batch 2080/2221) Loss:12.097094535827637\n",
      "epoch:15 batch 2090/2221) Loss:5.471665382385254\n",
      "epoch:15 batch 2100/2221) Loss:18.579328536987305\n",
      "epoch:15 batch 2110/2221) Loss:8.873408317565918\n",
      "epoch:15 batch 2120/2221) Loss:4.097309112548828\n",
      "epoch:15 batch 2130/2221) Loss:6.881978988647461\n",
      "epoch:15 batch 2140/2221) Loss:60.11009216308594\n",
      "epoch:15 batch 2150/2221) Loss:17.195112228393555\n",
      "epoch:15 batch 2160/2221) Loss:25.208648681640625\n",
      "epoch:15 batch 2170/2221) Loss:23.055477142333984\n",
      "epoch:15 batch 2180/2221) Loss:4.021048545837402\n",
      "epoch:15 batch 2190/2221) Loss:3.8229150772094727\n",
      "epoch:15 batch 2200/2221) Loss:7.625972747802734\n",
      "epoch:15 batch 2210/2221) Loss:13.512030601501465\n",
      "epoch:15 batch 2220/2221) Loss:6.8210906982421875\n",
      "epoch:15 precision:0.9965280588968078 recall:0.9840377339483629 f1-score:0.9900890670810742\n",
      "epoch:16 batch 1/2221) Loss:17.981962203979492\n",
      "epoch:16 batch 10/2221) Loss:31.49201202392578\n",
      "epoch:16 batch 20/2221) Loss:5.467530250549316\n",
      "epoch:16 batch 30/2221) Loss:12.51834774017334\n",
      "epoch:16 batch 40/2221) Loss:3.8228187561035156\n",
      "epoch:16 batch 50/2221) Loss:14.03626537322998\n",
      "epoch:16 batch 60/2221) Loss:7.094390869140625\n",
      "epoch:16 batch 70/2221) Loss:16.08633804321289\n",
      "epoch:16 batch 80/2221) Loss:14.37670612335205\n",
      "epoch:16 batch 90/2221) Loss:32.17972183227539\n",
      "epoch:16 batch 100/2221) Loss:15.700318336486816\n",
      "epoch:16 batch 110/2221) Loss:21.91115379333496\n",
      "epoch:16 batch 120/2221) Loss:7.965394973754883\n",
      "epoch:16 batch 130/2221) Loss:34.81153106689453\n",
      "epoch:16 batch 140/2221) Loss:35.557655334472656\n",
      "epoch:16 batch 150/2221) Loss:8.042338371276855\n",
      "epoch:16 batch 160/2221) Loss:10.834160804748535\n",
      "epoch:16 batch 170/2221) Loss:7.1497602462768555\n",
      "epoch:16 batch 180/2221) Loss:9.447700500488281\n",
      "epoch:16 batch 190/2221) Loss:34.092308044433594\n",
      "epoch:16 batch 200/2221) Loss:7.403959274291992\n",
      "epoch:16 batch 210/2221) Loss:3.15645694732666\n",
      "epoch:16 batch 220/2221) Loss:11.756377220153809\n",
      "epoch:16 batch 230/2221) Loss:21.4791202545166\n",
      "epoch:16 batch 240/2221) Loss:25.339305877685547\n",
      "epoch:16 batch 250/2221) Loss:9.342893600463867\n",
      "epoch:16 batch 260/2221) Loss:8.295015335083008\n",
      "epoch:16 batch 270/2221) Loss:16.525653839111328\n",
      "epoch:16 batch 280/2221) Loss:11.185836791992188\n",
      "epoch:16 batch 290/2221) Loss:8.49648666381836\n",
      "epoch:16 batch 300/2221) Loss:6.06702995300293\n",
      "epoch:16 batch 310/2221) Loss:16.48188018798828\n",
      "epoch:16 batch 320/2221) Loss:8.102312088012695\n",
      "epoch:16 batch 330/2221) Loss:22.103740692138672\n",
      "epoch:16 batch 340/2221) Loss:34.575775146484375\n",
      "epoch:16 batch 350/2221) Loss:16.207374572753906\n",
      "epoch:16 batch 360/2221) Loss:18.3756046295166\n",
      "epoch:16 batch 370/2221) Loss:4.259305953979492\n",
      "epoch:16 batch 380/2221) Loss:18.692676544189453\n",
      "epoch:16 batch 390/2221) Loss:19.15770721435547\n",
      "epoch:16 batch 400/2221) Loss:9.47521686553955\n",
      "epoch:16 batch 410/2221) Loss:14.722735404968262\n",
      "epoch:16 batch 420/2221) Loss:13.583990097045898\n",
      "epoch:16 batch 430/2221) Loss:11.439899444580078\n",
      "epoch:16 batch 440/2221) Loss:8.391521453857422\n",
      "epoch:16 batch 450/2221) Loss:13.835968971252441\n",
      "epoch:16 batch 460/2221) Loss:7.848440170288086\n",
      "epoch:16 batch 470/2221) Loss:16.335731506347656\n",
      "epoch:16 batch 480/2221) Loss:2.7676124572753906\n",
      "epoch:16 batch 490/2221) Loss:14.572397232055664\n",
      "epoch:16 batch 500/2221) Loss:11.298694610595703\n",
      "epoch:16 batch 510/2221) Loss:15.818674087524414\n",
      "epoch:16 batch 520/2221) Loss:26.368812561035156\n",
      "epoch:16 batch 530/2221) Loss:13.745930671691895\n",
      "epoch:16 batch 540/2221) Loss:14.420439720153809\n",
      "epoch:16 batch 550/2221) Loss:9.166912078857422\n",
      "epoch:16 batch 560/2221) Loss:9.565502166748047\n",
      "epoch:16 batch 570/2221) Loss:0.9736118316650391\n",
      "epoch:16 batch 580/2221) Loss:11.648303985595703\n",
      "epoch:16 batch 590/2221) Loss:22.317501068115234\n",
      "epoch:16 batch 600/2221) Loss:15.074941635131836\n",
      "epoch:16 batch 610/2221) Loss:16.717304229736328\n",
      "epoch:16 batch 620/2221) Loss:12.82686710357666\n",
      "epoch:16 batch 630/2221) Loss:12.633563995361328\n",
      "epoch:16 batch 640/2221) Loss:25.889663696289062\n",
      "epoch:16 batch 650/2221) Loss:11.555170059204102\n",
      "epoch:16 batch 660/2221) Loss:4.452279090881348\n",
      "epoch:16 batch 670/2221) Loss:16.208431243896484\n",
      "epoch:16 batch 680/2221) Loss:9.730950355529785\n",
      "epoch:16 batch 690/2221) Loss:8.632265090942383\n",
      "epoch:16 batch 700/2221) Loss:9.367956161499023\n",
      "epoch:16 batch 710/2221) Loss:4.511539459228516\n",
      "epoch:16 batch 720/2221) Loss:21.790668487548828\n",
      "epoch:16 batch 730/2221) Loss:7.300268173217773\n",
      "epoch:16 batch 740/2221) Loss:5.297218322753906\n",
      "epoch:16 batch 750/2221) Loss:12.539993286132812\n",
      "epoch:16 batch 760/2221) Loss:13.41505241394043\n",
      "epoch:16 batch 770/2221) Loss:28.82425308227539\n",
      "epoch:16 batch 780/2221) Loss:4.995245933532715\n",
      "epoch:16 batch 790/2221) Loss:3.336318016052246\n",
      "epoch:16 batch 800/2221) Loss:18.385711669921875\n",
      "epoch:16 batch 810/2221) Loss:22.039684295654297\n",
      "epoch:16 batch 820/2221) Loss:15.217361450195312\n",
      "epoch:16 batch 830/2221) Loss:4.481351852416992\n",
      "epoch:16 batch 840/2221) Loss:6.172478675842285\n",
      "epoch:16 batch 850/2221) Loss:38.94232177734375\n",
      "epoch:16 batch 860/2221) Loss:17.227375030517578\n",
      "epoch:16 batch 870/2221) Loss:1.2326507568359375\n",
      "epoch:16 batch 880/2221) Loss:36.9527587890625\n",
      "epoch:16 batch 890/2221) Loss:19.88370132446289\n",
      "epoch:16 batch 900/2221) Loss:4.794253349304199\n",
      "epoch:16 batch 910/2221) Loss:20.281003952026367\n",
      "epoch:16 batch 920/2221) Loss:5.358595848083496\n",
      "epoch:16 batch 930/2221) Loss:34.89030838012695\n",
      "epoch:16 batch 940/2221) Loss:37.82672882080078\n",
      "epoch:16 batch 950/2221) Loss:7.638935089111328\n",
      "epoch:16 batch 960/2221) Loss:16.53842544555664\n",
      "epoch:16 batch 970/2221) Loss:3.566451072692871\n",
      "epoch:16 batch 980/2221) Loss:2.653383255004883\n",
      "epoch:16 batch 990/2221) Loss:9.094615936279297\n",
      "epoch:16 batch 1000/2221) Loss:9.1639404296875\n",
      "epoch:16 batch 1010/2221) Loss:8.14521312713623\n",
      "epoch:16 batch 1020/2221) Loss:6.818330764770508\n",
      "epoch:16 batch 1030/2221) Loss:6.13453483581543\n",
      "epoch:16 batch 1040/2221) Loss:8.450634002685547\n",
      "epoch:16 batch 1050/2221) Loss:4.962898254394531\n",
      "epoch:16 batch 1060/2221) Loss:14.552123069763184\n",
      "epoch:16 batch 1070/2221) Loss:4.573807716369629\n",
      "epoch:16 batch 1080/2221) Loss:12.268197059631348\n",
      "epoch:16 batch 1090/2221) Loss:21.199508666992188\n",
      "epoch:16 batch 1100/2221) Loss:4.653312683105469\n",
      "epoch:16 batch 1110/2221) Loss:10.505531311035156\n",
      "epoch:16 batch 1120/2221) Loss:15.66832447052002\n",
      "epoch:16 batch 1130/2221) Loss:8.659317016601562\n",
      "epoch:16 batch 1140/2221) Loss:1.326582908630371\n",
      "epoch:16 batch 1150/2221) Loss:26.5076904296875\n",
      "epoch:16 batch 1160/2221) Loss:27.12936782836914\n",
      "epoch:16 batch 1170/2221) Loss:22.769245147705078\n",
      "epoch:16 batch 1180/2221) Loss:17.546817779541016\n",
      "epoch:16 batch 1190/2221) Loss:15.289228439331055\n",
      "epoch:16 batch 1200/2221) Loss:7.705867767333984\n",
      "epoch:16 batch 1210/2221) Loss:17.271282196044922\n",
      "epoch:16 batch 1220/2221) Loss:4.634406089782715\n",
      "epoch:16 batch 1230/2221) Loss:10.124212265014648\n",
      "epoch:16 batch 1240/2221) Loss:14.563831329345703\n",
      "epoch:16 batch 1250/2221) Loss:10.068870544433594\n",
      "epoch:16 batch 1260/2221) Loss:25.717796325683594\n",
      "epoch:16 batch 1270/2221) Loss:13.635161399841309\n",
      "epoch:16 batch 1280/2221) Loss:20.82794189453125\n",
      "epoch:16 batch 1290/2221) Loss:11.840023040771484\n",
      "epoch:16 batch 1300/2221) Loss:16.697601318359375\n",
      "epoch:16 batch 1310/2221) Loss:8.947352409362793\n",
      "epoch:16 batch 1320/2221) Loss:6.631864547729492\n",
      "epoch:16 batch 1330/2221) Loss:9.494283676147461\n",
      "epoch:16 batch 1340/2221) Loss:19.839324951171875\n",
      "epoch:16 batch 1350/2221) Loss:29.95134735107422\n",
      "epoch:16 batch 1360/2221) Loss:12.550739288330078\n",
      "epoch:16 batch 1370/2221) Loss:29.28797149658203\n",
      "epoch:16 batch 1380/2221) Loss:6.251900672912598\n",
      "epoch:16 batch 1390/2221) Loss:16.163806915283203\n",
      "epoch:16 batch 1400/2221) Loss:5.910379409790039\n",
      "epoch:16 batch 1410/2221) Loss:18.05181884765625\n",
      "epoch:16 batch 1420/2221) Loss:9.154725074768066\n",
      "epoch:16 batch 1430/2221) Loss:32.88249969482422\n",
      "epoch:16 batch 1440/2221) Loss:20.31757164001465\n",
      "epoch:16 batch 1450/2221) Loss:9.606446266174316\n",
      "epoch:16 batch 1460/2221) Loss:3.51796817779541\n",
      "epoch:16 batch 1470/2221) Loss:16.28335189819336\n",
      "epoch:16 batch 1480/2221) Loss:8.43703842163086\n",
      "epoch:16 batch 1490/2221) Loss:3.325021743774414\n",
      "epoch:16 batch 1500/2221) Loss:36.422054290771484\n",
      "epoch:16 batch 1510/2221) Loss:12.03293514251709\n",
      "epoch:16 batch 1520/2221) Loss:6.468036651611328\n",
      "epoch:16 batch 1530/2221) Loss:6.381254196166992\n",
      "epoch:16 batch 1540/2221) Loss:9.726938247680664\n",
      "epoch:16 batch 1550/2221) Loss:9.239809036254883\n",
      "epoch:16 batch 1560/2221) Loss:6.799910545349121\n",
      "epoch:16 batch 1570/2221) Loss:10.05426025390625\n",
      "epoch:16 batch 1580/2221) Loss:10.048958778381348\n",
      "epoch:16 batch 1590/2221) Loss:20.05763816833496\n",
      "epoch:16 batch 1600/2221) Loss:20.08747673034668\n",
      "epoch:16 batch 1610/2221) Loss:20.540897369384766\n",
      "epoch:16 batch 1620/2221) Loss:7.568816184997559\n",
      "epoch:16 batch 1630/2221) Loss:8.259356498718262\n",
      "epoch:16 batch 1640/2221) Loss:14.88410758972168\n",
      "epoch:16 batch 1650/2221) Loss:12.248276710510254\n",
      "epoch:16 batch 1660/2221) Loss:10.117207527160645\n",
      "epoch:16 batch 1670/2221) Loss:20.965919494628906\n",
      "epoch:16 batch 1680/2221) Loss:8.752464294433594\n",
      "epoch:16 batch 1690/2221) Loss:11.730566024780273\n",
      "epoch:16 batch 1700/2221) Loss:7.736498832702637\n",
      "epoch:16 batch 1710/2221) Loss:9.829758644104004\n",
      "epoch:16 batch 1720/2221) Loss:19.890377044677734\n",
      "epoch:16 batch 1730/2221) Loss:6.115481376647949\n",
      "epoch:16 batch 1740/2221) Loss:18.824724197387695\n",
      "epoch:16 batch 1750/2221) Loss:4.637575149536133\n",
      "epoch:16 batch 1760/2221) Loss:3.525120735168457\n",
      "epoch:16 batch 1770/2221) Loss:23.33047866821289\n",
      "epoch:16 batch 1780/2221) Loss:9.360770225524902\n",
      "epoch:16 batch 1790/2221) Loss:22.75067710876465\n",
      "epoch:16 batch 1800/2221) Loss:7.590973854064941\n",
      "epoch:16 batch 1810/2221) Loss:12.104571342468262\n",
      "epoch:16 batch 1820/2221) Loss:18.586986541748047\n",
      "epoch:16 batch 1830/2221) Loss:3.9986257553100586\n",
      "epoch:16 batch 1840/2221) Loss:1.8658699989318848\n",
      "epoch:16 batch 1850/2221) Loss:11.516284942626953\n",
      "epoch:16 batch 1860/2221) Loss:10.567132949829102\n",
      "epoch:16 batch 1870/2221) Loss:16.646072387695312\n",
      "epoch:16 batch 1880/2221) Loss:21.53271484375\n",
      "epoch:16 batch 1890/2221) Loss:14.397867202758789\n",
      "epoch:16 batch 1900/2221) Loss:10.940624237060547\n",
      "epoch:16 batch 1910/2221) Loss:5.200347900390625\n",
      "epoch:16 batch 1920/2221) Loss:8.46086597442627\n",
      "epoch:16 batch 1930/2221) Loss:11.907777786254883\n",
      "epoch:16 batch 1940/2221) Loss:18.879718780517578\n",
      "epoch:16 batch 1950/2221) Loss:7.774858474731445\n",
      "epoch:16 batch 1960/2221) Loss:13.12678050994873\n",
      "epoch:16 batch 1970/2221) Loss:7.029511451721191\n",
      "epoch:16 batch 1980/2221) Loss:5.59233283996582\n",
      "epoch:16 batch 1990/2221) Loss:1.8068971633911133\n",
      "epoch:16 batch 2000/2221) Loss:14.222034454345703\n",
      "epoch:16 batch 2010/2221) Loss:17.91143226623535\n",
      "epoch:16 batch 2020/2221) Loss:11.783256530761719\n",
      "epoch:16 batch 2030/2221) Loss:13.595673561096191\n",
      "epoch:16 batch 2040/2221) Loss:12.609436988830566\n",
      "epoch:16 batch 2050/2221) Loss:11.197057723999023\n",
      "epoch:16 batch 2060/2221) Loss:29.322059631347656\n",
      "epoch:16 batch 2070/2221) Loss:23.970195770263672\n",
      "epoch:16 batch 2080/2221) Loss:26.748611450195312\n",
      "epoch:16 batch 2090/2221) Loss:3.8229894638061523\n",
      "epoch:16 batch 2100/2221) Loss:16.036529541015625\n",
      "epoch:16 batch 2110/2221) Loss:1.1411428451538086\n",
      "epoch:16 batch 2120/2221) Loss:16.618196487426758\n",
      "epoch:16 batch 2130/2221) Loss:11.470991134643555\n",
      "epoch:16 batch 2140/2221) Loss:4.4419636726379395\n",
      "epoch:16 batch 2150/2221) Loss:18.11113739013672\n",
      "epoch:16 batch 2160/2221) Loss:12.69859790802002\n",
      "epoch:16 batch 2170/2221) Loss:12.840014457702637\n",
      "epoch:16 batch 2180/2221) Loss:26.21027374267578\n",
      "epoch:16 batch 2190/2221) Loss:10.855598449707031\n",
      "epoch:16 batch 2200/2221) Loss:22.627540588378906\n",
      "epoch:16 batch 2210/2221) Loss:25.870376586914062\n",
      "epoch:16 batch 2220/2221) Loss:1.9006562232971191\n",
      "epoch:16 precision:0.9963632109620918 recall:0.984782823649452 f1-score:0.990396717005261\n",
      "epoch:17 batch 1/2221) Loss:6.621120929718018\n",
      "epoch:17 batch 10/2221) Loss:1.4436407089233398\n",
      "epoch:17 batch 20/2221) Loss:25.952392578125\n",
      "epoch:17 batch 30/2221) Loss:18.309154510498047\n",
      "epoch:17 batch 40/2221) Loss:9.998486518859863\n",
      "epoch:17 batch 50/2221) Loss:11.008048057556152\n",
      "epoch:17 batch 60/2221) Loss:4.588780879974365\n",
      "epoch:17 batch 70/2221) Loss:19.584136962890625\n",
      "epoch:17 batch 80/2221) Loss:20.46381187438965\n",
      "epoch:17 batch 90/2221) Loss:13.942967414855957\n",
      "epoch:17 batch 100/2221) Loss:6.0292463302612305\n",
      "epoch:17 batch 110/2221) Loss:10.17676067352295\n",
      "epoch:17 batch 120/2221) Loss:25.075393676757812\n",
      "epoch:17 batch 130/2221) Loss:7.0940775871276855\n",
      "epoch:17 batch 140/2221) Loss:9.112981796264648\n",
      "epoch:17 batch 150/2221) Loss:5.109745025634766\n",
      "epoch:17 batch 160/2221) Loss:1.9607179164886475\n",
      "epoch:17 batch 170/2221) Loss:19.187030792236328\n",
      "epoch:17 batch 180/2221) Loss:22.775657653808594\n",
      "epoch:17 batch 190/2221) Loss:11.836073875427246\n",
      "epoch:17 batch 200/2221) Loss:4.097886085510254\n",
      "epoch:17 batch 210/2221) Loss:6.361812591552734\n",
      "epoch:17 batch 220/2221) Loss:22.111249923706055\n",
      "epoch:17 batch 230/2221) Loss:6.2837605476379395\n",
      "epoch:17 batch 240/2221) Loss:16.83844757080078\n",
      "epoch:17 batch 250/2221) Loss:22.39122772216797\n",
      "epoch:17 batch 260/2221) Loss:13.655418395996094\n",
      "epoch:17 batch 270/2221) Loss:17.16342544555664\n",
      "epoch:17 batch 280/2221) Loss:34.002540588378906\n",
      "epoch:17 batch 290/2221) Loss:17.01123809814453\n",
      "epoch:17 batch 300/2221) Loss:8.800227165222168\n",
      "epoch:17 batch 310/2221) Loss:20.352684020996094\n",
      "epoch:17 batch 320/2221) Loss:10.734172821044922\n",
      "epoch:17 batch 330/2221) Loss:4.949349403381348\n",
      "epoch:17 batch 340/2221) Loss:12.24267864227295\n",
      "epoch:17 batch 350/2221) Loss:9.342637062072754\n",
      "epoch:17 batch 360/2221) Loss:6.422956466674805\n",
      "epoch:17 batch 370/2221) Loss:2.374880790710449\n",
      "epoch:17 batch 380/2221) Loss:31.841957092285156\n",
      "epoch:17 batch 390/2221) Loss:18.979228973388672\n",
      "epoch:17 batch 400/2221) Loss:16.438819885253906\n",
      "epoch:17 batch 410/2221) Loss:0.9625730514526367\n",
      "epoch:17 batch 420/2221) Loss:9.506658554077148\n",
      "epoch:17 batch 430/2221) Loss:23.284330368041992\n",
      "epoch:17 batch 440/2221) Loss:12.036865234375\n",
      "epoch:17 batch 450/2221) Loss:27.88138198852539\n",
      "epoch:17 batch 460/2221) Loss:3.876373291015625\n",
      "epoch:17 batch 470/2221) Loss:6.991997718811035\n",
      "epoch:17 batch 480/2221) Loss:10.545612335205078\n",
      "epoch:17 batch 490/2221) Loss:17.446195602416992\n",
      "epoch:17 batch 500/2221) Loss:20.395156860351562\n",
      "epoch:17 batch 510/2221) Loss:26.638484954833984\n",
      "epoch:17 batch 520/2221) Loss:10.881885528564453\n",
      "epoch:17 batch 530/2221) Loss:4.388956546783447\n",
      "epoch:17 batch 540/2221) Loss:21.516109466552734\n",
      "epoch:17 batch 550/2221) Loss:11.662129402160645\n",
      "epoch:17 batch 560/2221) Loss:12.18680191040039\n",
      "epoch:17 batch 570/2221) Loss:7.4052019119262695\n",
      "epoch:17 batch 580/2221) Loss:3.5367183685302734\n",
      "epoch:17 batch 590/2221) Loss:17.183956146240234\n",
      "epoch:17 batch 600/2221) Loss:9.383663177490234\n",
      "epoch:17 batch 610/2221) Loss:20.70454978942871\n",
      "epoch:17 batch 620/2221) Loss:14.372222900390625\n",
      "epoch:17 batch 630/2221) Loss:10.006714820861816\n",
      "epoch:17 batch 640/2221) Loss:15.887151718139648\n",
      "epoch:17 batch 650/2221) Loss:8.014715194702148\n",
      "epoch:17 batch 660/2221) Loss:6.570857524871826\n",
      "epoch:17 batch 670/2221) Loss:11.20641040802002\n",
      "epoch:17 batch 680/2221) Loss:9.366119384765625\n",
      "epoch:17 batch 690/2221) Loss:6.308279037475586\n",
      "epoch:17 batch 700/2221) Loss:20.008831024169922\n",
      "epoch:17 batch 710/2221) Loss:19.354433059692383\n",
      "epoch:17 batch 720/2221) Loss:8.326289176940918\n",
      "epoch:17 batch 730/2221) Loss:9.924234390258789\n",
      "epoch:17 batch 740/2221) Loss:19.033458709716797\n",
      "epoch:17 batch 750/2221) Loss:9.991167068481445\n",
      "epoch:17 batch 760/2221) Loss:15.089461326599121\n",
      "epoch:17 batch 770/2221) Loss:26.29408073425293\n",
      "epoch:17 batch 780/2221) Loss:7.92984676361084\n",
      "epoch:17 batch 790/2221) Loss:8.862728118896484\n",
      "epoch:17 batch 800/2221) Loss:15.553205490112305\n",
      "epoch:17 batch 810/2221) Loss:4.411848068237305\n",
      "epoch:17 batch 820/2221) Loss:7.938043117523193\n",
      "epoch:17 batch 830/2221) Loss:8.74866008758545\n",
      "epoch:17 batch 840/2221) Loss:19.254396438598633\n",
      "epoch:17 batch 850/2221) Loss:1.2894916534423828\n",
      "epoch:17 batch 860/2221) Loss:31.436012268066406\n",
      "epoch:17 batch 870/2221) Loss:7.495758056640625\n",
      "epoch:17 batch 880/2221) Loss:7.0655670166015625\n",
      "epoch:17 batch 890/2221) Loss:20.10593032836914\n",
      "epoch:17 batch 900/2221) Loss:14.427363395690918\n",
      "epoch:17 batch 910/2221) Loss:8.807622909545898\n",
      "epoch:17 batch 920/2221) Loss:7.644513130187988\n",
      "epoch:17 batch 930/2221) Loss:10.421306610107422\n",
      "epoch:17 batch 940/2221) Loss:31.1470947265625\n",
      "epoch:17 batch 950/2221) Loss:27.488754272460938\n",
      "epoch:17 batch 960/2221) Loss:9.808956146240234\n",
      "epoch:17 batch 970/2221) Loss:29.145713806152344\n",
      "epoch:17 batch 980/2221) Loss:23.393474578857422\n",
      "epoch:17 batch 990/2221) Loss:9.465351104736328\n",
      "epoch:17 batch 1000/2221) Loss:7.9896745681762695\n",
      "epoch:17 batch 1010/2221) Loss:11.756381034851074\n",
      "epoch:17 batch 1020/2221) Loss:27.14914321899414\n",
      "epoch:17 batch 1030/2221) Loss:17.098278045654297\n",
      "epoch:17 batch 1040/2221) Loss:5.2791948318481445\n",
      "epoch:17 batch 1050/2221) Loss:20.36199951171875\n",
      "epoch:17 batch 1060/2221) Loss:28.23115348815918\n",
      "epoch:17 batch 1070/2221) Loss:31.72199821472168\n",
      "epoch:17 batch 1080/2221) Loss:11.826003074645996\n",
      "epoch:17 batch 1090/2221) Loss:22.428958892822266\n",
      "epoch:17 batch 1100/2221) Loss:14.52501392364502\n",
      "epoch:17 batch 1110/2221) Loss:26.372053146362305\n",
      "epoch:17 batch 1120/2221) Loss:23.116079330444336\n",
      "epoch:17 batch 1130/2221) Loss:10.249340057373047\n",
      "epoch:17 batch 1140/2221) Loss:13.516806602478027\n",
      "epoch:17 batch 1150/2221) Loss:28.644561767578125\n",
      "epoch:17 batch 1160/2221) Loss:24.351566314697266\n",
      "epoch:17 batch 1170/2221) Loss:17.838380813598633\n",
      "epoch:17 batch 1180/2221) Loss:6.872076511383057\n",
      "epoch:17 batch 1190/2221) Loss:17.35116958618164\n",
      "epoch:17 batch 1200/2221) Loss:9.511823654174805\n",
      "epoch:17 batch 1210/2221) Loss:32.67550277709961\n",
      "epoch:17 batch 1220/2221) Loss:20.59567642211914\n",
      "epoch:17 batch 1230/2221) Loss:24.368080139160156\n",
      "epoch:17 batch 1240/2221) Loss:5.3331522941589355\n",
      "epoch:17 batch 1250/2221) Loss:13.607831001281738\n",
      "epoch:17 batch 1260/2221) Loss:1.7767486572265625\n",
      "epoch:17 batch 1270/2221) Loss:4.777434349060059\n",
      "epoch:17 batch 1280/2221) Loss:17.72572898864746\n",
      "epoch:17 batch 1290/2221) Loss:18.53816795349121\n",
      "epoch:17 batch 1300/2221) Loss:18.42906951904297\n",
      "epoch:17 batch 1310/2221) Loss:7.562652587890625\n",
      "epoch:17 batch 1320/2221) Loss:4.9288201332092285\n",
      "epoch:17 batch 1330/2221) Loss:21.474422454833984\n",
      "epoch:17 batch 1340/2221) Loss:32.34529113769531\n",
      "epoch:17 batch 1350/2221) Loss:0.9654951095581055\n",
      "epoch:17 batch 1360/2221) Loss:3.275141716003418\n",
      "epoch:17 batch 1370/2221) Loss:22.23412322998047\n",
      "epoch:17 batch 1380/2221) Loss:9.050206184387207\n",
      "epoch:17 batch 1390/2221) Loss:7.3166680335998535\n",
      "epoch:17 batch 1400/2221) Loss:11.037614822387695\n",
      "epoch:17 batch 1410/2221) Loss:9.900513648986816\n",
      "epoch:17 batch 1420/2221) Loss:6.043069839477539\n",
      "epoch:17 batch 1430/2221) Loss:18.253067016601562\n",
      "epoch:17 batch 1440/2221) Loss:3.878263473510742\n",
      "epoch:17 batch 1450/2221) Loss:4.846490859985352\n",
      "epoch:17 batch 1460/2221) Loss:5.096287727355957\n",
      "epoch:17 batch 1470/2221) Loss:15.636571884155273\n",
      "epoch:17 batch 1480/2221) Loss:17.784605026245117\n",
      "epoch:17 batch 1490/2221) Loss:11.965497970581055\n",
      "epoch:17 batch 1500/2221) Loss:17.850679397583008\n",
      "epoch:17 batch 1510/2221) Loss:14.91258430480957\n",
      "epoch:17 batch 1520/2221) Loss:19.764785766601562\n",
      "epoch:17 batch 1530/2221) Loss:10.454050064086914\n",
      "epoch:17 batch 1540/2221) Loss:13.078049659729004\n",
      "epoch:17 batch 1550/2221) Loss:9.377796173095703\n",
      "epoch:17 batch 1560/2221) Loss:11.996456146240234\n",
      "epoch:17 batch 1570/2221) Loss:13.951047897338867\n",
      "epoch:17 batch 1580/2221) Loss:5.9956374168396\n",
      "epoch:17 batch 1590/2221) Loss:11.182571411132812\n",
      "epoch:17 batch 1600/2221) Loss:7.0405192375183105\n",
      "epoch:17 batch 1610/2221) Loss:11.917388916015625\n",
      "epoch:17 batch 1620/2221) Loss:12.963127136230469\n",
      "epoch:17 batch 1630/2221) Loss:18.83920669555664\n",
      "epoch:17 batch 1640/2221) Loss:3.631244659423828\n",
      "epoch:17 batch 1650/2221) Loss:10.419929504394531\n",
      "epoch:17 batch 1660/2221) Loss:18.456520080566406\n",
      "epoch:17 batch 1670/2221) Loss:28.204574584960938\n",
      "epoch:17 batch 1680/2221) Loss:23.50961685180664\n",
      "epoch:17 batch 1690/2221) Loss:15.132534980773926\n",
      "epoch:17 batch 1700/2221) Loss:13.788971900939941\n",
      "epoch:17 batch 1710/2221) Loss:9.04489517211914\n",
      "epoch:17 batch 1720/2221) Loss:27.127666473388672\n",
      "epoch:17 batch 1730/2221) Loss:4.700516700744629\n",
      "epoch:17 batch 1740/2221) Loss:19.071346282958984\n",
      "epoch:17 batch 1750/2221) Loss:10.177392959594727\n",
      "epoch:17 batch 1760/2221) Loss:4.1248297691345215\n",
      "epoch:17 batch 1770/2221) Loss:5.9167304039001465\n",
      "epoch:17 batch 1780/2221) Loss:7.0281219482421875\n",
      "epoch:17 batch 1790/2221) Loss:7.992779731750488\n",
      "epoch:17 batch 1800/2221) Loss:2.4212021827697754\n",
      "epoch:17 batch 1810/2221) Loss:6.171327114105225\n",
      "epoch:17 batch 1820/2221) Loss:10.82695484161377\n",
      "epoch:17 batch 1830/2221) Loss:11.562854766845703\n",
      "epoch:17 batch 1840/2221) Loss:12.208019256591797\n",
      "epoch:17 batch 1850/2221) Loss:14.986345291137695\n",
      "epoch:17 batch 1860/2221) Loss:7.937299728393555\n",
      "epoch:17 batch 1870/2221) Loss:7.232494831085205\n",
      "epoch:17 batch 1880/2221) Loss:18.098285675048828\n",
      "epoch:17 batch 1890/2221) Loss:12.573112487792969\n",
      "epoch:17 batch 1900/2221) Loss:12.911372184753418\n",
      "epoch:17 batch 1910/2221) Loss:22.063034057617188\n",
      "epoch:17 batch 1920/2221) Loss:7.590488910675049\n",
      "epoch:17 batch 1930/2221) Loss:19.291688919067383\n",
      "epoch:17 batch 1940/2221) Loss:14.320322036743164\n",
      "epoch:17 batch 1950/2221) Loss:20.8111572265625\n",
      "epoch:17 batch 1960/2221) Loss:13.129607200622559\n",
      "epoch:17 batch 1970/2221) Loss:26.83242416381836\n",
      "epoch:17 batch 1980/2221) Loss:23.078895568847656\n",
      "epoch:17 batch 1990/2221) Loss:2.3272414207458496\n",
      "epoch:17 batch 2000/2221) Loss:3.948601722717285\n",
      "epoch:17 batch 2010/2221) Loss:10.948335647583008\n",
      "epoch:17 batch 2020/2221) Loss:3.633854389190674\n",
      "epoch:17 batch 2030/2221) Loss:25.246917724609375\n",
      "epoch:17 batch 2040/2221) Loss:5.675032138824463\n",
      "epoch:17 batch 2050/2221) Loss:11.05752944946289\n",
      "epoch:17 batch 2060/2221) Loss:1.4572538137435913\n",
      "epoch:17 batch 2070/2221) Loss:26.001665115356445\n",
      "epoch:17 batch 2080/2221) Loss:6.663321495056152\n",
      "epoch:17 batch 2090/2221) Loss:12.327367782592773\n",
      "epoch:17 batch 2100/2221) Loss:11.091176986694336\n",
      "epoch:17 batch 2110/2221) Loss:6.587221145629883\n",
      "epoch:17 batch 2120/2221) Loss:10.38336181640625\n",
      "epoch:17 batch 2130/2221) Loss:2.672130584716797\n",
      "epoch:17 batch 2140/2221) Loss:1.0817923545837402\n",
      "epoch:17 batch 2150/2221) Loss:10.724682807922363\n",
      "epoch:17 batch 2160/2221) Loss:19.254819869995117\n",
      "epoch:17 batch 2170/2221) Loss:12.012399673461914\n",
      "epoch:17 batch 2180/2221) Loss:2.5036730766296387\n",
      "epoch:17 batch 2190/2221) Loss:12.499341011047363\n",
      "epoch:17 batch 2200/2221) Loss:13.036224365234375\n",
      "epoch:17 batch 2210/2221) Loss:16.340835571289062\n",
      "epoch:17 batch 2220/2221) Loss:15.126402854919434\n",
      "epoch:17 precision:0.9957444499596229 recall:0.9861392448741718 f1-score:0.990816667444728\n",
      "epoch:18 batch 1/2221) Loss:3.686652898788452\n",
      "epoch:18 batch 10/2221) Loss:14.87689208984375\n",
      "epoch:18 batch 20/2221) Loss:5.804350852966309\n",
      "epoch:18 batch 30/2221) Loss:7.013814926147461\n",
      "epoch:18 batch 40/2221) Loss:19.623332977294922\n",
      "epoch:18 batch 50/2221) Loss:15.673221588134766\n",
      "epoch:18 batch 60/2221) Loss:16.57691192626953\n",
      "epoch:18 batch 70/2221) Loss:18.834163665771484\n",
      "epoch:18 batch 80/2221) Loss:16.73596954345703\n",
      "epoch:18 batch 90/2221) Loss:1.5151138305664062\n",
      "epoch:18 batch 100/2221) Loss:5.735932350158691\n",
      "epoch:18 batch 110/2221) Loss:29.450382232666016\n",
      "epoch:18 batch 120/2221) Loss:8.690424919128418\n",
      "epoch:18 batch 130/2221) Loss:3.7129764556884766\n",
      "epoch:18 batch 140/2221) Loss:2.528585910797119\n",
      "epoch:18 batch 150/2221) Loss:31.967546463012695\n",
      "epoch:18 batch 160/2221) Loss:14.096328735351562\n",
      "epoch:18 batch 170/2221) Loss:3.0783510208129883\n",
      "epoch:18 batch 180/2221) Loss:8.946063041687012\n",
      "epoch:18 batch 190/2221) Loss:4.92422342300415\n",
      "epoch:18 batch 200/2221) Loss:9.368090629577637\n",
      "epoch:18 batch 210/2221) Loss:2.6153311729431152\n",
      "epoch:18 batch 220/2221) Loss:5.241820335388184\n",
      "epoch:18 batch 230/2221) Loss:3.935586452484131\n",
      "epoch:18 batch 240/2221) Loss:0.9681272506713867\n",
      "epoch:18 batch 250/2221) Loss:14.401525497436523\n",
      "epoch:18 batch 260/2221) Loss:21.23719024658203\n",
      "epoch:18 batch 270/2221) Loss:19.305980682373047\n",
      "epoch:18 batch 280/2221) Loss:12.37857437133789\n",
      "epoch:18 batch 290/2221) Loss:11.669078826904297\n",
      "epoch:18 batch 300/2221) Loss:5.848845481872559\n",
      "epoch:18 batch 310/2221) Loss:8.280444145202637\n",
      "epoch:18 batch 320/2221) Loss:4.382043838500977\n",
      "epoch:18 batch 330/2221) Loss:5.2005414962768555\n",
      "epoch:18 batch 340/2221) Loss:20.480152130126953\n",
      "epoch:18 batch 350/2221) Loss:13.656888961791992\n",
      "epoch:18 batch 360/2221) Loss:7.174114227294922\n",
      "epoch:18 batch 370/2221) Loss:14.695714950561523\n",
      "epoch:18 batch 380/2221) Loss:40.66453170776367\n",
      "epoch:18 batch 390/2221) Loss:17.758989334106445\n",
      "epoch:18 batch 400/2221) Loss:27.976726531982422\n",
      "epoch:18 batch 410/2221) Loss:6.775744438171387\n",
      "epoch:18 batch 420/2221) Loss:2.4595704078674316\n",
      "epoch:18 batch 430/2221) Loss:13.042282104492188\n",
      "epoch:18 batch 440/2221) Loss:7.517605304718018\n",
      "epoch:18 batch 450/2221) Loss:7.689747333526611\n",
      "epoch:18 batch 460/2221) Loss:27.34328842163086\n",
      "epoch:18 batch 470/2221) Loss:12.544807434082031\n",
      "epoch:18 batch 480/2221) Loss:14.991113662719727\n",
      "epoch:18 batch 490/2221) Loss:20.683923721313477\n",
      "epoch:18 batch 500/2221) Loss:5.375881671905518\n",
      "epoch:18 batch 510/2221) Loss:13.122241973876953\n",
      "epoch:18 batch 520/2221) Loss:8.960918426513672\n",
      "epoch:18 batch 530/2221) Loss:10.643119812011719\n",
      "epoch:18 batch 540/2221) Loss:3.841752052307129\n",
      "epoch:18 batch 550/2221) Loss:3.255707263946533\n",
      "epoch:18 batch 560/2221) Loss:0.7089023590087891\n",
      "epoch:18 batch 570/2221) Loss:32.974361419677734\n",
      "epoch:18 batch 580/2221) Loss:10.780474662780762\n",
      "epoch:18 batch 590/2221) Loss:9.191969871520996\n",
      "epoch:18 batch 600/2221) Loss:20.440547943115234\n",
      "epoch:18 batch 610/2221) Loss:4.516241073608398\n",
      "epoch:18 batch 620/2221) Loss:2.232482671737671\n",
      "epoch:18 batch 630/2221) Loss:5.002976417541504\n",
      "epoch:18 batch 640/2221) Loss:21.86013412475586\n",
      "epoch:18 batch 650/2221) Loss:35.898109436035156\n",
      "epoch:18 batch 660/2221) Loss:4.431353569030762\n",
      "epoch:18 batch 670/2221) Loss:25.892433166503906\n",
      "epoch:18 batch 680/2221) Loss:12.61349105834961\n",
      "epoch:18 batch 690/2221) Loss:11.150609970092773\n",
      "epoch:18 batch 700/2221) Loss:9.999353408813477\n",
      "epoch:18 batch 710/2221) Loss:12.28089714050293\n",
      "epoch:18 batch 720/2221) Loss:8.673961639404297\n",
      "epoch:18 batch 730/2221) Loss:7.586073875427246\n",
      "epoch:18 batch 740/2221) Loss:15.962356567382812\n",
      "epoch:18 batch 750/2221) Loss:16.727291107177734\n",
      "epoch:18 batch 760/2221) Loss:10.323293685913086\n",
      "epoch:18 batch 770/2221) Loss:18.544944763183594\n",
      "epoch:18 batch 780/2221) Loss:11.56452751159668\n",
      "epoch:18 batch 790/2221) Loss:5.813961029052734\n",
      "epoch:18 batch 800/2221) Loss:26.53343963623047\n",
      "epoch:18 batch 810/2221) Loss:10.440317153930664\n",
      "epoch:18 batch 820/2221) Loss:25.815134048461914\n",
      "epoch:18 batch 830/2221) Loss:12.005470275878906\n",
      "epoch:18 batch 840/2221) Loss:3.079805612564087\n",
      "epoch:18 batch 850/2221) Loss:6.30409574508667\n",
      "epoch:18 batch 860/2221) Loss:22.333921432495117\n",
      "epoch:18 batch 870/2221) Loss:14.991473197937012\n",
      "epoch:18 batch 880/2221) Loss:12.22752571105957\n",
      "epoch:18 batch 890/2221) Loss:33.311546325683594\n",
      "epoch:18 batch 900/2221) Loss:15.35417366027832\n",
      "epoch:18 batch 910/2221) Loss:13.749788284301758\n",
      "epoch:18 batch 920/2221) Loss:7.3867998123168945\n",
      "epoch:18 batch 930/2221) Loss:2.887585163116455\n",
      "epoch:18 batch 940/2221) Loss:7.039300918579102\n",
      "epoch:18 batch 950/2221) Loss:22.74077796936035\n",
      "epoch:18 batch 960/2221) Loss:5.413147449493408\n",
      "epoch:18 batch 970/2221) Loss:13.279507637023926\n",
      "epoch:18 batch 980/2221) Loss:2.033189296722412\n",
      "epoch:18 batch 990/2221) Loss:18.148155212402344\n",
      "epoch:18 batch 1000/2221) Loss:1.4891650676727295\n",
      "epoch:18 batch 1010/2221) Loss:10.852510452270508\n",
      "epoch:18 batch 1020/2221) Loss:8.524080276489258\n",
      "epoch:18 batch 1030/2221) Loss:27.737424850463867\n",
      "epoch:18 batch 1040/2221) Loss:5.547280311584473\n",
      "epoch:18 batch 1050/2221) Loss:17.531253814697266\n",
      "epoch:18 batch 1060/2221) Loss:22.6148738861084\n",
      "epoch:18 batch 1070/2221) Loss:9.839424133300781\n",
      "epoch:18 batch 1080/2221) Loss:10.335318565368652\n",
      "epoch:18 batch 1090/2221) Loss:8.77126693725586\n",
      "epoch:18 batch 1100/2221) Loss:7.845620155334473\n",
      "epoch:18 batch 1110/2221) Loss:32.41254425048828\n",
      "epoch:18 batch 1120/2221) Loss:2.2473273277282715\n",
      "epoch:18 batch 1130/2221) Loss:6.445919990539551\n",
      "epoch:18 batch 1140/2221) Loss:43.93860626220703\n",
      "epoch:18 batch 1150/2221) Loss:22.558008193969727\n",
      "epoch:18 batch 1160/2221) Loss:16.818933486938477\n",
      "epoch:18 batch 1170/2221) Loss:20.135761260986328\n",
      "epoch:18 batch 1180/2221) Loss:13.215682983398438\n",
      "epoch:18 batch 1190/2221) Loss:19.991830825805664\n",
      "epoch:18 batch 1200/2221) Loss:33.099178314208984\n",
      "epoch:18 batch 1210/2221) Loss:18.342487335205078\n",
      "epoch:18 batch 1220/2221) Loss:8.826980590820312\n",
      "epoch:18 batch 1230/2221) Loss:11.855640411376953\n",
      "epoch:18 batch 1240/2221) Loss:2.2145581245422363\n",
      "epoch:18 batch 1250/2221) Loss:27.66477394104004\n",
      "epoch:18 batch 1260/2221) Loss:5.15778112411499\n",
      "epoch:18 batch 1270/2221) Loss:11.740924835205078\n",
      "epoch:18 batch 1280/2221) Loss:8.841150283813477\n",
      "epoch:18 batch 1290/2221) Loss:19.068761825561523\n",
      "epoch:18 batch 1300/2221) Loss:9.16071891784668\n",
      "epoch:18 batch 1310/2221) Loss:8.040515899658203\n",
      "epoch:18 batch 1320/2221) Loss:5.097788333892822\n",
      "epoch:18 batch 1330/2221) Loss:6.983872413635254\n",
      "epoch:18 batch 1340/2221) Loss:6.300678253173828\n",
      "epoch:18 batch 1350/2221) Loss:20.73869514465332\n",
      "epoch:18 batch 1360/2221) Loss:27.072128295898438\n",
      "epoch:18 batch 1370/2221) Loss:22.512540817260742\n",
      "epoch:18 batch 1380/2221) Loss:6.372990131378174\n",
      "epoch:18 batch 1390/2221) Loss:7.704390525817871\n",
      "epoch:18 batch 1400/2221) Loss:6.622746467590332\n",
      "epoch:18 batch 1410/2221) Loss:12.72111701965332\n",
      "epoch:18 batch 1420/2221) Loss:1.2851881980895996\n",
      "epoch:18 batch 1430/2221) Loss:16.501968383789062\n",
      "epoch:18 batch 1440/2221) Loss:14.59628963470459\n",
      "epoch:18 batch 1450/2221) Loss:5.33490514755249\n",
      "epoch:18 batch 1460/2221) Loss:1.5714168548583984\n",
      "epoch:18 batch 1470/2221) Loss:16.88409423828125\n",
      "epoch:18 batch 1480/2221) Loss:7.835971832275391\n",
      "epoch:18 batch 1490/2221) Loss:13.753185272216797\n",
      "epoch:18 batch 1500/2221) Loss:22.97600746154785\n",
      "epoch:18 batch 1510/2221) Loss:26.818872451782227\n",
      "epoch:18 batch 1520/2221) Loss:3.3139452934265137\n",
      "epoch:18 batch 1530/2221) Loss:13.06289291381836\n",
      "epoch:18 batch 1540/2221) Loss:20.17009925842285\n",
      "epoch:18 batch 1550/2221) Loss:6.750356197357178\n",
      "epoch:18 batch 1560/2221) Loss:12.784137725830078\n",
      "epoch:18 batch 1570/2221) Loss:28.211627960205078\n",
      "epoch:18 batch 1580/2221) Loss:13.435201644897461\n",
      "epoch:18 batch 1590/2221) Loss:14.593881607055664\n",
      "epoch:18 batch 1600/2221) Loss:7.688786029815674\n",
      "epoch:18 batch 1610/2221) Loss:6.544927597045898\n",
      "epoch:18 batch 1620/2221) Loss:3.0018601417541504\n",
      "epoch:18 batch 1630/2221) Loss:6.528160095214844\n",
      "epoch:18 batch 1640/2221) Loss:17.741432189941406\n",
      "epoch:18 batch 1650/2221) Loss:8.291214942932129\n",
      "epoch:18 batch 1660/2221) Loss:16.660850524902344\n",
      "epoch:18 batch 1670/2221) Loss:10.536690711975098\n",
      "epoch:18 batch 1680/2221) Loss:2.983858585357666\n",
      "epoch:18 batch 1690/2221) Loss:21.98806381225586\n",
      "epoch:18 batch 1700/2221) Loss:15.705389976501465\n",
      "epoch:18 batch 1710/2221) Loss:19.03945541381836\n",
      "epoch:18 batch 1720/2221) Loss:11.89676284790039\n",
      "epoch:18 batch 1730/2221) Loss:5.456643104553223\n",
      "epoch:18 batch 1740/2221) Loss:25.98251724243164\n",
      "epoch:18 batch 1750/2221) Loss:6.028981685638428\n",
      "epoch:18 batch 1760/2221) Loss:11.58852767944336\n",
      "epoch:18 batch 1770/2221) Loss:3.7372589111328125\n",
      "epoch:18 batch 1780/2221) Loss:15.177043914794922\n",
      "epoch:18 batch 1790/2221) Loss:7.198018550872803\n",
      "epoch:18 batch 1800/2221) Loss:6.794121265411377\n",
      "epoch:18 batch 1810/2221) Loss:15.401511192321777\n",
      "epoch:18 batch 1820/2221) Loss:12.71073055267334\n",
      "epoch:18 batch 1830/2221) Loss:14.76342487335205\n",
      "epoch:18 batch 1840/2221) Loss:11.499736785888672\n",
      "epoch:18 batch 1850/2221) Loss:7.303208351135254\n",
      "epoch:18 batch 1860/2221) Loss:4.799195766448975\n",
      "epoch:18 batch 1870/2221) Loss:47.286094665527344\n",
      "epoch:18 batch 1880/2221) Loss:17.05057716369629\n",
      "epoch:18 batch 1890/2221) Loss:16.389812469482422\n",
      "epoch:18 batch 1900/2221) Loss:19.96723175048828\n",
      "epoch:18 batch 1910/2221) Loss:11.67776870727539\n",
      "epoch:18 batch 1920/2221) Loss:30.42557144165039\n",
      "epoch:18 batch 1930/2221) Loss:19.367393493652344\n",
      "epoch:18 batch 1940/2221) Loss:21.29418182373047\n",
      "epoch:18 batch 1950/2221) Loss:3.0735771656036377\n",
      "epoch:18 batch 1960/2221) Loss:15.674554824829102\n",
      "epoch:18 batch 1970/2221) Loss:15.3472318649292\n",
      "epoch:18 batch 1980/2221) Loss:2.483440637588501\n",
      "epoch:18 batch 1990/2221) Loss:25.95944595336914\n",
      "epoch:18 batch 2000/2221) Loss:46.15568542480469\n",
      "epoch:18 batch 2010/2221) Loss:14.161994934082031\n",
      "epoch:18 batch 2020/2221) Loss:18.31749725341797\n",
      "epoch:18 batch 2030/2221) Loss:5.91082239151001\n",
      "epoch:18 batch 2040/2221) Loss:10.830253601074219\n",
      "epoch:18 batch 2050/2221) Loss:18.531312942504883\n",
      "epoch:18 batch 2060/2221) Loss:14.551427841186523\n",
      "epoch:18 batch 2070/2221) Loss:11.022003173828125\n",
      "epoch:18 batch 2080/2221) Loss:10.916595458984375\n",
      "epoch:18 batch 2090/2221) Loss:13.011899948120117\n",
      "epoch:18 batch 2100/2221) Loss:10.72420597076416\n",
      "epoch:18 batch 2110/2221) Loss:5.168302059173584\n",
      "epoch:18 batch 2120/2221) Loss:13.102275848388672\n",
      "epoch:18 batch 2130/2221) Loss:14.432312965393066\n",
      "epoch:18 batch 2140/2221) Loss:10.985179901123047\n",
      "epoch:18 batch 2150/2221) Loss:24.51526641845703\n",
      "epoch:18 batch 2160/2221) Loss:19.244714736938477\n",
      "epoch:18 batch 2170/2221) Loss:6.518364906311035\n",
      "epoch:18 batch 2180/2221) Loss:14.180017471313477\n",
      "epoch:18 batch 2190/2221) Loss:24.768657684326172\n",
      "epoch:18 batch 2200/2221) Loss:14.115729331970215\n",
      "epoch:18 batch 2210/2221) Loss:7.465463638305664\n",
      "epoch:18 batch 2220/2221) Loss:16.71666717529297\n",
      "epoch:18 precision:0.9966479633580351 recall:0.9862371914500022 f1-score:0.9913265005383478\n",
      "epoch:19 batch 1/2221) Loss:12.789104461669922\n",
      "epoch:19 batch 10/2221) Loss:22.038785934448242\n",
      "epoch:19 batch 20/2221) Loss:14.649781227111816\n",
      "epoch:19 batch 30/2221) Loss:6.750973701477051\n",
      "epoch:19 batch 40/2221) Loss:13.09045696258545\n",
      "epoch:19 batch 50/2221) Loss:14.148496627807617\n",
      "epoch:19 batch 60/2221) Loss:4.02705192565918\n",
      "epoch:19 batch 70/2221) Loss:8.843123435974121\n",
      "epoch:19 batch 80/2221) Loss:9.1166353225708\n",
      "epoch:19 batch 90/2221) Loss:11.19570541381836\n",
      "epoch:19 batch 100/2221) Loss:9.649750709533691\n",
      "epoch:19 batch 110/2221) Loss:9.980535507202148\n",
      "epoch:19 batch 120/2221) Loss:14.525946617126465\n",
      "epoch:19 batch 130/2221) Loss:6.682974338531494\n",
      "epoch:19 batch 140/2221) Loss:10.337615013122559\n",
      "epoch:19 batch 150/2221) Loss:12.445198059082031\n",
      "epoch:19 batch 160/2221) Loss:6.708301544189453\n",
      "epoch:19 batch 170/2221) Loss:3.100079298019409\n",
      "epoch:19 batch 180/2221) Loss:4.762361526489258\n",
      "epoch:19 batch 190/2221) Loss:26.978763580322266\n",
      "epoch:19 batch 200/2221) Loss:4.537755489349365\n",
      "epoch:19 batch 210/2221) Loss:3.857048749923706\n",
      "epoch:19 batch 220/2221) Loss:7.6654486656188965\n",
      "epoch:19 batch 230/2221) Loss:4.238121032714844\n",
      "epoch:19 batch 240/2221) Loss:18.298200607299805\n",
      "epoch:19 batch 250/2221) Loss:8.357407569885254\n",
      "epoch:19 batch 260/2221) Loss:25.997440338134766\n",
      "epoch:19 batch 270/2221) Loss:21.232969284057617\n",
      "epoch:19 batch 280/2221) Loss:2.061870574951172\n",
      "epoch:19 batch 290/2221) Loss:11.04437255859375\n",
      "epoch:19 batch 300/2221) Loss:5.775637149810791\n",
      "epoch:19 batch 310/2221) Loss:11.452630996704102\n",
      "epoch:19 batch 320/2221) Loss:7.482085704803467\n",
      "epoch:19 batch 330/2221) Loss:35.295372009277344\n",
      "epoch:19 batch 340/2221) Loss:22.989028930664062\n",
      "epoch:19 batch 350/2221) Loss:6.114468574523926\n",
      "epoch:19 batch 360/2221) Loss:7.632026672363281\n",
      "epoch:19 batch 370/2221) Loss:7.684020042419434\n",
      "epoch:19 batch 380/2221) Loss:12.843109130859375\n",
      "epoch:19 batch 390/2221) Loss:14.07465934753418\n",
      "epoch:19 batch 400/2221) Loss:5.695807456970215\n",
      "epoch:19 batch 410/2221) Loss:16.41282844543457\n",
      "epoch:19 batch 420/2221) Loss:12.907095909118652\n",
      "epoch:19 batch 430/2221) Loss:5.1022186279296875\n",
      "epoch:19 batch 440/2221) Loss:2.171048402786255\n",
      "epoch:19 batch 450/2221) Loss:11.647130966186523\n",
      "epoch:19 batch 460/2221) Loss:19.006608963012695\n",
      "epoch:19 batch 470/2221) Loss:18.056320190429688\n",
      "epoch:19 batch 480/2221) Loss:24.11043930053711\n",
      "epoch:19 batch 490/2221) Loss:16.79145622253418\n",
      "epoch:19 batch 500/2221) Loss:15.320270538330078\n",
      "epoch:19 batch 510/2221) Loss:11.325122833251953\n",
      "epoch:19 batch 520/2221) Loss:5.911306381225586\n",
      "epoch:19 batch 530/2221) Loss:7.66977596282959\n",
      "epoch:19 batch 540/2221) Loss:10.238607406616211\n",
      "epoch:19 batch 550/2221) Loss:7.2967071533203125\n",
      "epoch:19 batch 560/2221) Loss:11.541437149047852\n",
      "epoch:19 batch 570/2221) Loss:15.113861083984375\n",
      "epoch:19 batch 580/2221) Loss:8.841852188110352\n",
      "epoch:19 batch 590/2221) Loss:13.839639663696289\n",
      "epoch:19 batch 600/2221) Loss:18.01186752319336\n",
      "epoch:19 batch 610/2221) Loss:12.14470386505127\n",
      "epoch:19 batch 620/2221) Loss:20.730640411376953\n",
      "epoch:19 batch 630/2221) Loss:21.799753189086914\n",
      "epoch:19 batch 640/2221) Loss:5.5705037117004395\n",
      "epoch:19 batch 650/2221) Loss:1.023662805557251\n",
      "epoch:19 batch 660/2221) Loss:8.084125518798828\n",
      "epoch:19 batch 670/2221) Loss:39.02364730834961\n",
      "epoch:19 batch 680/2221) Loss:23.577529907226562\n",
      "epoch:19 batch 690/2221) Loss:2.513305902481079\n",
      "epoch:19 batch 700/2221) Loss:21.98986053466797\n",
      "epoch:19 batch 710/2221) Loss:8.916749954223633\n",
      "epoch:19 batch 720/2221) Loss:19.381237030029297\n",
      "epoch:19 batch 730/2221) Loss:6.413011074066162\n",
      "epoch:19 batch 740/2221) Loss:12.350116729736328\n",
      "epoch:19 batch 750/2221) Loss:6.622427940368652\n",
      "epoch:19 batch 760/2221) Loss:37.629554748535156\n",
      "epoch:19 batch 770/2221) Loss:12.001523971557617\n",
      "epoch:19 batch 780/2221) Loss:8.197600364685059\n",
      "epoch:19 batch 790/2221) Loss:13.607523918151855\n",
      "epoch:19 batch 800/2221) Loss:8.45412826538086\n",
      "epoch:19 batch 810/2221) Loss:9.13448715209961\n",
      "epoch:19 batch 820/2221) Loss:16.22222900390625\n",
      "epoch:19 batch 830/2221) Loss:11.885964393615723\n",
      "epoch:19 batch 840/2221) Loss:4.639245986938477\n",
      "epoch:19 batch 850/2221) Loss:15.135952949523926\n",
      "epoch:19 batch 860/2221) Loss:10.192399978637695\n",
      "epoch:19 batch 870/2221) Loss:8.63896369934082\n",
      "epoch:19 batch 880/2221) Loss:17.05512809753418\n",
      "epoch:19 batch 890/2221) Loss:52.47065353393555\n",
      "epoch:19 batch 900/2221) Loss:20.594514846801758\n",
      "epoch:19 batch 910/2221) Loss:16.26879119873047\n",
      "epoch:19 batch 920/2221) Loss:23.182315826416016\n",
      "epoch:19 batch 930/2221) Loss:34.19035720825195\n",
      "epoch:19 batch 940/2221) Loss:11.126989364624023\n",
      "epoch:19 batch 950/2221) Loss:9.056841850280762\n",
      "epoch:19 batch 960/2221) Loss:31.419078826904297\n",
      "epoch:19 batch 970/2221) Loss:31.17548370361328\n",
      "epoch:19 batch 980/2221) Loss:2.8493990898132324\n",
      "epoch:19 batch 990/2221) Loss:11.760811805725098\n",
      "epoch:19 batch 1000/2221) Loss:8.411392211914062\n",
      "epoch:19 batch 1010/2221) Loss:20.431053161621094\n",
      "epoch:19 batch 1020/2221) Loss:17.412137985229492\n",
      "epoch:19 batch 1030/2221) Loss:14.201105117797852\n",
      "epoch:19 batch 1040/2221) Loss:7.430784225463867\n",
      "epoch:19 batch 1050/2221) Loss:3.051288604736328\n",
      "epoch:19 batch 1060/2221) Loss:10.605683326721191\n",
      "epoch:19 batch 1070/2221) Loss:2.673931121826172\n",
      "epoch:19 batch 1080/2221) Loss:10.820868492126465\n",
      "epoch:19 batch 1090/2221) Loss:16.07183074951172\n",
      "epoch:19 batch 1100/2221) Loss:5.888579368591309\n",
      "epoch:19 batch 1110/2221) Loss:24.125585556030273\n",
      "epoch:19 batch 1120/2221) Loss:4.041781425476074\n",
      "epoch:19 batch 1130/2221) Loss:1.737959384918213\n",
      "epoch:19 batch 1140/2221) Loss:18.603506088256836\n",
      "epoch:19 batch 1150/2221) Loss:13.6427583694458\n",
      "epoch:19 batch 1160/2221) Loss:17.934066772460938\n",
      "epoch:19 batch 1170/2221) Loss:29.74799919128418\n",
      "epoch:19 batch 1180/2221) Loss:14.12812614440918\n",
      "epoch:19 batch 1190/2221) Loss:7.856916427612305\n",
      "epoch:19 batch 1200/2221) Loss:8.915794372558594\n",
      "epoch:19 batch 1210/2221) Loss:3.815958261489868\n",
      "epoch:19 batch 1220/2221) Loss:8.678773880004883\n",
      "epoch:19 batch 1230/2221) Loss:8.106651306152344\n",
      "epoch:19 batch 1240/2221) Loss:24.30649185180664\n",
      "epoch:19 batch 1250/2221) Loss:12.67127799987793\n",
      "epoch:19 batch 1260/2221) Loss:10.98917007446289\n",
      "epoch:19 batch 1270/2221) Loss:7.274724960327148\n",
      "epoch:19 batch 1280/2221) Loss:6.806136608123779\n",
      "epoch:19 batch 1290/2221) Loss:4.49886417388916\n",
      "epoch:19 batch 1300/2221) Loss:9.466543197631836\n",
      "epoch:19 batch 1310/2221) Loss:3.9120523929595947\n",
      "epoch:19 batch 1320/2221) Loss:2.396024703979492\n",
      "epoch:19 batch 1330/2221) Loss:8.422391891479492\n",
      "epoch:19 batch 1340/2221) Loss:32.08934020996094\n",
      "epoch:19 batch 1350/2221) Loss:5.679784774780273\n",
      "epoch:19 batch 1360/2221) Loss:5.4619140625\n",
      "epoch:19 batch 1370/2221) Loss:9.47198486328125\n",
      "epoch:19 batch 1380/2221) Loss:10.607195854187012\n",
      "epoch:19 batch 1390/2221) Loss:8.50072956085205\n",
      "epoch:19 batch 1400/2221) Loss:8.094149589538574\n",
      "epoch:19 batch 1410/2221) Loss:10.15239429473877\n",
      "epoch:19 batch 1420/2221) Loss:4.866615295410156\n",
      "epoch:19 batch 1430/2221) Loss:5.324306488037109\n",
      "epoch:19 batch 1440/2221) Loss:15.381295204162598\n",
      "epoch:19 batch 1450/2221) Loss:1.9533233642578125\n",
      "epoch:19 batch 1460/2221) Loss:13.590607643127441\n",
      "epoch:19 batch 1470/2221) Loss:6.7088212966918945\n",
      "epoch:19 batch 1480/2221) Loss:11.346914291381836\n",
      "epoch:19 batch 1490/2221) Loss:1.4457000494003296\n",
      "epoch:19 batch 1500/2221) Loss:16.703609466552734\n",
      "epoch:19 batch 1510/2221) Loss:22.314468383789062\n",
      "epoch:19 batch 1520/2221) Loss:22.508522033691406\n",
      "epoch:19 batch 1530/2221) Loss:16.829635620117188\n",
      "epoch:19 batch 1540/2221) Loss:12.463555335998535\n",
      "epoch:19 batch 1550/2221) Loss:2.518319606781006\n",
      "epoch:19 batch 1560/2221) Loss:5.3585429191589355\n",
      "epoch:19 batch 1570/2221) Loss:14.814591407775879\n",
      "epoch:19 batch 1580/2221) Loss:23.507688522338867\n",
      "epoch:19 batch 1590/2221) Loss:14.015905380249023\n",
      "epoch:19 batch 1600/2221) Loss:3.745650291442871\n",
      "epoch:19 batch 1610/2221) Loss:14.099627494812012\n",
      "epoch:19 batch 1620/2221) Loss:17.397184371948242\n",
      "epoch:19 batch 1630/2221) Loss:5.4355788230896\n",
      "epoch:19 batch 1640/2221) Loss:2.8480570316314697\n",
      "epoch:19 batch 1650/2221) Loss:13.609996795654297\n",
      "epoch:19 batch 1660/2221) Loss:2.572214365005493\n",
      "epoch:19 batch 1670/2221) Loss:6.31339168548584\n",
      "epoch:19 batch 1680/2221) Loss:10.183151245117188\n",
      "epoch:19 batch 1690/2221) Loss:6.223861217498779\n",
      "epoch:19 batch 1700/2221) Loss:20.39462661743164\n",
      "epoch:19 batch 1710/2221) Loss:8.935054779052734\n",
      "epoch:19 batch 1720/2221) Loss:1.8076269626617432\n",
      "epoch:19 batch 1730/2221) Loss:11.078554153442383\n",
      "epoch:19 batch 1740/2221) Loss:18.32802391052246\n",
      "epoch:19 batch 1750/2221) Loss:19.96739959716797\n",
      "epoch:19 batch 1760/2221) Loss:10.590130805969238\n",
      "epoch:19 batch 1770/2221) Loss:3.6414942741394043\n",
      "epoch:19 batch 1780/2221) Loss:8.133588790893555\n",
      "epoch:19 batch 1790/2221) Loss:14.434484481811523\n",
      "epoch:19 batch 1800/2221) Loss:4.738659858703613\n",
      "epoch:19 batch 1810/2221) Loss:8.862918853759766\n",
      "epoch:19 batch 1820/2221) Loss:5.352130889892578\n",
      "epoch:19 batch 1830/2221) Loss:11.860225677490234\n",
      "epoch:19 batch 1840/2221) Loss:4.943824291229248\n",
      "epoch:19 batch 1850/2221) Loss:2.9258031845092773\n",
      "epoch:19 batch 1860/2221) Loss:7.721029758453369\n",
      "epoch:19 batch 1870/2221) Loss:9.474174499511719\n",
      "epoch:19 batch 1880/2221) Loss:6.586060523986816\n",
      "epoch:19 batch 1890/2221) Loss:9.452981948852539\n",
      "epoch:19 batch 1900/2221) Loss:7.946541786193848\n",
      "epoch:19 batch 1910/2221) Loss:16.79421043395996\n",
      "epoch:19 batch 1920/2221) Loss:40.902347564697266\n",
      "epoch:19 batch 1930/2221) Loss:6.805546283721924\n",
      "epoch:19 batch 1940/2221) Loss:9.212603569030762\n",
      "epoch:19 batch 1950/2221) Loss:16.485143661499023\n",
      "epoch:19 batch 1960/2221) Loss:5.140888214111328\n",
      "epoch:19 batch 1970/2221) Loss:2.227128028869629\n",
      "epoch:19 batch 1980/2221) Loss:4.183916091918945\n",
      "epoch:19 batch 1990/2221) Loss:11.12959098815918\n",
      "epoch:19 batch 2000/2221) Loss:9.023548126220703\n",
      "epoch:19 batch 2010/2221) Loss:6.031397819519043\n",
      "epoch:19 batch 2020/2221) Loss:10.401331901550293\n",
      "epoch:19 batch 2030/2221) Loss:5.072913646697998\n",
      "epoch:19 batch 2040/2221) Loss:19.92359161376953\n",
      "epoch:19 batch 2050/2221) Loss:8.515506744384766\n",
      "epoch:19 batch 2060/2221) Loss:5.283356666564941\n",
      "epoch:19 batch 2070/2221) Loss:9.063972473144531\n",
      "epoch:19 batch 2080/2221) Loss:10.61336898803711\n",
      "epoch:19 batch 2090/2221) Loss:7.419000625610352\n",
      "epoch:19 batch 2100/2221) Loss:19.543092727661133\n",
      "epoch:19 batch 2110/2221) Loss:3.6509006023406982\n",
      "epoch:19 batch 2120/2221) Loss:14.623035430908203\n",
      "epoch:19 batch 2130/2221) Loss:16.66344451904297\n",
      "epoch:19 batch 2140/2221) Loss:14.326634407043457\n",
      "epoch:19 batch 2150/2221) Loss:5.467027187347412\n",
      "epoch:19 batch 2160/2221) Loss:13.753612518310547\n",
      "epoch:19 batch 2170/2221) Loss:9.843612670898438\n",
      "epoch:19 batch 2180/2221) Loss:3.435704231262207\n",
      "epoch:19 batch 2190/2221) Loss:10.952436447143555\n",
      "epoch:19 batch 2200/2221) Loss:9.811893463134766\n",
      "epoch:19 batch 2210/2221) Loss:35.020721435546875\n",
      "epoch:19 batch 2220/2221) Loss:22.43057632446289\n",
      "epoch:19 precision:0.9970352309941706 recall:0.9870503629866736 f1-score:0.9919230395849544\n",
      "epoch:20 batch 1/2221) Loss:4.714766502380371\n",
      "epoch:20 batch 10/2221) Loss:9.122398376464844\n",
      "epoch:20 batch 20/2221) Loss:6.556952476501465\n",
      "epoch:20 batch 30/2221) Loss:21.40728759765625\n",
      "epoch:20 batch 40/2221) Loss:7.210829734802246\n",
      "epoch:20 batch 50/2221) Loss:4.342242240905762\n",
      "epoch:20 batch 60/2221) Loss:5.152791976928711\n",
      "epoch:20 batch 70/2221) Loss:9.824348449707031\n",
      "epoch:20 batch 80/2221) Loss:9.45317268371582\n",
      "epoch:20 batch 90/2221) Loss:15.781871795654297\n",
      "epoch:20 batch 100/2221) Loss:6.69457483291626\n",
      "epoch:20 batch 110/2221) Loss:10.382708549499512\n",
      "epoch:20 batch 120/2221) Loss:3.671363115310669\n",
      "epoch:20 batch 130/2221) Loss:5.832529544830322\n",
      "epoch:20 batch 140/2221) Loss:4.284489154815674\n",
      "epoch:20 batch 150/2221) Loss:9.949995040893555\n",
      "epoch:20 batch 160/2221) Loss:8.55204963684082\n",
      "epoch:20 batch 170/2221) Loss:9.593889236450195\n",
      "epoch:20 batch 180/2221) Loss:5.16147518157959\n",
      "epoch:20 batch 190/2221) Loss:4.325450420379639\n",
      "epoch:20 batch 200/2221) Loss:27.249465942382812\n",
      "epoch:20 batch 210/2221) Loss:18.329776763916016\n",
      "epoch:20 batch 220/2221) Loss:1.4429203271865845\n",
      "epoch:20 batch 230/2221) Loss:14.308023452758789\n",
      "epoch:20 batch 240/2221) Loss:8.473710060119629\n",
      "epoch:20 batch 250/2221) Loss:9.336932182312012\n",
      "epoch:20 batch 260/2221) Loss:7.461513042449951\n",
      "epoch:20 batch 270/2221) Loss:4.148553848266602\n",
      "epoch:20 batch 280/2221) Loss:8.032783508300781\n",
      "epoch:20 batch 290/2221) Loss:7.173732280731201\n",
      "epoch:20 batch 300/2221) Loss:13.086784362792969\n",
      "epoch:20 batch 310/2221) Loss:14.066960334777832\n",
      "epoch:20 batch 320/2221) Loss:31.313600540161133\n",
      "epoch:20 batch 330/2221) Loss:9.034690856933594\n",
      "epoch:20 batch 340/2221) Loss:3.6960949897766113\n",
      "epoch:20 batch 350/2221) Loss:10.27316665649414\n",
      "epoch:20 batch 360/2221) Loss:10.150141716003418\n",
      "epoch:20 batch 370/2221) Loss:12.899781227111816\n",
      "epoch:20 batch 380/2221) Loss:4.184195518493652\n",
      "epoch:20 batch 390/2221) Loss:3.8454182147979736\n",
      "epoch:20 batch 400/2221) Loss:6.182504177093506\n",
      "epoch:20 batch 410/2221) Loss:11.523204803466797\n",
      "epoch:20 batch 420/2221) Loss:38.79027557373047\n",
      "epoch:20 batch 430/2221) Loss:20.765871047973633\n",
      "epoch:20 batch 440/2221) Loss:7.469500541687012\n",
      "epoch:20 batch 450/2221) Loss:17.787561416625977\n",
      "epoch:20 batch 460/2221) Loss:3.00549578666687\n",
      "epoch:20 batch 470/2221) Loss:5.267144203186035\n",
      "epoch:20 batch 480/2221) Loss:23.615819931030273\n",
      "epoch:20 batch 490/2221) Loss:12.956143379211426\n",
      "epoch:20 batch 500/2221) Loss:5.660619735717773\n",
      "epoch:20 batch 510/2221) Loss:21.634048461914062\n",
      "epoch:20 batch 520/2221) Loss:15.614410400390625\n",
      "epoch:20 batch 530/2221) Loss:12.123165130615234\n",
      "epoch:20 batch 540/2221) Loss:6.193965911865234\n",
      "epoch:20 batch 550/2221) Loss:8.355257034301758\n",
      "epoch:20 batch 560/2221) Loss:33.78858184814453\n",
      "epoch:20 batch 570/2221) Loss:7.975033760070801\n",
      "epoch:20 batch 580/2221) Loss:4.306858062744141\n",
      "epoch:20 batch 590/2221) Loss:8.407238006591797\n",
      "epoch:20 batch 600/2221) Loss:5.887498378753662\n",
      "epoch:20 batch 610/2221) Loss:19.709156036376953\n",
      "epoch:20 batch 620/2221) Loss:20.0067195892334\n",
      "epoch:20 batch 630/2221) Loss:15.367032051086426\n",
      "epoch:20 batch 640/2221) Loss:15.551033020019531\n",
      "epoch:20 batch 650/2221) Loss:4.514135360717773\n",
      "epoch:20 batch 660/2221) Loss:25.06279754638672\n",
      "epoch:20 batch 670/2221) Loss:2.95074462890625\n",
      "epoch:20 batch 680/2221) Loss:5.255319595336914\n",
      "epoch:20 batch 690/2221) Loss:7.466670513153076\n",
      "epoch:20 batch 700/2221) Loss:12.11686897277832\n",
      "epoch:20 batch 710/2221) Loss:3.6861371994018555\n",
      "epoch:20 batch 720/2221) Loss:20.46603775024414\n",
      "epoch:20 batch 730/2221) Loss:1.8565218448638916\n",
      "epoch:20 batch 740/2221) Loss:29.62813377380371\n",
      "epoch:20 batch 750/2221) Loss:3.2441506385803223\n",
      "epoch:20 batch 760/2221) Loss:33.79007339477539\n",
      "epoch:20 batch 770/2221) Loss:3.4913315773010254\n",
      "epoch:20 batch 780/2221) Loss:11.800771713256836\n",
      "epoch:20 batch 790/2221) Loss:13.957359313964844\n",
      "epoch:20 batch 800/2221) Loss:0.9815369844436646\n",
      "epoch:20 batch 810/2221) Loss:17.41958999633789\n",
      "epoch:20 batch 820/2221) Loss:5.472561359405518\n",
      "epoch:20 batch 830/2221) Loss:18.046215057373047\n",
      "epoch:20 batch 840/2221) Loss:12.395255088806152\n",
      "epoch:20 batch 850/2221) Loss:7.058557510375977\n",
      "epoch:20 batch 860/2221) Loss:8.794207572937012\n",
      "epoch:20 batch 870/2221) Loss:7.831637859344482\n",
      "epoch:20 batch 880/2221) Loss:2.095548629760742\n",
      "epoch:20 batch 890/2221) Loss:5.7407121658325195\n",
      "epoch:20 batch 900/2221) Loss:2.395031452178955\n",
      "epoch:20 batch 910/2221) Loss:18.10755157470703\n",
      "epoch:20 batch 920/2221) Loss:7.292094707489014\n",
      "epoch:20 batch 930/2221) Loss:19.754478454589844\n",
      "epoch:20 batch 940/2221) Loss:8.718069076538086\n",
      "epoch:20 batch 950/2221) Loss:25.030555725097656\n",
      "epoch:20 batch 960/2221) Loss:5.225407600402832\n",
      "epoch:20 batch 970/2221) Loss:22.34358787536621\n",
      "epoch:20 batch 980/2221) Loss:19.008914947509766\n",
      "epoch:20 batch 990/2221) Loss:16.923873901367188\n",
      "epoch:20 batch 1000/2221) Loss:12.714444160461426\n",
      "epoch:20 batch 1010/2221) Loss:11.457178115844727\n",
      "epoch:20 batch 1020/2221) Loss:14.162225723266602\n",
      "epoch:20 batch 1030/2221) Loss:5.219921112060547\n",
      "epoch:20 batch 1040/2221) Loss:11.746614456176758\n",
      "epoch:20 batch 1050/2221) Loss:4.774988651275635\n",
      "epoch:20 batch 1060/2221) Loss:15.548513412475586\n",
      "epoch:20 batch 1070/2221) Loss:2.049388885498047\n",
      "epoch:20 batch 1080/2221) Loss:10.458185195922852\n",
      "epoch:20 batch 1090/2221) Loss:4.567775726318359\n",
      "epoch:20 batch 1100/2221) Loss:9.077180862426758\n",
      "epoch:20 batch 1110/2221) Loss:3.7866454124450684\n",
      "epoch:20 batch 1120/2221) Loss:20.20656394958496\n",
      "epoch:20 batch 1130/2221) Loss:10.38567066192627\n",
      "epoch:20 batch 1140/2221) Loss:14.875425338745117\n",
      "epoch:20 batch 1150/2221) Loss:11.890052795410156\n",
      "epoch:20 batch 1160/2221) Loss:22.148969650268555\n",
      "epoch:20 batch 1170/2221) Loss:12.756661415100098\n",
      "epoch:20 batch 1180/2221) Loss:1.244370698928833\n",
      "epoch:20 batch 1190/2221) Loss:11.874505043029785\n",
      "epoch:20 batch 1200/2221) Loss:28.441919326782227\n",
      "epoch:20 batch 1210/2221) Loss:20.09124755859375\n",
      "epoch:20 batch 1220/2221) Loss:10.7196683883667\n",
      "epoch:20 batch 1230/2221) Loss:18.066774368286133\n",
      "epoch:20 batch 1240/2221) Loss:8.679911613464355\n",
      "epoch:20 batch 1250/2221) Loss:18.110984802246094\n",
      "epoch:20 batch 1260/2221) Loss:4.7366814613342285\n",
      "epoch:20 batch 1270/2221) Loss:67.23445129394531\n",
      "epoch:20 batch 1280/2221) Loss:2.677133321762085\n",
      "epoch:20 batch 1290/2221) Loss:10.251938819885254\n",
      "epoch:20 batch 1300/2221) Loss:5.379567623138428\n",
      "epoch:20 batch 1310/2221) Loss:5.436951637268066\n",
      "epoch:20 batch 1320/2221) Loss:16.903352737426758\n",
      "epoch:20 batch 1330/2221) Loss:1.3796310424804688\n",
      "epoch:20 batch 1340/2221) Loss:3.6413986682891846\n",
      "epoch:20 batch 1350/2221) Loss:17.796035766601562\n",
      "epoch:20 batch 1360/2221) Loss:9.938383102416992\n",
      "epoch:20 batch 1370/2221) Loss:7.914436340332031\n",
      "epoch:20 batch 1380/2221) Loss:7.743071556091309\n",
      "epoch:20 batch 1390/2221) Loss:22.02402687072754\n",
      "epoch:20 batch 1400/2221) Loss:19.151723861694336\n",
      "epoch:20 batch 1410/2221) Loss:32.009521484375\n",
      "epoch:20 batch 1420/2221) Loss:2.4807310104370117\n",
      "epoch:20 batch 1430/2221) Loss:4.56460428237915\n",
      "epoch:20 batch 1440/2221) Loss:11.777792930603027\n",
      "epoch:20 batch 1450/2221) Loss:6.512727737426758\n",
      "epoch:20 batch 1460/2221) Loss:5.898275852203369\n",
      "epoch:20 batch 1470/2221) Loss:30.715179443359375\n",
      "epoch:20 batch 1480/2221) Loss:25.26913070678711\n",
      "epoch:20 batch 1490/2221) Loss:22.338253021240234\n",
      "epoch:20 batch 1500/2221) Loss:13.183870315551758\n",
      "epoch:20 batch 1510/2221) Loss:12.245153427124023\n",
      "epoch:20 batch 1520/2221) Loss:8.800848960876465\n",
      "epoch:20 batch 1530/2221) Loss:9.887859344482422\n",
      "epoch:20 batch 1540/2221) Loss:8.615592002868652\n",
      "epoch:20 batch 1550/2221) Loss:17.163799285888672\n",
      "epoch:20 batch 1560/2221) Loss:3.483783721923828\n",
      "epoch:20 batch 1570/2221) Loss:13.479135513305664\n",
      "epoch:20 batch 1580/2221) Loss:5.496296405792236\n",
      "epoch:20 batch 1590/2221) Loss:1.4364982843399048\n",
      "epoch:20 batch 1600/2221) Loss:16.465478897094727\n",
      "epoch:20 batch 1610/2221) Loss:7.420820236206055\n",
      "epoch:20 batch 1620/2221) Loss:4.305102348327637\n",
      "epoch:20 batch 1630/2221) Loss:4.286564350128174\n",
      "epoch:20 batch 1640/2221) Loss:3.0087099075317383\n",
      "epoch:20 batch 1650/2221) Loss:9.829553604125977\n",
      "epoch:20 batch 1660/2221) Loss:10.371210098266602\n",
      "epoch:20 batch 1670/2221) Loss:11.112117767333984\n",
      "epoch:20 batch 1680/2221) Loss:14.217811584472656\n",
      "epoch:20 batch 1690/2221) Loss:42.899940490722656\n",
      "epoch:20 batch 1700/2221) Loss:8.720324516296387\n",
      "epoch:20 batch 1710/2221) Loss:4.753986358642578\n",
      "epoch:20 batch 1720/2221) Loss:11.391949653625488\n",
      "epoch:20 batch 1730/2221) Loss:3.834883213043213\n",
      "epoch:20 batch 1740/2221) Loss:7.587588787078857\n",
      "epoch:20 batch 1750/2221) Loss:27.7241153717041\n",
      "epoch:20 batch 1760/2221) Loss:10.068458557128906\n",
      "epoch:20 batch 1770/2221) Loss:1.7297825813293457\n",
      "epoch:20 batch 1780/2221) Loss:25.066238403320312\n",
      "epoch:20 batch 1790/2221) Loss:6.646589279174805\n",
      "epoch:20 batch 1800/2221) Loss:6.301262855529785\n",
      "epoch:20 batch 1810/2221) Loss:11.35595703125\n",
      "epoch:20 batch 1820/2221) Loss:19.568363189697266\n",
      "epoch:20 batch 1830/2221) Loss:20.617107391357422\n",
      "epoch:20 batch 1840/2221) Loss:26.976478576660156\n",
      "epoch:20 batch 1850/2221) Loss:1.138020634651184\n",
      "epoch:20 batch 1860/2221) Loss:8.546262741088867\n",
      "epoch:20 batch 1870/2221) Loss:24.790138244628906\n",
      "epoch:20 batch 1880/2221) Loss:1.9102736711502075\n",
      "epoch:20 batch 1890/2221) Loss:6.848731994628906\n",
      "epoch:20 batch 1900/2221) Loss:12.236899375915527\n",
      "epoch:20 batch 1910/2221) Loss:7.0552144050598145\n",
      "epoch:20 batch 1920/2221) Loss:6.196572303771973\n",
      "epoch:20 batch 1930/2221) Loss:12.222602844238281\n",
      "epoch:20 batch 1940/2221) Loss:3.5623292922973633\n",
      "epoch:20 batch 1950/2221) Loss:22.851802825927734\n",
      "epoch:20 batch 1960/2221) Loss:4.270303726196289\n",
      "epoch:20 batch 1970/2221) Loss:13.298564910888672\n",
      "epoch:20 batch 1980/2221) Loss:21.14802360534668\n",
      "epoch:20 batch 1990/2221) Loss:3.2999427318573\n",
      "epoch:20 batch 2000/2221) Loss:12.113372802734375\n",
      "epoch:20 batch 2010/2221) Loss:9.529762268066406\n",
      "epoch:20 batch 2020/2221) Loss:5.7533650398254395\n",
      "epoch:20 batch 2030/2221) Loss:12.966475486755371\n",
      "epoch:20 batch 2040/2221) Loss:8.47384262084961\n",
      "epoch:20 batch 2050/2221) Loss:12.889946937561035\n",
      "epoch:20 batch 2060/2221) Loss:6.561924934387207\n",
      "epoch:20 batch 2070/2221) Loss:29.748106002807617\n",
      "epoch:20 batch 2080/2221) Loss:7.8425612449646\n",
      "epoch:20 batch 2090/2221) Loss:7.693915843963623\n",
      "epoch:20 batch 2100/2221) Loss:2.3149821758270264\n",
      "epoch:20 batch 2110/2221) Loss:4.577414512634277\n",
      "epoch:20 batch 2120/2221) Loss:15.75494384765625\n",
      "epoch:20 batch 2130/2221) Loss:2.813192367553711\n",
      "epoch:20 batch 2140/2221) Loss:4.330031394958496\n",
      "epoch:20 batch 2150/2221) Loss:5.741418838500977\n",
      "epoch:20 batch 2160/2221) Loss:16.382259368896484\n",
      "epoch:20 batch 2170/2221) Loss:7.735148906707764\n",
      "epoch:20 batch 2180/2221) Loss:5.636250019073486\n",
      "epoch:20 batch 2190/2221) Loss:29.321840286254883\n",
      "epoch:20 batch 2200/2221) Loss:6.007557392120361\n",
      "epoch:20 batch 2210/2221) Loss:9.37143325805664\n",
      "epoch:20 batch 2220/2221) Loss:9.558873176574707\n",
      "epoch:20 precision:0.9966728802574141 recall:0.9865251345201792 f1-score:0.9915077303581283\n",
      "epoch:21 batch 1/2221) Loss:4.681779861450195\n",
      "epoch:21 batch 10/2221) Loss:4.334632396697998\n",
      "epoch:21 batch 20/2221) Loss:10.715108871459961\n",
      "epoch:21 batch 30/2221) Loss:4.021728038787842\n",
      "epoch:21 batch 40/2221) Loss:12.797445297241211\n",
      "epoch:21 batch 50/2221) Loss:28.370559692382812\n",
      "epoch:21 batch 60/2221) Loss:17.607715606689453\n",
      "epoch:21 batch 70/2221) Loss:25.66084861755371\n",
      "epoch:21 batch 80/2221) Loss:17.289627075195312\n",
      "epoch:21 batch 90/2221) Loss:10.35171127319336\n",
      "epoch:21 batch 100/2221) Loss:11.65056037902832\n",
      "epoch:21 batch 110/2221) Loss:24.55608367919922\n",
      "epoch:21 batch 120/2221) Loss:13.397066116333008\n",
      "epoch:21 batch 130/2221) Loss:6.814298629760742\n",
      "epoch:21 batch 140/2221) Loss:15.595185279846191\n",
      "epoch:21 batch 150/2221) Loss:9.475931167602539\n",
      "epoch:21 batch 160/2221) Loss:14.559638977050781\n",
      "epoch:21 batch 170/2221) Loss:10.882548332214355\n",
      "epoch:21 batch 180/2221) Loss:3.248971462249756\n",
      "epoch:21 batch 190/2221) Loss:12.304811477661133\n",
      "epoch:21 batch 200/2221) Loss:11.102411270141602\n",
      "epoch:21 batch 210/2221) Loss:6.581939697265625\n",
      "epoch:21 batch 220/2221) Loss:6.569931507110596\n",
      "epoch:21 batch 230/2221) Loss:6.391460418701172\n",
      "epoch:21 batch 240/2221) Loss:10.622855186462402\n",
      "epoch:21 batch 250/2221) Loss:8.905462265014648\n",
      "epoch:21 batch 260/2221) Loss:2.6871204376220703\n",
      "epoch:21 batch 270/2221) Loss:12.979037284851074\n",
      "epoch:21 batch 280/2221) Loss:4.970087051391602\n",
      "epoch:21 batch 290/2221) Loss:2.2945899963378906\n",
      "epoch:21 batch 300/2221) Loss:4.485953330993652\n",
      "epoch:21 batch 310/2221) Loss:6.564950942993164\n",
      "epoch:21 batch 320/2221) Loss:9.086299896240234\n",
      "epoch:21 batch 330/2221) Loss:3.690410614013672\n",
      "epoch:21 batch 340/2221) Loss:5.180284023284912\n",
      "epoch:21 batch 350/2221) Loss:11.098865509033203\n",
      "epoch:21 batch 360/2221) Loss:10.578851699829102\n",
      "epoch:21 batch 370/2221) Loss:7.164010047912598\n",
      "epoch:21 batch 380/2221) Loss:4.102645397186279\n",
      "epoch:21 batch 390/2221) Loss:17.220386505126953\n",
      "epoch:21 batch 400/2221) Loss:13.930850982666016\n",
      "epoch:21 batch 410/2221) Loss:8.782402038574219\n",
      "epoch:21 batch 420/2221) Loss:10.916020393371582\n",
      "epoch:21 batch 430/2221) Loss:2.3168246746063232\n",
      "epoch:21 batch 440/2221) Loss:10.796889305114746\n",
      "epoch:21 batch 450/2221) Loss:3.2714195251464844\n",
      "epoch:21 batch 460/2221) Loss:3.7038111686706543\n",
      "epoch:21 batch 470/2221) Loss:7.226789951324463\n",
      "epoch:21 batch 480/2221) Loss:15.735395431518555\n",
      "epoch:21 batch 490/2221) Loss:10.089695930480957\n",
      "epoch:21 batch 500/2221) Loss:2.8667070865631104\n",
      "epoch:21 batch 510/2221) Loss:16.028032302856445\n",
      "epoch:21 batch 520/2221) Loss:8.263341903686523\n",
      "epoch:21 batch 530/2221) Loss:9.783439636230469\n",
      "epoch:21 batch 540/2221) Loss:4.182980060577393\n",
      "epoch:21 batch 550/2221) Loss:8.67573070526123\n",
      "epoch:21 batch 560/2221) Loss:5.083752632141113\n",
      "epoch:21 batch 570/2221) Loss:25.25094985961914\n",
      "epoch:21 batch 580/2221) Loss:19.973995208740234\n",
      "epoch:21 batch 590/2221) Loss:4.648078918457031\n",
      "epoch:21 batch 600/2221) Loss:11.122979164123535\n",
      "epoch:21 batch 610/2221) Loss:9.607355117797852\n",
      "epoch:21 batch 620/2221) Loss:4.032893180847168\n",
      "epoch:21 batch 630/2221) Loss:11.809181213378906\n",
      "epoch:21 batch 640/2221) Loss:7.256258010864258\n",
      "epoch:21 batch 650/2221) Loss:10.756216049194336\n",
      "epoch:21 batch 660/2221) Loss:7.10231351852417\n",
      "epoch:21 batch 670/2221) Loss:17.60736656188965\n",
      "epoch:21 batch 680/2221) Loss:12.653822898864746\n",
      "epoch:21 batch 690/2221) Loss:9.410390853881836\n",
      "epoch:21 batch 700/2221) Loss:13.580270767211914\n",
      "epoch:21 batch 710/2221) Loss:7.617666244506836\n",
      "epoch:21 batch 720/2221) Loss:5.220364570617676\n",
      "epoch:21 batch 730/2221) Loss:9.583332061767578\n",
      "epoch:21 batch 740/2221) Loss:2.615609645843506\n",
      "epoch:21 batch 750/2221) Loss:10.956172943115234\n",
      "epoch:21 batch 760/2221) Loss:14.607778549194336\n",
      "epoch:21 batch 770/2221) Loss:11.499678611755371\n",
      "epoch:21 batch 780/2221) Loss:11.08995532989502\n",
      "epoch:21 batch 790/2221) Loss:3.829310894012451\n",
      "epoch:21 batch 800/2221) Loss:7.876473426818848\n",
      "epoch:21 batch 810/2221) Loss:19.450180053710938\n",
      "epoch:21 batch 820/2221) Loss:2.1497488021850586\n",
      "epoch:21 batch 830/2221) Loss:6.794419288635254\n",
      "epoch:21 batch 840/2221) Loss:3.890450954437256\n",
      "epoch:21 batch 850/2221) Loss:3.40704345703125\n",
      "epoch:21 batch 860/2221) Loss:34.94649887084961\n",
      "epoch:21 batch 870/2221) Loss:4.185060977935791\n",
      "epoch:21 batch 880/2221) Loss:20.566268920898438\n",
      "epoch:21 batch 890/2221) Loss:26.20885467529297\n",
      "epoch:21 batch 900/2221) Loss:4.661128044128418\n",
      "epoch:21 batch 910/2221) Loss:19.528627395629883\n",
      "epoch:21 batch 920/2221) Loss:2.393167734146118\n",
      "epoch:21 batch 930/2221) Loss:7.4254655838012695\n",
      "epoch:21 batch 940/2221) Loss:7.589992523193359\n",
      "epoch:21 batch 950/2221) Loss:9.017166137695312\n",
      "epoch:21 batch 960/2221) Loss:21.825685501098633\n",
      "epoch:21 batch 970/2221) Loss:13.169150352478027\n",
      "epoch:21 batch 980/2221) Loss:18.141103744506836\n",
      "epoch:21 batch 990/2221) Loss:13.250471115112305\n",
      "epoch:21 batch 1000/2221) Loss:4.535312175750732\n",
      "epoch:21 batch 1010/2221) Loss:6.869676113128662\n",
      "epoch:21 batch 1020/2221) Loss:28.711090087890625\n",
      "epoch:21 batch 1030/2221) Loss:20.84653663635254\n",
      "epoch:21 batch 1040/2221) Loss:7.678445339202881\n",
      "epoch:21 batch 1050/2221) Loss:9.52676773071289\n",
      "epoch:21 batch 1060/2221) Loss:10.811752319335938\n",
      "epoch:21 batch 1070/2221) Loss:19.118087768554688\n",
      "epoch:21 batch 1080/2221) Loss:8.500690460205078\n",
      "epoch:21 batch 1090/2221) Loss:6.558794975280762\n",
      "epoch:21 batch 1100/2221) Loss:9.634583473205566\n",
      "epoch:21 batch 1110/2221) Loss:9.825166702270508\n",
      "epoch:21 batch 1120/2221) Loss:22.250202178955078\n",
      "epoch:21 batch 1130/2221) Loss:6.663751602172852\n",
      "epoch:21 batch 1140/2221) Loss:12.293197631835938\n",
      "epoch:21 batch 1150/2221) Loss:6.8687591552734375\n",
      "epoch:21 batch 1160/2221) Loss:17.483043670654297\n",
      "epoch:21 batch 1170/2221) Loss:4.285998344421387\n",
      "epoch:21 batch 1180/2221) Loss:14.340761184692383\n",
      "epoch:21 batch 1190/2221) Loss:12.154509544372559\n",
      "epoch:21 batch 1200/2221) Loss:3.8438544273376465\n",
      "epoch:21 batch 1210/2221) Loss:2.1302552223205566\n",
      "epoch:21 batch 1220/2221) Loss:3.523947238922119\n",
      "epoch:21 batch 1230/2221) Loss:4.207892894744873\n",
      "epoch:21 batch 1240/2221) Loss:11.921777725219727\n",
      "epoch:21 batch 1250/2221) Loss:10.867301940917969\n",
      "epoch:21 batch 1260/2221) Loss:5.626148223876953\n",
      "epoch:21 batch 1270/2221) Loss:26.292192459106445\n",
      "epoch:21 batch 1280/2221) Loss:8.967386245727539\n",
      "epoch:21 batch 1290/2221) Loss:3.708407402038574\n",
      "epoch:21 batch 1300/2221) Loss:4.547732830047607\n",
      "epoch:21 batch 1310/2221) Loss:12.686603546142578\n",
      "epoch:21 batch 1320/2221) Loss:7.48851203918457\n",
      "epoch:21 batch 1330/2221) Loss:7.003252029418945\n",
      "epoch:21 batch 1340/2221) Loss:5.639913558959961\n",
      "epoch:21 batch 1350/2221) Loss:50.521236419677734\n",
      "epoch:21 batch 1360/2221) Loss:21.301067352294922\n",
      "epoch:21 batch 1370/2221) Loss:28.001750946044922\n",
      "epoch:21 batch 1380/2221) Loss:8.65987777709961\n",
      "epoch:21 batch 1390/2221) Loss:4.823418617248535\n",
      "epoch:21 batch 1400/2221) Loss:9.74502944946289\n",
      "epoch:21 batch 1410/2221) Loss:15.054126739501953\n",
      "epoch:21 batch 1420/2221) Loss:4.927152156829834\n",
      "epoch:21 batch 1430/2221) Loss:4.499825954437256\n",
      "epoch:21 batch 1440/2221) Loss:1.3599579334259033\n",
      "epoch:21 batch 1450/2221) Loss:1.9614006280899048\n",
      "epoch:21 batch 1460/2221) Loss:17.42690658569336\n",
      "epoch:21 batch 1470/2221) Loss:8.38463020324707\n",
      "epoch:21 batch 1480/2221) Loss:17.8577880859375\n",
      "epoch:21 batch 1490/2221) Loss:4.599384307861328\n",
      "epoch:21 batch 1500/2221) Loss:9.526731491088867\n",
      "epoch:21 batch 1510/2221) Loss:3.9448037147521973\n",
      "epoch:21 batch 1520/2221) Loss:4.4135541915893555\n",
      "epoch:21 batch 1530/2221) Loss:8.193741798400879\n",
      "epoch:21 batch 1540/2221) Loss:1.843119502067566\n",
      "epoch:21 batch 1550/2221) Loss:5.3911824226379395\n",
      "epoch:21 batch 1560/2221) Loss:8.346226692199707\n",
      "epoch:21 batch 1570/2221) Loss:10.404577255249023\n",
      "epoch:21 batch 1580/2221) Loss:12.180732727050781\n",
      "epoch:21 batch 1590/2221) Loss:3.5039429664611816\n",
      "epoch:21 batch 1600/2221) Loss:3.689235210418701\n",
      "epoch:21 batch 1610/2221) Loss:1.448560357093811\n",
      "epoch:21 batch 1620/2221) Loss:7.933969497680664\n",
      "epoch:21 batch 1630/2221) Loss:15.332625389099121\n",
      "epoch:21 batch 1640/2221) Loss:5.118257999420166\n",
      "epoch:21 batch 1650/2221) Loss:6.135488033294678\n",
      "epoch:21 batch 1660/2221) Loss:9.875503540039062\n",
      "epoch:21 batch 1670/2221) Loss:7.44103479385376\n",
      "epoch:21 batch 1680/2221) Loss:7.379977703094482\n",
      "epoch:21 batch 1690/2221) Loss:20.261188507080078\n",
      "epoch:21 batch 1700/2221) Loss:27.19835662841797\n",
      "epoch:21 batch 1710/2221) Loss:4.539151191711426\n",
      "epoch:21 batch 1720/2221) Loss:11.437077522277832\n",
      "epoch:21 batch 1730/2221) Loss:4.901210784912109\n",
      "epoch:21 batch 1740/2221) Loss:9.132436752319336\n",
      "epoch:21 batch 1750/2221) Loss:18.597795486450195\n",
      "epoch:21 batch 1760/2221) Loss:5.6974968910217285\n",
      "epoch:21 batch 1770/2221) Loss:2.5274765491485596\n",
      "epoch:21 batch 1780/2221) Loss:16.502174377441406\n",
      "epoch:21 batch 1790/2221) Loss:7.174922466278076\n",
      "epoch:21 batch 1800/2221) Loss:13.127561569213867\n",
      "epoch:21 batch 1810/2221) Loss:21.413711547851562\n",
      "epoch:21 batch 1820/2221) Loss:5.519805908203125\n",
      "epoch:21 batch 1830/2221) Loss:8.58077621459961\n",
      "epoch:21 batch 1840/2221) Loss:6.158501148223877\n",
      "epoch:21 batch 1850/2221) Loss:11.299322128295898\n",
      "epoch:21 batch 1860/2221) Loss:9.02004623413086\n",
      "epoch:21 batch 1870/2221) Loss:24.523681640625\n",
      "epoch:21 batch 1880/2221) Loss:8.938730239868164\n",
      "epoch:21 batch 1890/2221) Loss:21.733694076538086\n",
      "epoch:21 batch 1900/2221) Loss:10.659066200256348\n",
      "epoch:21 batch 1910/2221) Loss:6.31342887878418\n",
      "epoch:21 batch 1920/2221) Loss:9.462993621826172\n",
      "epoch:21 batch 1930/2221) Loss:7.736839294433594\n",
      "epoch:21 batch 1940/2221) Loss:32.78746032714844\n",
      "epoch:21 batch 1950/2221) Loss:8.686662673950195\n",
      "epoch:21 batch 1960/2221) Loss:3.21864652633667\n",
      "epoch:21 batch 1970/2221) Loss:3.199632167816162\n",
      "epoch:21 batch 1980/2221) Loss:23.78571319580078\n",
      "epoch:21 batch 1990/2221) Loss:19.85832405090332\n",
      "epoch:21 batch 2000/2221) Loss:4.582304000854492\n",
      "epoch:21 batch 2010/2221) Loss:1.5350966453552246\n",
      "epoch:21 batch 2020/2221) Loss:10.847700119018555\n",
      "epoch:21 batch 2030/2221) Loss:23.176864624023438\n",
      "epoch:21 batch 2040/2221) Loss:6.894315242767334\n",
      "epoch:21 batch 2050/2221) Loss:11.7242431640625\n",
      "epoch:21 batch 2060/2221) Loss:18.63591194152832\n",
      "epoch:21 batch 2070/2221) Loss:7.567870140075684\n",
      "epoch:21 batch 2080/2221) Loss:21.437511444091797\n",
      "epoch:21 batch 2090/2221) Loss:4.295995712280273\n",
      "epoch:21 batch 2100/2221) Loss:13.433414459228516\n",
      "epoch:21 batch 2110/2221) Loss:20.931583404541016\n",
      "epoch:21 batch 2120/2221) Loss:10.39194393157959\n",
      "epoch:21 batch 2130/2221) Loss:22.388957977294922\n",
      "epoch:21 batch 2140/2221) Loss:9.41530990600586\n",
      "epoch:21 batch 2150/2221) Loss:1.658720850944519\n",
      "epoch:21 batch 2160/2221) Loss:14.229121208190918\n",
      "epoch:21 batch 2170/2221) Loss:7.396038055419922\n",
      "epoch:21 batch 2180/2221) Loss:5.181346893310547\n",
      "epoch:21 batch 2190/2221) Loss:7.6900129318237305\n",
      "epoch:21 batch 2200/2221) Loss:8.149637222290039\n",
      "epoch:21 batch 2210/2221) Loss:28.464426040649414\n",
      "epoch:21 batch 2220/2221) Loss:8.856966018676758\n",
      "epoch:21 precision:0.9963376085534125 recall:0.9882073772041419 f1-score:0.9922046019465475\n",
      "epoch:22 batch 1/2221) Loss:6.2643561363220215\n",
      "epoch:22 batch 10/2221) Loss:9.226150512695312\n",
      "epoch:22 batch 20/2221) Loss:2.3484559059143066\n",
      "epoch:22 batch 30/2221) Loss:3.9080862998962402\n",
      "epoch:22 batch 40/2221) Loss:14.07921028137207\n",
      "epoch:22 batch 50/2221) Loss:8.184633255004883\n",
      "epoch:22 batch 60/2221) Loss:16.105812072753906\n",
      "epoch:22 batch 70/2221) Loss:13.491896629333496\n",
      "epoch:22 batch 80/2221) Loss:12.892287254333496\n",
      "epoch:22 batch 90/2221) Loss:1.048337459564209\n",
      "epoch:22 batch 100/2221) Loss:25.61876678466797\n",
      "epoch:22 batch 110/2221) Loss:7.514067649841309\n",
      "epoch:22 batch 120/2221) Loss:15.288406372070312\n",
      "epoch:22 batch 130/2221) Loss:8.637266159057617\n",
      "epoch:22 batch 140/2221) Loss:5.304704189300537\n",
      "epoch:22 batch 150/2221) Loss:3.0550734996795654\n",
      "epoch:22 batch 160/2221) Loss:1.7276474237442017\n",
      "epoch:22 batch 170/2221) Loss:27.332576751708984\n",
      "epoch:22 batch 180/2221) Loss:5.529985427856445\n",
      "epoch:22 batch 190/2221) Loss:17.876501083374023\n",
      "epoch:22 batch 200/2221) Loss:2.244013786315918\n",
      "epoch:22 batch 210/2221) Loss:3.644162893295288\n",
      "epoch:22 batch 220/2221) Loss:2.97493839263916\n",
      "epoch:22 batch 230/2221) Loss:9.116989135742188\n",
      "epoch:22 batch 240/2221) Loss:1.8515315055847168\n",
      "epoch:22 batch 250/2221) Loss:4.5621490478515625\n",
      "epoch:22 batch 260/2221) Loss:4.841846466064453\n",
      "epoch:22 batch 270/2221) Loss:4.125299453735352\n",
      "epoch:22 batch 280/2221) Loss:32.12798309326172\n",
      "epoch:22 batch 290/2221) Loss:9.420222282409668\n",
      "epoch:22 batch 300/2221) Loss:5.0594916343688965\n",
      "epoch:22 batch 310/2221) Loss:9.639385223388672\n",
      "epoch:22 batch 320/2221) Loss:26.10069465637207\n",
      "epoch:22 batch 330/2221) Loss:16.582317352294922\n",
      "epoch:22 batch 340/2221) Loss:13.591999053955078\n",
      "epoch:22 batch 350/2221) Loss:9.903812408447266\n",
      "epoch:22 batch 360/2221) Loss:7.6884446144104\n",
      "epoch:22 batch 370/2221) Loss:4.643397331237793\n",
      "epoch:22 batch 380/2221) Loss:1.743920087814331\n",
      "epoch:22 batch 390/2221) Loss:6.9475789070129395\n",
      "epoch:22 batch 400/2221) Loss:10.634574890136719\n",
      "epoch:22 batch 410/2221) Loss:7.341855525970459\n",
      "epoch:22 batch 420/2221) Loss:6.946313858032227\n",
      "epoch:22 batch 430/2221) Loss:6.947325706481934\n",
      "epoch:22 batch 440/2221) Loss:2.735579490661621\n",
      "epoch:22 batch 450/2221) Loss:10.526310920715332\n",
      "epoch:22 batch 460/2221) Loss:3.9580132961273193\n",
      "epoch:22 batch 470/2221) Loss:12.147134780883789\n",
      "epoch:22 batch 480/2221) Loss:4.5511932373046875\n",
      "epoch:22 batch 490/2221) Loss:6.6597185134887695\n",
      "epoch:22 batch 500/2221) Loss:6.261835098266602\n",
      "epoch:22 batch 510/2221) Loss:5.727090358734131\n",
      "epoch:22 batch 520/2221) Loss:12.89455795288086\n",
      "epoch:22 batch 530/2221) Loss:11.045740127563477\n",
      "epoch:22 batch 540/2221) Loss:5.293038845062256\n",
      "epoch:22 batch 550/2221) Loss:2.7677531242370605\n",
      "epoch:22 batch 560/2221) Loss:17.89464569091797\n",
      "epoch:22 batch 570/2221) Loss:24.98933982849121\n",
      "epoch:22 batch 580/2221) Loss:1.5842995643615723\n",
      "epoch:22 batch 590/2221) Loss:11.39090633392334\n",
      "epoch:22 batch 600/2221) Loss:5.46393346786499\n",
      "epoch:22 batch 610/2221) Loss:6.271793842315674\n",
      "epoch:22 batch 620/2221) Loss:6.386061191558838\n",
      "epoch:22 batch 630/2221) Loss:7.87412166595459\n",
      "epoch:22 batch 640/2221) Loss:9.071539878845215\n",
      "epoch:22 batch 650/2221) Loss:9.791698455810547\n",
      "epoch:22 batch 660/2221) Loss:6.774693489074707\n",
      "epoch:22 batch 670/2221) Loss:19.445215225219727\n",
      "epoch:22 batch 680/2221) Loss:16.09437370300293\n",
      "epoch:22 batch 690/2221) Loss:15.45722770690918\n",
      "epoch:22 batch 700/2221) Loss:28.288537979125977\n",
      "epoch:22 batch 710/2221) Loss:7.312262058258057\n",
      "epoch:22 batch 720/2221) Loss:4.230417728424072\n",
      "epoch:22 batch 730/2221) Loss:9.799190521240234\n",
      "epoch:22 batch 740/2221) Loss:11.175928115844727\n",
      "epoch:22 batch 750/2221) Loss:11.500642776489258\n",
      "epoch:22 batch 760/2221) Loss:18.73781394958496\n",
      "epoch:22 batch 770/2221) Loss:9.557741165161133\n",
      "epoch:22 batch 780/2221) Loss:27.125221252441406\n",
      "epoch:22 batch 790/2221) Loss:13.549962043762207\n",
      "epoch:22 batch 800/2221) Loss:6.37367582321167\n",
      "epoch:22 batch 810/2221) Loss:2.0873970985412598\n",
      "epoch:22 batch 820/2221) Loss:5.008986473083496\n",
      "epoch:22 batch 830/2221) Loss:19.11066436767578\n",
      "epoch:22 batch 840/2221) Loss:6.222490310668945\n",
      "epoch:22 batch 850/2221) Loss:26.426376342773438\n",
      "epoch:22 batch 860/2221) Loss:2.9480810165405273\n",
      "epoch:22 batch 870/2221) Loss:15.877105712890625\n",
      "epoch:22 batch 880/2221) Loss:2.4729721546173096\n",
      "epoch:22 batch 890/2221) Loss:21.32602882385254\n",
      "epoch:22 batch 900/2221) Loss:25.523117065429688\n",
      "epoch:22 batch 910/2221) Loss:6.9516072273254395\n",
      "epoch:22 batch 920/2221) Loss:13.359733581542969\n",
      "epoch:22 batch 930/2221) Loss:6.046764373779297\n",
      "epoch:22 batch 940/2221) Loss:3.1671996116638184\n",
      "epoch:22 batch 950/2221) Loss:15.153048515319824\n",
      "epoch:22 batch 960/2221) Loss:8.431187629699707\n",
      "epoch:22 batch 970/2221) Loss:25.528034210205078\n",
      "epoch:22 batch 980/2221) Loss:31.420454025268555\n",
      "epoch:22 batch 990/2221) Loss:7.746287822723389\n",
      "epoch:22 batch 1000/2221) Loss:11.730080604553223\n",
      "epoch:22 batch 1010/2221) Loss:9.722513198852539\n",
      "epoch:22 batch 1020/2221) Loss:14.016733169555664\n",
      "epoch:22 batch 1030/2221) Loss:4.142166614532471\n",
      "epoch:22 batch 1040/2221) Loss:8.557785987854004\n",
      "epoch:22 batch 1050/2221) Loss:41.78776550292969\n",
      "epoch:22 batch 1060/2221) Loss:16.44813346862793\n",
      "epoch:22 batch 1070/2221) Loss:10.422821044921875\n",
      "epoch:22 batch 1080/2221) Loss:9.206689834594727\n",
      "epoch:22 batch 1090/2221) Loss:3.0974369049072266\n",
      "epoch:22 batch 1100/2221) Loss:21.589794158935547\n",
      "epoch:22 batch 1110/2221) Loss:8.487632751464844\n",
      "epoch:22 batch 1120/2221) Loss:17.56148910522461\n",
      "epoch:22 batch 1130/2221) Loss:8.479074478149414\n",
      "epoch:22 batch 1140/2221) Loss:10.439424514770508\n",
      "epoch:22 batch 1150/2221) Loss:20.33403205871582\n",
      "epoch:22 batch 1160/2221) Loss:1.9574143886566162\n",
      "epoch:22 batch 1170/2221) Loss:11.3980131149292\n",
      "epoch:22 batch 1180/2221) Loss:3.484132766723633\n",
      "epoch:22 batch 1190/2221) Loss:12.596211433410645\n",
      "epoch:22 batch 1200/2221) Loss:9.447117805480957\n",
      "epoch:22 batch 1210/2221) Loss:13.008950233459473\n",
      "epoch:22 batch 1220/2221) Loss:6.754419326782227\n",
      "epoch:22 batch 1230/2221) Loss:2.078270673751831\n",
      "epoch:22 batch 1240/2221) Loss:11.27453327178955\n",
      "epoch:22 batch 1250/2221) Loss:7.182175636291504\n",
      "epoch:22 batch 1260/2221) Loss:17.814342498779297\n",
      "epoch:22 batch 1270/2221) Loss:9.83583927154541\n",
      "epoch:22 batch 1280/2221) Loss:5.876468658447266\n",
      "epoch:22 batch 1290/2221) Loss:8.069204330444336\n",
      "epoch:22 batch 1300/2221) Loss:11.968551635742188\n",
      "epoch:22 batch 1310/2221) Loss:25.854976654052734\n",
      "epoch:22 batch 1320/2221) Loss:4.9160943031311035\n",
      "epoch:22 batch 1330/2221) Loss:19.350404739379883\n",
      "epoch:22 batch 1340/2221) Loss:10.332326889038086\n",
      "epoch:22 batch 1350/2221) Loss:9.954164505004883\n",
      "epoch:22 batch 1360/2221) Loss:7.4835052490234375\n",
      "epoch:22 batch 1370/2221) Loss:9.984411239624023\n",
      "epoch:22 batch 1380/2221) Loss:15.715518951416016\n",
      "epoch:22 batch 1390/2221) Loss:8.333852767944336\n",
      "epoch:22 batch 1400/2221) Loss:9.62221622467041\n",
      "epoch:22 batch 1410/2221) Loss:2.199831247329712\n",
      "epoch:22 batch 1420/2221) Loss:5.224289894104004\n",
      "epoch:22 batch 1430/2221) Loss:6.925200939178467\n",
      "epoch:22 batch 1440/2221) Loss:1.1111868619918823\n",
      "epoch:22 batch 1450/2221) Loss:8.178674697875977\n",
      "epoch:22 batch 1460/2221) Loss:28.427976608276367\n",
      "epoch:22 batch 1470/2221) Loss:13.336627960205078\n",
      "epoch:22 batch 1480/2221) Loss:6.549328327178955\n",
      "epoch:22 batch 1490/2221) Loss:1.2889248132705688\n",
      "epoch:22 batch 1500/2221) Loss:14.866853713989258\n",
      "epoch:22 batch 1510/2221) Loss:8.195968627929688\n",
      "epoch:22 batch 1520/2221) Loss:19.88600730895996\n",
      "epoch:22 batch 1530/2221) Loss:8.287209510803223\n",
      "epoch:22 batch 1540/2221) Loss:18.170379638671875\n",
      "epoch:22 batch 1550/2221) Loss:5.592168807983398\n",
      "epoch:22 batch 1560/2221) Loss:6.594798564910889\n",
      "epoch:22 batch 1570/2221) Loss:11.046079635620117\n",
      "epoch:22 batch 1580/2221) Loss:11.17394733428955\n",
      "epoch:22 batch 1590/2221) Loss:6.500800132751465\n",
      "epoch:22 batch 1600/2221) Loss:16.52198600769043\n",
      "epoch:22 batch 1610/2221) Loss:4.661718368530273\n",
      "epoch:22 batch 1620/2221) Loss:9.972475051879883\n",
      "epoch:22 batch 1630/2221) Loss:7.0971832275390625\n",
      "epoch:22 batch 1640/2221) Loss:11.808914184570312\n",
      "epoch:22 batch 1650/2221) Loss:17.841135025024414\n",
      "epoch:22 batch 1660/2221) Loss:1.3616567850112915\n",
      "epoch:22 batch 1670/2221) Loss:6.133795738220215\n",
      "epoch:22 batch 1680/2221) Loss:9.115493774414062\n",
      "epoch:22 batch 1690/2221) Loss:37.272850036621094\n",
      "epoch:22 batch 1700/2221) Loss:12.022855758666992\n",
      "epoch:22 batch 1710/2221) Loss:5.527418613433838\n",
      "epoch:22 batch 1720/2221) Loss:4.636695861816406\n",
      "epoch:22 batch 1730/2221) Loss:22.398113250732422\n",
      "epoch:22 batch 1740/2221) Loss:11.397943496704102\n",
      "epoch:22 batch 1750/2221) Loss:14.087377548217773\n",
      "epoch:22 batch 1760/2221) Loss:17.303537368774414\n",
      "epoch:22 batch 1770/2221) Loss:4.813097953796387\n",
      "epoch:22 batch 1780/2221) Loss:4.196571350097656\n",
      "epoch:22 batch 1790/2221) Loss:10.037979125976562\n",
      "epoch:22 batch 1800/2221) Loss:2.4018092155456543\n",
      "epoch:22 batch 1810/2221) Loss:6.343714237213135\n",
      "epoch:22 batch 1820/2221) Loss:3.62673282623291\n",
      "epoch:22 batch 1830/2221) Loss:15.13956356048584\n",
      "epoch:22 batch 1840/2221) Loss:4.062182426452637\n",
      "epoch:22 batch 1850/2221) Loss:1.740290880203247\n",
      "epoch:22 batch 1860/2221) Loss:12.048211097717285\n",
      "epoch:22 batch 1870/2221) Loss:9.712282180786133\n",
      "epoch:22 batch 1880/2221) Loss:8.521817207336426\n",
      "epoch:22 batch 1890/2221) Loss:1.9934970140457153\n",
      "epoch:22 batch 1900/2221) Loss:3.2064476013183594\n",
      "epoch:22 batch 1910/2221) Loss:7.577579975128174\n",
      "epoch:22 batch 1920/2221) Loss:15.748697280883789\n",
      "epoch:22 batch 1930/2221) Loss:5.566937446594238\n",
      "epoch:22 batch 1940/2221) Loss:9.02203369140625\n",
      "epoch:22 batch 1950/2221) Loss:8.069442749023438\n",
      "epoch:22 batch 1960/2221) Loss:4.887751579284668\n",
      "epoch:22 batch 1970/2221) Loss:9.271881103515625\n",
      "epoch:22 batch 1980/2221) Loss:22.53104591369629\n",
      "epoch:22 batch 1990/2221) Loss:5.01384162902832\n",
      "epoch:22 batch 2000/2221) Loss:9.121973037719727\n",
      "epoch:22 batch 2010/2221) Loss:19.215726852416992\n",
      "epoch:22 batch 2020/2221) Loss:5.617553234100342\n",
      "epoch:22 batch 2030/2221) Loss:18.76459503173828\n",
      "epoch:22 batch 2040/2221) Loss:16.107666015625\n",
      "epoch:22 batch 2050/2221) Loss:9.79380989074707\n",
      "epoch:22 batch 2060/2221) Loss:10.328043937683105\n",
      "epoch:22 batch 2070/2221) Loss:7.343980312347412\n",
      "epoch:22 batch 2080/2221) Loss:6.376021385192871\n",
      "epoch:22 batch 2090/2221) Loss:3.0438194274902344\n",
      "epoch:22 batch 2100/2221) Loss:5.020010948181152\n",
      "epoch:22 batch 2110/2221) Loss:3.9634878635406494\n",
      "epoch:22 batch 2120/2221) Loss:8.616732597351074\n",
      "epoch:22 batch 2130/2221) Loss:4.288544178009033\n",
      "epoch:22 batch 2140/2221) Loss:11.977932929992676\n",
      "epoch:22 batch 2150/2221) Loss:0.9322322607040405\n",
      "epoch:22 batch 2160/2221) Loss:6.196596145629883\n",
      "epoch:22 batch 2170/2221) Loss:6.077293395996094\n",
      "epoch:22 batch 2180/2221) Loss:10.539660453796387\n",
      "epoch:22 batch 2190/2221) Loss:9.266312599182129\n",
      "epoch:22 batch 2200/2221) Loss:9.880450248718262\n",
      "epoch:22 batch 2210/2221) Loss:1.702039122581482\n",
      "epoch:22 batch 2220/2221) Loss:2.9411747455596924\n",
      "epoch:22 precision:0.9966030832600318 recall:0.9885361702246687 f1-score:0.9924948845202687\n",
      "epoch:23 batch 1/2221) Loss:4.614126682281494\n",
      "epoch:23 batch 10/2221) Loss:5.950913429260254\n",
      "epoch:23 batch 20/2221) Loss:3.362271308898926\n",
      "epoch:23 batch 30/2221) Loss:13.821639060974121\n",
      "epoch:23 batch 40/2221) Loss:5.520605087280273\n",
      "epoch:23 batch 50/2221) Loss:4.906874179840088\n",
      "epoch:23 batch 60/2221) Loss:11.021902084350586\n",
      "epoch:23 batch 70/2221) Loss:5.689391136169434\n",
      "epoch:23 batch 80/2221) Loss:17.388931274414062\n",
      "epoch:23 batch 90/2221) Loss:1.2712453603744507\n",
      "epoch:23 batch 100/2221) Loss:6.679434776306152\n",
      "epoch:23 batch 110/2221) Loss:23.04141616821289\n",
      "epoch:23 batch 120/2221) Loss:1.4891802072525024\n",
      "epoch:23 batch 130/2221) Loss:30.47096824645996\n",
      "epoch:23 batch 140/2221) Loss:4.113472938537598\n",
      "epoch:23 batch 150/2221) Loss:25.317625045776367\n",
      "epoch:23 batch 160/2221) Loss:8.633871078491211\n",
      "epoch:23 batch 170/2221) Loss:7.416220664978027\n",
      "epoch:23 batch 180/2221) Loss:7.6596784591674805\n",
      "epoch:23 batch 190/2221) Loss:12.662683486938477\n",
      "epoch:23 batch 200/2221) Loss:13.63703727722168\n",
      "epoch:23 batch 210/2221) Loss:4.881982803344727\n",
      "epoch:23 batch 220/2221) Loss:13.815485954284668\n",
      "epoch:23 batch 230/2221) Loss:5.062021255493164\n",
      "epoch:23 batch 240/2221) Loss:14.600497245788574\n",
      "epoch:23 batch 250/2221) Loss:3.4146175384521484\n",
      "epoch:23 batch 260/2221) Loss:6.446498394012451\n",
      "epoch:23 batch 270/2221) Loss:8.218421936035156\n",
      "epoch:23 batch 280/2221) Loss:9.818679809570312\n",
      "epoch:23 batch 290/2221) Loss:6.936744689941406\n",
      "epoch:23 batch 300/2221) Loss:25.078763961791992\n",
      "epoch:23 batch 310/2221) Loss:18.409534454345703\n",
      "epoch:23 batch 320/2221) Loss:3.34562087059021\n",
      "epoch:23 batch 330/2221) Loss:5.212154865264893\n",
      "epoch:23 batch 340/2221) Loss:14.771203994750977\n",
      "epoch:23 batch 350/2221) Loss:7.398722171783447\n",
      "epoch:23 batch 360/2221) Loss:3.653780221939087\n",
      "epoch:23 batch 370/2221) Loss:3.6708731651306152\n",
      "epoch:23 batch 380/2221) Loss:10.862804412841797\n",
      "epoch:23 batch 390/2221) Loss:9.04318618774414\n",
      "epoch:23 batch 400/2221) Loss:7.414895534515381\n",
      "epoch:23 batch 410/2221) Loss:2.5904622077941895\n",
      "epoch:23 batch 420/2221) Loss:6.800081729888916\n",
      "epoch:23 batch 430/2221) Loss:1.305656909942627\n",
      "epoch:23 batch 440/2221) Loss:1.7493679523468018\n",
      "epoch:23 batch 450/2221) Loss:15.388924598693848\n",
      "epoch:23 batch 460/2221) Loss:17.88852882385254\n",
      "epoch:23 batch 470/2221) Loss:11.765339851379395\n",
      "epoch:23 batch 480/2221) Loss:5.389621734619141\n",
      "epoch:23 batch 490/2221) Loss:11.313328742980957\n",
      "epoch:23 batch 500/2221) Loss:4.416082859039307\n",
      "epoch:23 batch 510/2221) Loss:21.89491081237793\n",
      "epoch:23 batch 520/2221) Loss:7.99063777923584\n",
      "epoch:23 batch 530/2221) Loss:8.6836576461792\n",
      "epoch:23 batch 540/2221) Loss:14.013710021972656\n",
      "epoch:23 batch 550/2221) Loss:11.071162223815918\n",
      "epoch:23 batch 560/2221) Loss:3.816744804382324\n",
      "epoch:23 batch 570/2221) Loss:16.129901885986328\n",
      "epoch:23 batch 580/2221) Loss:9.576399803161621\n",
      "epoch:23 batch 590/2221) Loss:9.317726135253906\n",
      "epoch:23 batch 600/2221) Loss:11.579010009765625\n",
      "epoch:23 batch 610/2221) Loss:12.975162506103516\n",
      "epoch:23 batch 620/2221) Loss:1.530747413635254\n",
      "epoch:23 batch 630/2221) Loss:20.098270416259766\n",
      "epoch:23 batch 640/2221) Loss:13.75672435760498\n",
      "epoch:23 batch 650/2221) Loss:17.482677459716797\n",
      "epoch:23 batch 660/2221) Loss:5.304465293884277\n",
      "epoch:23 batch 670/2221) Loss:7.140420913696289\n",
      "epoch:23 batch 680/2221) Loss:13.792119026184082\n",
      "epoch:23 batch 690/2221) Loss:7.7645087242126465\n",
      "epoch:23 batch 700/2221) Loss:6.677515506744385\n",
      "epoch:23 batch 710/2221) Loss:16.436302185058594\n",
      "epoch:23 batch 720/2221) Loss:5.467921733856201\n",
      "epoch:23 batch 730/2221) Loss:1.929567575454712\n",
      "epoch:23 batch 740/2221) Loss:5.746301651000977\n",
      "epoch:23 batch 750/2221) Loss:2.4669108390808105\n",
      "epoch:23 batch 760/2221) Loss:15.060022354125977\n",
      "epoch:23 batch 770/2221) Loss:10.726951599121094\n",
      "epoch:23 batch 780/2221) Loss:31.083206176757812\n",
      "epoch:23 batch 790/2221) Loss:7.260058879852295\n",
      "epoch:23 batch 800/2221) Loss:15.617803573608398\n",
      "epoch:23 batch 810/2221) Loss:13.298521995544434\n",
      "epoch:23 batch 820/2221) Loss:4.116916656494141\n",
      "epoch:23 batch 830/2221) Loss:3.7798218727111816\n",
      "epoch:23 batch 840/2221) Loss:11.246667861938477\n",
      "epoch:23 batch 850/2221) Loss:1.241844654083252\n",
      "epoch:23 batch 860/2221) Loss:5.3561811447143555\n",
      "epoch:23 batch 870/2221) Loss:6.0052103996276855\n",
      "epoch:23 batch 880/2221) Loss:4.163652420043945\n",
      "epoch:23 batch 890/2221) Loss:1.3280712366104126\n",
      "epoch:23 batch 900/2221) Loss:10.392120361328125\n",
      "epoch:23 batch 910/2221) Loss:4.225508213043213\n",
      "epoch:23 batch 920/2221) Loss:4.0880126953125\n",
      "epoch:23 batch 930/2221) Loss:7.254705429077148\n",
      "epoch:23 batch 940/2221) Loss:19.43596649169922\n",
      "epoch:23 batch 950/2221) Loss:4.775908946990967\n",
      "epoch:23 batch 960/2221) Loss:10.31601333618164\n",
      "epoch:23 batch 970/2221) Loss:9.327771186828613\n",
      "epoch:23 batch 980/2221) Loss:40.43499755859375\n",
      "epoch:23 batch 990/2221) Loss:4.049036026000977\n",
      "epoch:23 batch 1000/2221) Loss:16.967817306518555\n",
      "epoch:23 batch 1010/2221) Loss:19.56167984008789\n",
      "epoch:23 batch 1020/2221) Loss:8.660274505615234\n",
      "epoch:23 batch 1030/2221) Loss:12.296773910522461\n",
      "epoch:23 batch 1040/2221) Loss:8.136412620544434\n",
      "epoch:23 batch 1050/2221) Loss:11.88509464263916\n",
      "epoch:23 batch 1060/2221) Loss:20.678144454956055\n",
      "epoch:23 batch 1070/2221) Loss:10.590665817260742\n",
      "epoch:23 batch 1080/2221) Loss:10.274412155151367\n",
      "epoch:23 batch 1090/2221) Loss:12.353508949279785\n",
      "epoch:23 batch 1100/2221) Loss:11.615981101989746\n",
      "epoch:23 batch 1110/2221) Loss:1.1488783359527588\n",
      "epoch:23 batch 1120/2221) Loss:6.21293830871582\n",
      "epoch:23 batch 1130/2221) Loss:9.332996368408203\n",
      "epoch:23 batch 1140/2221) Loss:5.624239921569824\n",
      "epoch:23 batch 1150/2221) Loss:10.946798324584961\n",
      "epoch:23 batch 1160/2221) Loss:12.532353401184082\n",
      "epoch:23 batch 1170/2221) Loss:5.599653244018555\n",
      "epoch:23 batch 1180/2221) Loss:13.537225723266602\n",
      "epoch:23 batch 1190/2221) Loss:25.3314208984375\n",
      "epoch:23 batch 1200/2221) Loss:8.078707695007324\n",
      "epoch:23 batch 1210/2221) Loss:7.114475727081299\n",
      "epoch:23 batch 1220/2221) Loss:4.2036895751953125\n",
      "epoch:23 batch 1230/2221) Loss:4.416942596435547\n",
      "epoch:23 batch 1240/2221) Loss:3.2591700553894043\n",
      "epoch:23 batch 1250/2221) Loss:10.907134056091309\n",
      "epoch:23 batch 1260/2221) Loss:13.448078155517578\n",
      "epoch:23 batch 1270/2221) Loss:1.9918358325958252\n",
      "epoch:23 batch 1280/2221) Loss:4.288898468017578\n",
      "epoch:23 batch 1290/2221) Loss:7.154433250427246\n",
      "epoch:23 batch 1300/2221) Loss:3.024456739425659\n",
      "epoch:23 batch 1310/2221) Loss:13.787059783935547\n",
      "epoch:23 batch 1320/2221) Loss:12.872119903564453\n",
      "epoch:23 batch 1330/2221) Loss:8.126620292663574\n",
      "epoch:23 batch 1340/2221) Loss:21.167524337768555\n",
      "epoch:23 batch 1350/2221) Loss:22.63964080810547\n",
      "epoch:23 batch 1360/2221) Loss:15.764102935791016\n",
      "epoch:23 batch 1370/2221) Loss:4.91788387298584\n",
      "epoch:23 batch 1380/2221) Loss:11.368064880371094\n",
      "epoch:23 batch 1390/2221) Loss:9.491268157958984\n",
      "epoch:23 batch 1400/2221) Loss:6.009790420532227\n",
      "epoch:23 batch 1410/2221) Loss:22.769527435302734\n",
      "epoch:23 batch 1420/2221) Loss:4.8686113357543945\n",
      "epoch:23 batch 1430/2221) Loss:7.196855545043945\n",
      "epoch:23 batch 1440/2221) Loss:22.497722625732422\n",
      "epoch:23 batch 1450/2221) Loss:13.511021614074707\n",
      "epoch:23 batch 1460/2221) Loss:5.109894752502441\n",
      "epoch:23 batch 1470/2221) Loss:6.093240737915039\n",
      "epoch:23 batch 1480/2221) Loss:8.496260643005371\n",
      "epoch:23 batch 1490/2221) Loss:6.983767032623291\n",
      "epoch:23 batch 1500/2221) Loss:9.496066093444824\n",
      "epoch:23 batch 1510/2221) Loss:11.786190032958984\n",
      "epoch:23 batch 1520/2221) Loss:7.167885780334473\n",
      "epoch:23 batch 1530/2221) Loss:15.585890769958496\n",
      "epoch:23 batch 1540/2221) Loss:17.516132354736328\n",
      "epoch:23 batch 1550/2221) Loss:6.191980361938477\n",
      "epoch:23 batch 1560/2221) Loss:1.89851713180542\n",
      "epoch:23 batch 1570/2221) Loss:4.8546881675720215\n",
      "epoch:23 batch 1580/2221) Loss:9.826383590698242\n",
      "epoch:23 batch 1590/2221) Loss:18.611677169799805\n",
      "epoch:23 batch 1600/2221) Loss:3.043069839477539\n",
      "epoch:23 batch 1610/2221) Loss:7.239262580871582\n",
      "epoch:23 batch 1620/2221) Loss:5.525803565979004\n",
      "epoch:23 batch 1630/2221) Loss:9.901029586791992\n",
      "epoch:23 batch 1640/2221) Loss:12.792787551879883\n",
      "epoch:23 batch 1650/2221) Loss:1.215448260307312\n",
      "epoch:23 batch 1660/2221) Loss:4.537867546081543\n",
      "epoch:23 batch 1670/2221) Loss:23.518003463745117\n",
      "epoch:23 batch 1680/2221) Loss:4.992225646972656\n",
      "epoch:23 batch 1690/2221) Loss:6.921693801879883\n",
      "epoch:23 batch 1700/2221) Loss:13.331014633178711\n",
      "epoch:23 batch 1710/2221) Loss:1.3557219505310059\n",
      "epoch:23 batch 1720/2221) Loss:3.051560878753662\n",
      "epoch:23 batch 1730/2221) Loss:13.313272476196289\n",
      "epoch:23 batch 1740/2221) Loss:15.98987865447998\n",
      "epoch:23 batch 1750/2221) Loss:8.077884674072266\n",
      "epoch:23 batch 1760/2221) Loss:13.246447563171387\n",
      "epoch:23 batch 1770/2221) Loss:37.2397346496582\n",
      "epoch:23 batch 1780/2221) Loss:15.713000297546387\n",
      "epoch:23 batch 1790/2221) Loss:1.258218765258789\n",
      "epoch:23 batch 1800/2221) Loss:9.435507774353027\n",
      "epoch:23 batch 1810/2221) Loss:3.9237523078918457\n",
      "epoch:23 batch 1820/2221) Loss:10.587065696716309\n",
      "epoch:23 batch 1830/2221) Loss:7.236810684204102\n",
      "epoch:23 batch 1840/2221) Loss:15.8094482421875\n",
      "epoch:23 batch 1850/2221) Loss:1.1173622608184814\n",
      "epoch:23 batch 1860/2221) Loss:12.942960739135742\n",
      "epoch:23 batch 1870/2221) Loss:4.558414459228516\n",
      "epoch:23 batch 1880/2221) Loss:6.94549560546875\n",
      "epoch:23 batch 1890/2221) Loss:11.614408493041992\n",
      "epoch:23 batch 1900/2221) Loss:28.920249938964844\n",
      "epoch:23 batch 1910/2221) Loss:6.691549301147461\n",
      "epoch:23 batch 1920/2221) Loss:2.876401901245117\n",
      "epoch:23 batch 1930/2221) Loss:3.8073041439056396\n",
      "epoch:23 batch 1940/2221) Loss:26.67777442932129\n",
      "epoch:23 batch 1950/2221) Loss:5.921337604522705\n",
      "epoch:23 batch 1960/2221) Loss:9.446441650390625\n",
      "epoch:23 batch 1970/2221) Loss:20.860517501831055\n",
      "epoch:23 batch 1980/2221) Loss:9.11996078491211\n",
      "epoch:23 batch 1990/2221) Loss:16.28485870361328\n",
      "epoch:23 batch 2000/2221) Loss:2.656905174255371\n",
      "epoch:23 batch 2010/2221) Loss:4.91541862487793\n",
      "epoch:23 batch 2020/2221) Loss:9.248763084411621\n",
      "epoch:23 batch 2030/2221) Loss:9.412943840026855\n",
      "epoch:23 batch 2040/2221) Loss:5.865636825561523\n",
      "epoch:23 batch 2050/2221) Loss:6.051659107208252\n",
      "epoch:23 batch 2060/2221) Loss:4.508015155792236\n",
      "epoch:23 batch 2070/2221) Loss:9.536808013916016\n",
      "epoch:23 batch 2080/2221) Loss:14.417020797729492\n",
      "epoch:23 batch 2090/2221) Loss:9.535660743713379\n",
      "epoch:23 batch 2100/2221) Loss:6.224740505218506\n",
      "epoch:23 batch 2110/2221) Loss:3.2412030696868896\n",
      "epoch:23 batch 2120/2221) Loss:6.157222270965576\n",
      "epoch:23 batch 2130/2221) Loss:6.636457443237305\n",
      "epoch:23 batch 2140/2221) Loss:9.456697463989258\n",
      "epoch:23 batch 2150/2221) Loss:4.779033660888672\n",
      "epoch:23 batch 2160/2221) Loss:14.448675155639648\n",
      "epoch:23 batch 2170/2221) Loss:0.9948356747627258\n",
      "epoch:23 batch 2180/2221) Loss:7.019821643829346\n",
      "epoch:23 batch 2190/2221) Loss:13.334480285644531\n",
      "epoch:23 batch 2200/2221) Loss:5.863637447357178\n",
      "epoch:23 batch 2210/2221) Loss:24.068931579589844\n",
      "epoch:23 batch 2220/2221) Loss:13.451292991638184\n",
      "epoch:23 precision:0.9962919872089289 recall:0.9889652115733841 f1-score:0.9925656096108489\n",
      "epoch:24 batch 1/2221) Loss:8.034090042114258\n",
      "epoch:24 batch 10/2221) Loss:18.962474822998047\n",
      "epoch:24 batch 20/2221) Loss:21.252750396728516\n",
      "epoch:24 batch 30/2221) Loss:2.3737952709198\n",
      "epoch:24 batch 40/2221) Loss:2.978695869445801\n",
      "epoch:24 batch 50/2221) Loss:4.504755973815918\n",
      "epoch:24 batch 60/2221) Loss:4.895359992980957\n",
      "epoch:24 batch 70/2221) Loss:6.053195476531982\n",
      "epoch:24 batch 80/2221) Loss:11.4325532913208\n",
      "epoch:24 batch 90/2221) Loss:11.451793670654297\n",
      "epoch:24 batch 100/2221) Loss:15.297601699829102\n",
      "epoch:24 batch 110/2221) Loss:8.54245662689209\n",
      "epoch:24 batch 120/2221) Loss:11.567769050598145\n",
      "epoch:24 batch 130/2221) Loss:11.012617111206055\n",
      "epoch:24 batch 140/2221) Loss:7.9568915367126465\n",
      "epoch:24 batch 150/2221) Loss:6.6841654777526855\n",
      "epoch:24 batch 160/2221) Loss:6.498516082763672\n",
      "epoch:24 batch 170/2221) Loss:6.820135116577148\n",
      "epoch:24 batch 180/2221) Loss:10.067638397216797\n",
      "epoch:24 batch 190/2221) Loss:10.42548942565918\n",
      "epoch:24 batch 200/2221) Loss:31.80353546142578\n",
      "epoch:24 batch 210/2221) Loss:2.1724421977996826\n",
      "epoch:24 batch 220/2221) Loss:13.212325096130371\n",
      "epoch:24 batch 230/2221) Loss:23.781503677368164\n",
      "epoch:24 batch 240/2221) Loss:23.66341781616211\n",
      "epoch:24 batch 250/2221) Loss:1.3449712991714478\n",
      "epoch:24 batch 260/2221) Loss:11.894922256469727\n",
      "epoch:24 batch 270/2221) Loss:11.613423347473145\n",
      "epoch:24 batch 280/2221) Loss:15.398153305053711\n",
      "epoch:24 batch 290/2221) Loss:10.76243782043457\n",
      "epoch:24 batch 300/2221) Loss:5.5548224449157715\n",
      "epoch:24 batch 310/2221) Loss:2.747499465942383\n",
      "epoch:24 batch 320/2221) Loss:14.537546157836914\n",
      "epoch:24 batch 330/2221) Loss:7.901681900024414\n",
      "epoch:24 batch 340/2221) Loss:12.934703826904297\n",
      "epoch:24 batch 350/2221) Loss:9.234347343444824\n",
      "epoch:24 batch 360/2221) Loss:3.1357903480529785\n",
      "epoch:24 batch 370/2221) Loss:23.419952392578125\n",
      "epoch:24 batch 380/2221) Loss:4.4589314460754395\n",
      "epoch:24 batch 390/2221) Loss:1.377954125404358\n",
      "epoch:24 batch 400/2221) Loss:19.872364044189453\n",
      "epoch:24 batch 410/2221) Loss:6.797244548797607\n",
      "epoch:24 batch 420/2221) Loss:12.023329734802246\n",
      "epoch:24 batch 430/2221) Loss:4.837538719177246\n",
      "epoch:24 batch 440/2221) Loss:10.385089874267578\n",
      "epoch:24 batch 450/2221) Loss:9.882266998291016\n",
      "epoch:24 batch 460/2221) Loss:8.58687973022461\n",
      "epoch:24 batch 470/2221) Loss:13.143196105957031\n",
      "epoch:24 batch 480/2221) Loss:7.00052547454834\n",
      "epoch:24 batch 490/2221) Loss:26.711719512939453\n",
      "epoch:24 batch 500/2221) Loss:18.99498176574707\n",
      "epoch:24 batch 510/2221) Loss:3.4963793754577637\n",
      "epoch:24 batch 520/2221) Loss:7.783845901489258\n",
      "epoch:24 batch 530/2221) Loss:1.957890272140503\n",
      "epoch:24 batch 540/2221) Loss:10.836682319641113\n",
      "epoch:24 batch 550/2221) Loss:8.953482627868652\n",
      "epoch:24 batch 560/2221) Loss:9.068424224853516\n",
      "epoch:24 batch 570/2221) Loss:8.519536972045898\n",
      "epoch:24 batch 580/2221) Loss:26.6602725982666\n",
      "epoch:24 batch 590/2221) Loss:7.289233684539795\n",
      "epoch:24 batch 600/2221) Loss:0.8626207113265991\n",
      "epoch:24 batch 610/2221) Loss:5.30833625793457\n",
      "epoch:24 batch 620/2221) Loss:3.90830659866333\n",
      "epoch:24 batch 630/2221) Loss:2.255580425262451\n",
      "epoch:24 batch 640/2221) Loss:7.239043235778809\n",
      "epoch:24 batch 650/2221) Loss:9.704364776611328\n",
      "epoch:24 batch 660/2221) Loss:15.97911262512207\n",
      "epoch:24 batch 670/2221) Loss:17.908889770507812\n",
      "epoch:24 batch 680/2221) Loss:9.612751960754395\n",
      "epoch:24 batch 690/2221) Loss:9.58329963684082\n",
      "epoch:24 batch 700/2221) Loss:3.7160866260528564\n",
      "epoch:24 batch 710/2221) Loss:5.0704665184021\n",
      "epoch:24 batch 720/2221) Loss:12.111228942871094\n",
      "epoch:24 batch 730/2221) Loss:3.87430477142334\n",
      "epoch:24 batch 740/2221) Loss:1.782824993133545\n",
      "epoch:24 batch 750/2221) Loss:1.6699398756027222\n",
      "epoch:24 batch 760/2221) Loss:11.714818954467773\n",
      "epoch:24 batch 770/2221) Loss:9.785754203796387\n",
      "epoch:24 batch 780/2221) Loss:13.604439735412598\n",
      "epoch:24 batch 790/2221) Loss:10.331000328063965\n",
      "epoch:24 batch 800/2221) Loss:3.8362770080566406\n",
      "epoch:24 batch 810/2221) Loss:3.68053936958313\n",
      "epoch:24 batch 820/2221) Loss:5.790378570556641\n",
      "epoch:24 batch 830/2221) Loss:11.751896858215332\n",
      "epoch:24 batch 840/2221) Loss:23.37774658203125\n",
      "epoch:24 batch 850/2221) Loss:4.322049617767334\n",
      "epoch:24 batch 860/2221) Loss:10.112639427185059\n",
      "epoch:24 batch 870/2221) Loss:1.8597246408462524\n",
      "epoch:24 batch 880/2221) Loss:4.114282131195068\n",
      "epoch:24 batch 890/2221) Loss:14.243026733398438\n",
      "epoch:24 batch 900/2221) Loss:1.570955753326416\n",
      "epoch:24 batch 910/2221) Loss:7.4496541023254395\n",
      "epoch:24 batch 920/2221) Loss:10.076776504516602\n",
      "epoch:24 batch 930/2221) Loss:7.789039611816406\n",
      "epoch:24 batch 940/2221) Loss:5.055362701416016\n",
      "epoch:24 batch 950/2221) Loss:1.174278974533081\n",
      "epoch:24 batch 960/2221) Loss:1.7562100887298584\n",
      "epoch:24 batch 970/2221) Loss:10.017631530761719\n",
      "epoch:24 batch 980/2221) Loss:8.753742218017578\n",
      "epoch:24 batch 990/2221) Loss:8.379597663879395\n",
      "epoch:24 batch 1000/2221) Loss:11.204261779785156\n",
      "epoch:24 batch 1010/2221) Loss:7.319308280944824\n",
      "epoch:24 batch 1020/2221) Loss:5.236070156097412\n",
      "epoch:24 batch 1030/2221) Loss:8.511651039123535\n",
      "epoch:24 batch 1040/2221) Loss:4.500528335571289\n",
      "epoch:24 batch 1050/2221) Loss:8.778705596923828\n",
      "epoch:24 batch 1060/2221) Loss:5.8742218017578125\n",
      "epoch:24 batch 1070/2221) Loss:11.489083290100098\n",
      "epoch:24 batch 1080/2221) Loss:21.802505493164062\n",
      "epoch:24 batch 1090/2221) Loss:4.950381278991699\n",
      "epoch:24 batch 1100/2221) Loss:3.285292625427246\n",
      "epoch:24 batch 1110/2221) Loss:2.2399821281433105\n",
      "epoch:24 batch 1120/2221) Loss:0.9898920059204102\n",
      "epoch:24 batch 1130/2221) Loss:11.55703353881836\n",
      "epoch:24 batch 1140/2221) Loss:8.868749618530273\n",
      "epoch:24 batch 1150/2221) Loss:16.500503540039062\n",
      "epoch:24 batch 1160/2221) Loss:9.673648834228516\n",
      "epoch:24 batch 1170/2221) Loss:7.102334022521973\n",
      "epoch:24 batch 1180/2221) Loss:4.940487861633301\n",
      "epoch:24 batch 1190/2221) Loss:19.568809509277344\n",
      "epoch:24 batch 1200/2221) Loss:6.97251033782959\n",
      "epoch:24 batch 1210/2221) Loss:4.3124494552612305\n",
      "epoch:24 batch 1220/2221) Loss:7.132847785949707\n",
      "epoch:24 batch 1230/2221) Loss:15.096508026123047\n",
      "epoch:24 batch 1240/2221) Loss:2.217482089996338\n",
      "epoch:24 batch 1250/2221) Loss:2.2274911403656006\n",
      "epoch:24 batch 1260/2221) Loss:14.559914588928223\n",
      "epoch:24 batch 1270/2221) Loss:2.6616740226745605\n",
      "epoch:24 batch 1280/2221) Loss:21.86721420288086\n",
      "epoch:24 batch 1290/2221) Loss:3.0037617683410645\n",
      "epoch:24 batch 1300/2221) Loss:15.449728012084961\n",
      "epoch:24 batch 1310/2221) Loss:5.348842620849609\n",
      "epoch:24 batch 1320/2221) Loss:6.681022644042969\n",
      "epoch:24 batch 1330/2221) Loss:20.317787170410156\n",
      "epoch:24 batch 1340/2221) Loss:9.080033302307129\n",
      "epoch:24 batch 1350/2221) Loss:10.190814971923828\n",
      "epoch:24 batch 1360/2221) Loss:4.014629364013672\n",
      "epoch:24 batch 1370/2221) Loss:10.097063064575195\n",
      "epoch:24 batch 1380/2221) Loss:7.25637149810791\n",
      "epoch:24 batch 1390/2221) Loss:6.029939651489258\n",
      "epoch:24 batch 1400/2221) Loss:3.3049540519714355\n",
      "epoch:24 batch 1410/2221) Loss:8.81590461730957\n",
      "epoch:24 batch 1420/2221) Loss:5.7566070556640625\n",
      "epoch:24 batch 1430/2221) Loss:14.284271240234375\n",
      "epoch:24 batch 1440/2221) Loss:10.251577377319336\n",
      "epoch:24 batch 1450/2221) Loss:7.37441349029541\n",
      "epoch:24 batch 1460/2221) Loss:10.604742050170898\n",
      "epoch:24 batch 1470/2221) Loss:3.0064353942871094\n",
      "epoch:24 batch 1480/2221) Loss:10.608778953552246\n",
      "epoch:24 batch 1490/2221) Loss:7.019131660461426\n",
      "epoch:24 batch 1500/2221) Loss:3.854963779449463\n",
      "epoch:24 batch 1510/2221) Loss:11.534307479858398\n",
      "epoch:24 batch 1520/2221) Loss:9.279731750488281\n",
      "epoch:24 batch 1530/2221) Loss:7.456350326538086\n",
      "epoch:24 batch 1540/2221) Loss:12.785003662109375\n",
      "epoch:24 batch 1550/2221) Loss:11.17855453491211\n",
      "epoch:24 batch 1560/2221) Loss:15.975008964538574\n",
      "epoch:24 batch 1570/2221) Loss:11.908352851867676\n",
      "epoch:24 batch 1580/2221) Loss:2.3465118408203125\n",
      "epoch:24 batch 1590/2221) Loss:7.225013256072998\n",
      "epoch:24 batch 1600/2221) Loss:9.23831558227539\n",
      "epoch:24 batch 1610/2221) Loss:11.18358325958252\n",
      "epoch:24 batch 1620/2221) Loss:1.238845944404602\n",
      "epoch:24 batch 1630/2221) Loss:3.076857566833496\n",
      "epoch:24 batch 1640/2221) Loss:4.860406398773193\n",
      "epoch:24 batch 1650/2221) Loss:2.792985677719116\n",
      "epoch:24 batch 1660/2221) Loss:3.790012836456299\n",
      "epoch:24 batch 1670/2221) Loss:10.76455020904541\n",
      "epoch:24 batch 1680/2221) Loss:12.710871696472168\n",
      "epoch:24 batch 1690/2221) Loss:18.388216018676758\n",
      "epoch:24 batch 1700/2221) Loss:9.868448257446289\n",
      "epoch:24 batch 1710/2221) Loss:10.596665382385254\n",
      "epoch:24 batch 1720/2221) Loss:6.157864570617676\n",
      "epoch:24 batch 1730/2221) Loss:12.785900115966797\n",
      "epoch:24 batch 1740/2221) Loss:3.7710344791412354\n",
      "epoch:24 batch 1750/2221) Loss:3.4315128326416016\n",
      "epoch:24 batch 1760/2221) Loss:13.469191551208496\n",
      "epoch:24 batch 1770/2221) Loss:7.8819355964660645\n",
      "epoch:24 batch 1780/2221) Loss:6.095123767852783\n",
      "epoch:24 batch 1790/2221) Loss:2.9094157218933105\n",
      "epoch:24 batch 1800/2221) Loss:4.668824672698975\n",
      "epoch:24 batch 1810/2221) Loss:6.526205062866211\n",
      "epoch:24 batch 1820/2221) Loss:6.700268745422363\n",
      "epoch:24 batch 1830/2221) Loss:8.101969718933105\n",
      "epoch:24 batch 1840/2221) Loss:11.090200424194336\n",
      "epoch:24 batch 1850/2221) Loss:3.1353342533111572\n",
      "epoch:24 batch 1860/2221) Loss:17.248035430908203\n",
      "epoch:24 batch 1870/2221) Loss:16.72506332397461\n",
      "epoch:24 batch 1880/2221) Loss:13.835233688354492\n",
      "epoch:24 batch 1890/2221) Loss:26.349536895751953\n",
      "epoch:24 batch 1900/2221) Loss:2.6122844219207764\n",
      "epoch:24 batch 1910/2221) Loss:16.08544158935547\n",
      "epoch:24 batch 1920/2221) Loss:5.706107139587402\n",
      "epoch:24 batch 1930/2221) Loss:9.454202651977539\n",
      "epoch:24 batch 1940/2221) Loss:13.823970794677734\n",
      "epoch:24 batch 1950/2221) Loss:6.704798221588135\n",
      "epoch:24 batch 1960/2221) Loss:13.922355651855469\n",
      "epoch:24 batch 1970/2221) Loss:19.54658317565918\n",
      "epoch:24 batch 1980/2221) Loss:7.511229515075684\n",
      "epoch:24 batch 1990/2221) Loss:11.290521621704102\n",
      "epoch:24 batch 2000/2221) Loss:14.233490943908691\n",
      "epoch:24 batch 2010/2221) Loss:3.7125039100646973\n",
      "epoch:24 batch 2020/2221) Loss:2.364323854446411\n",
      "epoch:24 batch 2030/2221) Loss:11.098344802856445\n",
      "epoch:24 batch 2040/2221) Loss:11.831092834472656\n",
      "epoch:24 batch 2050/2221) Loss:1.6040256023406982\n",
      "epoch:24 batch 2060/2221) Loss:6.340281009674072\n",
      "epoch:24 batch 2070/2221) Loss:18.859567642211914\n",
      "epoch:24 batch 2080/2221) Loss:16.034996032714844\n",
      "epoch:24 batch 2090/2221) Loss:18.108123779296875\n",
      "epoch:24 batch 2100/2221) Loss:4.728646755218506\n",
      "epoch:24 batch 2110/2221) Loss:28.470186233520508\n",
      "epoch:24 batch 2120/2221) Loss:2.360954761505127\n",
      "epoch:24 batch 2130/2221) Loss:11.227846145629883\n",
      "epoch:24 batch 2140/2221) Loss:4.860651016235352\n",
      "epoch:24 batch 2150/2221) Loss:6.350138187408447\n",
      "epoch:24 batch 2160/2221) Loss:18.67529296875\n",
      "epoch:24 batch 2170/2221) Loss:6.852663516998291\n",
      "epoch:24 batch 2180/2221) Loss:1.701542615890503\n",
      "epoch:24 batch 2190/2221) Loss:7.841723442077637\n",
      "epoch:24 batch 2200/2221) Loss:5.195529937744141\n",
      "epoch:24 batch 2210/2221) Loss:9.727986335754395\n",
      "epoch:24 batch 2220/2221) Loss:12.778984069824219\n",
      "epoch:24 precision:0.9962274594644427 recall:0.988800335319836 f1-score:0.9924597172240112\n",
      "epoch:25 batch 1/2221) Loss:6.937147617340088\n",
      "epoch:25 batch 10/2221) Loss:4.203769207000732\n",
      "epoch:25 batch 20/2221) Loss:9.425858497619629\n",
      "epoch:25 batch 30/2221) Loss:13.309423446655273\n",
      "epoch:25 batch 40/2221) Loss:6.409395694732666\n",
      "epoch:25 batch 50/2221) Loss:1.5558634996414185\n",
      "epoch:25 batch 60/2221) Loss:1.2017964124679565\n",
      "epoch:25 batch 70/2221) Loss:9.773242950439453\n",
      "epoch:25 batch 80/2221) Loss:17.842002868652344\n",
      "epoch:25 batch 90/2221) Loss:2.7115025520324707\n",
      "epoch:25 batch 100/2221) Loss:10.111650466918945\n",
      "epoch:25 batch 110/2221) Loss:8.943577766418457\n",
      "epoch:25 batch 120/2221) Loss:8.564834594726562\n",
      "epoch:25 batch 130/2221) Loss:5.182250499725342\n",
      "epoch:25 batch 140/2221) Loss:12.355083465576172\n",
      "epoch:25 batch 150/2221) Loss:10.531292915344238\n",
      "epoch:25 batch 160/2221) Loss:29.788619995117188\n",
      "epoch:25 batch 170/2221) Loss:9.929513931274414\n",
      "epoch:25 batch 180/2221) Loss:11.967877388000488\n",
      "epoch:25 batch 190/2221) Loss:9.294316291809082\n",
      "epoch:25 batch 200/2221) Loss:2.1947097778320312\n",
      "epoch:25 batch 210/2221) Loss:3.8658032417297363\n",
      "epoch:25 batch 220/2221) Loss:6.175281047821045\n",
      "epoch:25 batch 230/2221) Loss:2.2179548740386963\n",
      "epoch:25 batch 240/2221) Loss:10.313879013061523\n",
      "epoch:25 batch 250/2221) Loss:6.766805171966553\n",
      "epoch:25 batch 260/2221) Loss:17.64330291748047\n",
      "epoch:25 batch 270/2221) Loss:1.3131928443908691\n",
      "epoch:25 batch 280/2221) Loss:9.395512580871582\n",
      "epoch:25 batch 290/2221) Loss:6.247165679931641\n",
      "epoch:25 batch 300/2221) Loss:14.897274017333984\n",
      "epoch:25 batch 310/2221) Loss:6.291839122772217\n",
      "epoch:25 batch 320/2221) Loss:1.0808875560760498\n",
      "epoch:25 batch 330/2221) Loss:7.929039478302002\n",
      "epoch:25 batch 340/2221) Loss:9.287181854248047\n",
      "epoch:25 batch 350/2221) Loss:11.150266647338867\n",
      "epoch:25 batch 360/2221) Loss:4.617537975311279\n",
      "epoch:25 batch 370/2221) Loss:1.683511734008789\n",
      "epoch:25 batch 380/2221) Loss:22.27462387084961\n",
      "epoch:25 batch 390/2221) Loss:5.044458866119385\n",
      "epoch:25 batch 400/2221) Loss:1.2021002769470215\n",
      "epoch:25 batch 410/2221) Loss:19.468181610107422\n",
      "epoch:25 batch 420/2221) Loss:6.423343181610107\n",
      "epoch:25 batch 430/2221) Loss:11.944195747375488\n",
      "epoch:25 batch 440/2221) Loss:6.911448001861572\n",
      "epoch:25 batch 450/2221) Loss:9.875452041625977\n",
      "epoch:25 batch 460/2221) Loss:6.959280967712402\n",
      "epoch:25 batch 470/2221) Loss:10.980142593383789\n",
      "epoch:25 batch 480/2221) Loss:1.686240315437317\n",
      "epoch:25 batch 490/2221) Loss:20.196949005126953\n",
      "epoch:25 batch 500/2221) Loss:5.255235195159912\n",
      "epoch:25 batch 510/2221) Loss:15.550089836120605\n",
      "epoch:25 batch 520/2221) Loss:7.495731353759766\n",
      "epoch:25 batch 530/2221) Loss:7.860090732574463\n",
      "epoch:25 batch 540/2221) Loss:8.369226455688477\n",
      "epoch:25 batch 550/2221) Loss:24.860198974609375\n",
      "epoch:25 batch 560/2221) Loss:8.713781356811523\n",
      "epoch:25 batch 570/2221) Loss:6.304357051849365\n",
      "epoch:25 batch 580/2221) Loss:4.683788299560547\n",
      "epoch:25 batch 590/2221) Loss:13.216625213623047\n",
      "epoch:25 batch 600/2221) Loss:17.854413986206055\n",
      "epoch:25 batch 610/2221) Loss:7.9004225730896\n",
      "epoch:25 batch 620/2221) Loss:1.1011258363723755\n",
      "epoch:25 batch 630/2221) Loss:32.39588928222656\n",
      "epoch:25 batch 640/2221) Loss:7.767662048339844\n",
      "epoch:25 batch 650/2221) Loss:9.468145370483398\n",
      "epoch:25 batch 660/2221) Loss:9.031628608703613\n",
      "epoch:25 batch 670/2221) Loss:4.047383785247803\n",
      "epoch:25 batch 680/2221) Loss:12.35755443572998\n",
      "epoch:25 batch 690/2221) Loss:8.632140159606934\n",
      "epoch:25 batch 700/2221) Loss:1.8744680881500244\n",
      "epoch:25 batch 710/2221) Loss:4.186071395874023\n",
      "epoch:25 batch 720/2221) Loss:8.864864349365234\n",
      "epoch:25 batch 730/2221) Loss:5.945676803588867\n",
      "epoch:25 batch 740/2221) Loss:3.4109764099121094\n",
      "epoch:25 batch 750/2221) Loss:7.7890143394470215\n",
      "epoch:25 batch 760/2221) Loss:4.493281364440918\n",
      "epoch:25 batch 770/2221) Loss:9.938416481018066\n",
      "epoch:25 batch 780/2221) Loss:9.632451057434082\n",
      "epoch:25 batch 790/2221) Loss:1.9412258863449097\n",
      "epoch:25 batch 800/2221) Loss:1.794454574584961\n",
      "epoch:25 batch 810/2221) Loss:3.5568599700927734\n",
      "epoch:25 batch 820/2221) Loss:5.41801643371582\n",
      "epoch:25 batch 830/2221) Loss:3.100851535797119\n",
      "epoch:25 batch 840/2221) Loss:2.9457974433898926\n",
      "epoch:25 batch 850/2221) Loss:2.4015870094299316\n",
      "epoch:25 batch 860/2221) Loss:2.247260570526123\n",
      "epoch:25 batch 870/2221) Loss:4.709407806396484\n",
      "epoch:25 batch 880/2221) Loss:2.895477771759033\n",
      "epoch:25 batch 890/2221) Loss:13.337259292602539\n",
      "epoch:25 batch 900/2221) Loss:1.86674964427948\n",
      "epoch:25 batch 910/2221) Loss:4.865968704223633\n",
      "epoch:25 batch 920/2221) Loss:2.052262783050537\n",
      "epoch:25 batch 930/2221) Loss:2.5029075145721436\n",
      "epoch:25 batch 940/2221) Loss:2.2799601554870605\n",
      "epoch:25 batch 950/2221) Loss:11.852651596069336\n",
      "epoch:25 batch 960/2221) Loss:6.162322998046875\n",
      "epoch:25 batch 970/2221) Loss:7.797441482543945\n",
      "epoch:25 batch 980/2221) Loss:3.5954933166503906\n",
      "epoch:25 batch 990/2221) Loss:18.260276794433594\n",
      "epoch:25 batch 1000/2221) Loss:12.421491622924805\n",
      "epoch:25 batch 1010/2221) Loss:6.725380897521973\n",
      "epoch:25 batch 1020/2221) Loss:9.405016899108887\n",
      "epoch:25 batch 1030/2221) Loss:4.762994766235352\n",
      "epoch:25 batch 1040/2221) Loss:8.333213806152344\n",
      "epoch:25 batch 1050/2221) Loss:5.751893997192383\n",
      "epoch:25 batch 1060/2221) Loss:3.1889538764953613\n",
      "epoch:25 batch 1070/2221) Loss:10.541877746582031\n",
      "epoch:25 batch 1080/2221) Loss:1.3569585084915161\n",
      "epoch:25 batch 1090/2221) Loss:3.7769737243652344\n",
      "epoch:25 batch 1100/2221) Loss:4.2829060554504395\n",
      "epoch:25 batch 1110/2221) Loss:10.123745918273926\n",
      "epoch:25 batch 1120/2221) Loss:1.6055101156234741\n",
      "epoch:25 batch 1130/2221) Loss:5.8430328369140625\n",
      "epoch:25 batch 1140/2221) Loss:12.961116790771484\n",
      "epoch:25 batch 1150/2221) Loss:12.369248390197754\n",
      "epoch:25 batch 1160/2221) Loss:8.628414154052734\n",
      "epoch:25 batch 1170/2221) Loss:9.783098220825195\n",
      "epoch:25 batch 1180/2221) Loss:9.745292663574219\n",
      "epoch:25 batch 1190/2221) Loss:2.3188300132751465\n",
      "epoch:25 batch 1200/2221) Loss:19.79709243774414\n",
      "epoch:25 batch 1210/2221) Loss:2.388634443283081\n",
      "epoch:25 batch 1220/2221) Loss:13.668020248413086\n",
      "epoch:25 batch 1230/2221) Loss:16.70998764038086\n",
      "epoch:25 batch 1240/2221) Loss:17.727783203125\n",
      "epoch:25 batch 1250/2221) Loss:5.405245304107666\n",
      "epoch:25 batch 1260/2221) Loss:10.339852333068848\n",
      "epoch:25 batch 1270/2221) Loss:3.608260154724121\n",
      "epoch:25 batch 1280/2221) Loss:12.891988754272461\n",
      "epoch:25 batch 1290/2221) Loss:14.649591445922852\n",
      "epoch:25 batch 1300/2221) Loss:15.8955078125\n",
      "epoch:25 batch 1310/2221) Loss:12.753074645996094\n",
      "epoch:25 batch 1320/2221) Loss:7.311769962310791\n",
      "epoch:25 batch 1330/2221) Loss:0.76468825340271\n",
      "epoch:25 batch 1340/2221) Loss:4.12807559967041\n",
      "epoch:25 batch 1350/2221) Loss:22.56938362121582\n",
      "epoch:25 batch 1360/2221) Loss:3.1557445526123047\n",
      "epoch:25 batch 1370/2221) Loss:8.414405822753906\n",
      "epoch:25 batch 1380/2221) Loss:13.930021286010742\n",
      "epoch:25 batch 1390/2221) Loss:7.763460159301758\n",
      "epoch:25 batch 1400/2221) Loss:2.2075552940368652\n",
      "epoch:25 batch 1410/2221) Loss:3.0945985317230225\n",
      "epoch:25 batch 1420/2221) Loss:8.58533763885498\n",
      "epoch:25 batch 1430/2221) Loss:6.128049373626709\n",
      "epoch:25 batch 1440/2221) Loss:8.209859848022461\n",
      "epoch:25 batch 1450/2221) Loss:4.678633689880371\n",
      "epoch:25 batch 1460/2221) Loss:5.246225833892822\n",
      "epoch:25 batch 1470/2221) Loss:8.961106300354004\n",
      "epoch:25 batch 1480/2221) Loss:30.678377151489258\n",
      "epoch:25 batch 1490/2221) Loss:2.4042489528656006\n",
      "epoch:25 batch 1500/2221) Loss:6.378235340118408\n",
      "epoch:25 batch 1510/2221) Loss:10.55375862121582\n",
      "epoch:25 batch 1520/2221) Loss:16.685443878173828\n",
      "epoch:25 batch 1530/2221) Loss:2.9090609550476074\n",
      "epoch:25 batch 1540/2221) Loss:13.388418197631836\n",
      "epoch:25 batch 1550/2221) Loss:4.309876918792725\n",
      "epoch:25 batch 1560/2221) Loss:3.590350389480591\n",
      "epoch:25 batch 1570/2221) Loss:11.193893432617188\n",
      "epoch:25 batch 1580/2221) Loss:25.19439697265625\n",
      "epoch:25 batch 1590/2221) Loss:3.0244264602661133\n",
      "epoch:25 batch 1600/2221) Loss:10.600166320800781\n",
      "epoch:25 batch 1610/2221) Loss:1.3962502479553223\n",
      "epoch:25 batch 1620/2221) Loss:4.193188667297363\n",
      "epoch:25 batch 1630/2221) Loss:1.742082118988037\n",
      "epoch:25 batch 1640/2221) Loss:11.738923072814941\n",
      "epoch:25 batch 1650/2221) Loss:30.68550682067871\n",
      "epoch:25 batch 1660/2221) Loss:17.843547821044922\n",
      "epoch:25 batch 1670/2221) Loss:12.963804244995117\n",
      "epoch:25 batch 1680/2221) Loss:12.546506881713867\n",
      "epoch:25 batch 1690/2221) Loss:16.255813598632812\n",
      "epoch:25 batch 1700/2221) Loss:11.069110870361328\n",
      "epoch:25 batch 1710/2221) Loss:15.709712982177734\n",
      "epoch:25 batch 1720/2221) Loss:11.530510902404785\n",
      "epoch:25 batch 1730/2221) Loss:10.035024642944336\n",
      "epoch:25 batch 1740/2221) Loss:6.575773239135742\n",
      "epoch:25 batch 1750/2221) Loss:3.792541027069092\n",
      "epoch:25 batch 1760/2221) Loss:14.375394821166992\n",
      "epoch:25 batch 1770/2221) Loss:11.212491989135742\n",
      "epoch:25 batch 1780/2221) Loss:22.133773803710938\n",
      "epoch:25 batch 1790/2221) Loss:10.842439651489258\n",
      "epoch:25 batch 1800/2221) Loss:14.744783401489258\n",
      "epoch:25 batch 1810/2221) Loss:24.74176025390625\n",
      "epoch:25 batch 1820/2221) Loss:8.120868682861328\n",
      "epoch:25 batch 1830/2221) Loss:15.866461753845215\n",
      "epoch:25 batch 1840/2221) Loss:4.2526397705078125\n",
      "epoch:25 batch 1850/2221) Loss:6.1757917404174805\n",
      "epoch:25 batch 1860/2221) Loss:12.957487106323242\n",
      "epoch:25 batch 1870/2221) Loss:7.218721866607666\n",
      "epoch:25 batch 1880/2221) Loss:8.160229682922363\n",
      "epoch:25 batch 1890/2221) Loss:6.580830097198486\n",
      "epoch:25 batch 1900/2221) Loss:17.888471603393555\n",
      "epoch:25 batch 1910/2221) Loss:5.329341888427734\n",
      "epoch:25 batch 1920/2221) Loss:9.494829177856445\n",
      "epoch:25 batch 1930/2221) Loss:1.1511378288269043\n",
      "epoch:25 batch 1940/2221) Loss:7.009432792663574\n",
      "epoch:25 batch 1950/2221) Loss:12.776226043701172\n",
      "epoch:25 batch 1960/2221) Loss:9.601393699645996\n",
      "epoch:25 batch 1970/2221) Loss:3.9876656532287598\n",
      "epoch:25 batch 1980/2221) Loss:26.469036102294922\n",
      "epoch:25 batch 1990/2221) Loss:2.717252731323242\n",
      "epoch:25 batch 2000/2221) Loss:6.827463626861572\n",
      "epoch:25 batch 2010/2221) Loss:16.065731048583984\n",
      "epoch:25 batch 2020/2221) Loss:0.9529215097427368\n",
      "epoch:25 batch 2030/2221) Loss:16.789960861206055\n",
      "epoch:25 batch 2040/2221) Loss:8.519960403442383\n",
      "epoch:25 batch 2050/2221) Loss:13.624834060668945\n",
      "epoch:25 batch 2060/2221) Loss:7.0936174392700195\n",
      "epoch:25 batch 2070/2221) Loss:3.8611087799072266\n",
      "epoch:25 batch 2080/2221) Loss:1.9498273134231567\n",
      "epoch:25 batch 2090/2221) Loss:11.277900695800781\n",
      "epoch:25 batch 2100/2221) Loss:9.768974304199219\n",
      "epoch:25 batch 2110/2221) Loss:5.732692718505859\n",
      "epoch:25 batch 2120/2221) Loss:8.29623031616211\n",
      "epoch:25 batch 2130/2221) Loss:22.161895751953125\n",
      "epoch:25 batch 2140/2221) Loss:7.583015441894531\n",
      "epoch:25 batch 2150/2221) Loss:0.6107162237167358\n",
      "epoch:25 batch 2160/2221) Loss:12.442340850830078\n",
      "epoch:25 batch 2170/2221) Loss:7.95674467086792\n",
      "epoch:25 batch 2180/2221) Loss:10.023550987243652\n",
      "epoch:25 batch 2190/2221) Loss:13.967523574829102\n",
      "epoch:25 batch 2200/2221) Loss:17.289936065673828\n",
      "epoch:25 batch 2210/2221) Loss:6.172041893005371\n",
      "epoch:25 batch 2220/2221) Loss:2.1077699661254883\n",
      "epoch:25 precision:0.9969480051909091 recall:0.9883275286905492 f1-score:0.9925751871944464\n",
      "epoch:26 batch 1/2221) Loss:6.491847038269043\n",
      "epoch:26 batch 10/2221) Loss:13.407976150512695\n",
      "epoch:26 batch 20/2221) Loss:16.42275619506836\n",
      "epoch:26 batch 30/2221) Loss:10.362092018127441\n",
      "epoch:26 batch 40/2221) Loss:2.8024215698242188\n",
      "epoch:26 batch 50/2221) Loss:12.280263900756836\n",
      "epoch:26 batch 60/2221) Loss:7.697258949279785\n",
      "epoch:26 batch 70/2221) Loss:3.9592995643615723\n",
      "epoch:26 batch 80/2221) Loss:9.426118850708008\n",
      "epoch:26 batch 90/2221) Loss:2.3711681365966797\n",
      "epoch:26 batch 100/2221) Loss:2.992751121520996\n",
      "epoch:26 batch 110/2221) Loss:8.77402400970459\n",
      "epoch:26 batch 120/2221) Loss:14.35777473449707\n",
      "epoch:26 batch 130/2221) Loss:3.70387601852417\n",
      "epoch:26 batch 140/2221) Loss:5.590393543243408\n",
      "epoch:26 batch 150/2221) Loss:23.443967819213867\n",
      "epoch:26 batch 160/2221) Loss:23.186325073242188\n",
      "epoch:26 batch 170/2221) Loss:8.113435745239258\n",
      "epoch:26 batch 180/2221) Loss:8.369704246520996\n",
      "epoch:26 batch 190/2221) Loss:0.49002814292907715\n",
      "epoch:26 batch 200/2221) Loss:9.223556518554688\n",
      "epoch:26 batch 210/2221) Loss:21.699798583984375\n",
      "epoch:26 batch 220/2221) Loss:0.9257498979568481\n",
      "epoch:26 batch 230/2221) Loss:12.762770652770996\n",
      "epoch:26 batch 240/2221) Loss:3.945374011993408\n",
      "epoch:26 batch 250/2221) Loss:2.925297260284424\n",
      "epoch:26 batch 260/2221) Loss:15.308769226074219\n",
      "epoch:26 batch 270/2221) Loss:11.224778175354004\n",
      "epoch:26 batch 280/2221) Loss:15.19678783416748\n",
      "epoch:26 batch 290/2221) Loss:7.643138885498047\n",
      "epoch:26 batch 300/2221) Loss:4.715137481689453\n",
      "epoch:26 batch 310/2221) Loss:1.4325717687606812\n",
      "epoch:26 batch 320/2221) Loss:2.1819984912872314\n",
      "epoch:26 batch 330/2221) Loss:1.0974088907241821\n",
      "epoch:26 batch 340/2221) Loss:6.348061561584473\n",
      "epoch:26 batch 350/2221) Loss:14.919355392456055\n",
      "epoch:26 batch 360/2221) Loss:3.9371490478515625\n",
      "epoch:26 batch 370/2221) Loss:6.831088066101074\n",
      "epoch:26 batch 380/2221) Loss:16.136903762817383\n",
      "epoch:26 batch 390/2221) Loss:9.121395111083984\n",
      "epoch:26 batch 400/2221) Loss:7.507031440734863\n",
      "epoch:26 batch 410/2221) Loss:14.570035934448242\n",
      "epoch:26 batch 420/2221) Loss:1.4620469808578491\n",
      "epoch:26 batch 430/2221) Loss:2.1611392498016357\n",
      "epoch:26 batch 440/2221) Loss:15.342781066894531\n",
      "epoch:26 batch 450/2221) Loss:2.70780611038208\n",
      "epoch:26 batch 460/2221) Loss:1.6253501176834106\n",
      "epoch:26 batch 470/2221) Loss:10.44514274597168\n",
      "epoch:26 batch 480/2221) Loss:2.070189952850342\n",
      "epoch:26 batch 490/2221) Loss:5.975592613220215\n",
      "epoch:26 batch 500/2221) Loss:6.268846035003662\n",
      "epoch:26 batch 510/2221) Loss:5.958498477935791\n",
      "epoch:26 batch 520/2221) Loss:6.888124465942383\n",
      "epoch:26 batch 530/2221) Loss:20.485410690307617\n",
      "epoch:26 batch 540/2221) Loss:9.394909858703613\n",
      "epoch:26 batch 550/2221) Loss:7.680227279663086\n",
      "epoch:26 batch 560/2221) Loss:14.345592498779297\n",
      "epoch:26 batch 570/2221) Loss:15.935422897338867\n",
      "epoch:26 batch 580/2221) Loss:5.127325534820557\n",
      "epoch:26 batch 590/2221) Loss:8.189728736877441\n",
      "epoch:26 batch 600/2221) Loss:4.698674201965332\n",
      "epoch:26 batch 610/2221) Loss:5.348888397216797\n",
      "epoch:26 batch 620/2221) Loss:15.074350357055664\n",
      "epoch:26 batch 630/2221) Loss:6.28988790512085\n",
      "epoch:26 batch 640/2221) Loss:11.12612533569336\n",
      "epoch:26 batch 650/2221) Loss:7.988193511962891\n",
      "epoch:26 batch 660/2221) Loss:8.573277473449707\n",
      "epoch:26 batch 670/2221) Loss:2.4045417308807373\n",
      "epoch:26 batch 680/2221) Loss:4.525155067443848\n",
      "epoch:26 batch 690/2221) Loss:6.483172416687012\n",
      "epoch:26 batch 700/2221) Loss:9.358793258666992\n",
      "epoch:26 batch 710/2221) Loss:6.430877685546875\n",
      "epoch:26 batch 720/2221) Loss:1.2353590726852417\n",
      "epoch:26 batch 730/2221) Loss:5.802855491638184\n",
      "epoch:26 batch 740/2221) Loss:7.99397087097168\n",
      "epoch:26 batch 750/2221) Loss:11.082636833190918\n",
      "epoch:26 batch 760/2221) Loss:2.130743980407715\n",
      "epoch:26 batch 770/2221) Loss:13.654549598693848\n",
      "epoch:26 batch 780/2221) Loss:10.40455150604248\n",
      "epoch:26 batch 790/2221) Loss:6.499905586242676\n",
      "epoch:26 batch 800/2221) Loss:11.242836952209473\n",
      "epoch:26 batch 810/2221) Loss:1.5262479782104492\n",
      "epoch:26 batch 820/2221) Loss:2.841758966445923\n",
      "epoch:26 batch 830/2221) Loss:1.3091094493865967\n",
      "epoch:26 batch 840/2221) Loss:5.677576065063477\n",
      "epoch:26 batch 850/2221) Loss:4.775796890258789\n",
      "epoch:26 batch 860/2221) Loss:18.085779190063477\n",
      "epoch:26 batch 870/2221) Loss:21.2928466796875\n",
      "epoch:26 batch 880/2221) Loss:3.0122523307800293\n",
      "epoch:26 batch 890/2221) Loss:3.8029909133911133\n",
      "epoch:26 batch 900/2221) Loss:17.303173065185547\n",
      "epoch:26 batch 910/2221) Loss:1.1258710622787476\n",
      "epoch:26 batch 920/2221) Loss:4.29572057723999\n",
      "epoch:26 batch 930/2221) Loss:2.628404140472412\n",
      "epoch:26 batch 940/2221) Loss:14.593672752380371\n",
      "epoch:26 batch 950/2221) Loss:10.475581169128418\n",
      "epoch:26 batch 960/2221) Loss:13.970296859741211\n",
      "epoch:26 batch 970/2221) Loss:10.562000274658203\n",
      "epoch:26 batch 980/2221) Loss:1.8142718076705933\n",
      "epoch:26 batch 990/2221) Loss:7.554299354553223\n",
      "epoch:26 batch 1000/2221) Loss:4.331700325012207\n",
      "epoch:26 batch 1010/2221) Loss:1.4477120637893677\n",
      "epoch:26 batch 1020/2221) Loss:9.7236967086792\n",
      "epoch:26 batch 1030/2221) Loss:17.051054000854492\n",
      "epoch:26 batch 1040/2221) Loss:1.0451719760894775\n",
      "epoch:26 batch 1050/2221) Loss:3.872364044189453\n",
      "epoch:26 batch 1060/2221) Loss:14.088380813598633\n",
      "epoch:26 batch 1070/2221) Loss:15.332535743713379\n",
      "epoch:26 batch 1080/2221) Loss:2.112128257751465\n",
      "epoch:26 batch 1090/2221) Loss:13.528532981872559\n",
      "epoch:26 batch 1100/2221) Loss:3.120083808898926\n",
      "epoch:26 batch 1110/2221) Loss:6.07755708694458\n",
      "epoch:26 batch 1120/2221) Loss:30.78307342529297\n",
      "epoch:26 batch 1130/2221) Loss:5.2741169929504395\n",
      "epoch:26 batch 1140/2221) Loss:6.377211570739746\n",
      "epoch:26 batch 1150/2221) Loss:9.975345611572266\n",
      "epoch:26 batch 1160/2221) Loss:1.8234986066818237\n",
      "epoch:26 batch 1170/2221) Loss:4.651494979858398\n",
      "epoch:26 batch 1180/2221) Loss:14.18586254119873\n",
      "epoch:26 batch 1190/2221) Loss:24.507722854614258\n",
      "epoch:26 batch 1200/2221) Loss:14.120414733886719\n",
      "epoch:26 batch 1210/2221) Loss:15.400548934936523\n",
      "epoch:26 batch 1220/2221) Loss:5.021576881408691\n",
      "epoch:26 batch 1230/2221) Loss:14.991361618041992\n",
      "epoch:26 batch 1240/2221) Loss:4.474662780761719\n",
      "epoch:26 batch 1250/2221) Loss:9.634271621704102\n",
      "epoch:26 batch 1260/2221) Loss:1.513708233833313\n",
      "epoch:26 batch 1270/2221) Loss:5.453878879547119\n",
      "epoch:26 batch 1280/2221) Loss:13.5271635055542\n",
      "epoch:26 batch 1290/2221) Loss:17.205902099609375\n",
      "epoch:26 batch 1300/2221) Loss:6.510805130004883\n",
      "epoch:26 batch 1310/2221) Loss:12.341155052185059\n",
      "epoch:26 batch 1320/2221) Loss:15.5006742477417\n",
      "epoch:26 batch 1330/2221) Loss:8.060239791870117\n",
      "epoch:26 batch 1340/2221) Loss:13.845178604125977\n",
      "epoch:26 batch 1350/2221) Loss:5.35413122177124\n",
      "epoch:26 batch 1360/2221) Loss:9.482965469360352\n",
      "epoch:26 batch 1370/2221) Loss:7.277468681335449\n",
      "epoch:26 batch 1380/2221) Loss:9.083900451660156\n",
      "epoch:26 batch 1390/2221) Loss:5.531744480133057\n",
      "epoch:26 batch 1400/2221) Loss:4.895604133605957\n",
      "epoch:26 batch 1410/2221) Loss:8.881486892700195\n",
      "epoch:26 batch 1420/2221) Loss:14.630582809448242\n",
      "epoch:26 batch 1430/2221) Loss:32.93331527709961\n",
      "epoch:26 batch 1440/2221) Loss:36.304901123046875\n",
      "epoch:26 batch 1450/2221) Loss:1.4645264148712158\n",
      "epoch:26 batch 1460/2221) Loss:2.050665855407715\n",
      "epoch:26 batch 1470/2221) Loss:9.082244873046875\n",
      "epoch:26 batch 1480/2221) Loss:10.974414825439453\n",
      "epoch:26 batch 1490/2221) Loss:11.050414085388184\n",
      "epoch:26 batch 1500/2221) Loss:14.180291175842285\n",
      "epoch:26 batch 1510/2221) Loss:7.55061149597168\n",
      "epoch:26 batch 1520/2221) Loss:9.782598495483398\n",
      "epoch:26 batch 1530/2221) Loss:11.866466522216797\n",
      "epoch:26 batch 1540/2221) Loss:8.710033416748047\n",
      "epoch:26 batch 1550/2221) Loss:35.87108612060547\n",
      "epoch:26 batch 1560/2221) Loss:20.78403663635254\n",
      "epoch:26 batch 1570/2221) Loss:25.770780563354492\n",
      "epoch:26 batch 1580/2221) Loss:6.221707344055176\n",
      "epoch:26 batch 1590/2221) Loss:21.723953247070312\n",
      "epoch:26 batch 1600/2221) Loss:4.386612892150879\n",
      "epoch:26 batch 1610/2221) Loss:23.664997100830078\n",
      "epoch:26 batch 1620/2221) Loss:2.003570079803467\n",
      "epoch:26 batch 1630/2221) Loss:3.706376075744629\n",
      "epoch:26 batch 1640/2221) Loss:52.653907775878906\n",
      "epoch:26 batch 1650/2221) Loss:6.925703048706055\n",
      "epoch:26 batch 1660/2221) Loss:14.092351913452148\n",
      "epoch:26 batch 1670/2221) Loss:12.564712524414062\n",
      "epoch:26 batch 1680/2221) Loss:5.923089981079102\n",
      "epoch:26 batch 1690/2221) Loss:16.507787704467773\n",
      "epoch:26 batch 1700/2221) Loss:1.3792704343795776\n",
      "epoch:26 batch 1710/2221) Loss:20.630802154541016\n",
      "epoch:26 batch 1720/2221) Loss:10.308431625366211\n",
      "epoch:26 batch 1730/2221) Loss:8.952252388000488\n",
      "epoch:26 batch 1740/2221) Loss:4.794421195983887\n",
      "epoch:26 batch 1750/2221) Loss:7.757095813751221\n",
      "epoch:26 batch 1760/2221) Loss:7.354376792907715\n",
      "epoch:26 batch 1770/2221) Loss:2.6197328567504883\n",
      "epoch:26 batch 1780/2221) Loss:4.7658281326293945\n",
      "epoch:26 batch 1790/2221) Loss:7.716602802276611\n",
      "epoch:26 batch 1800/2221) Loss:9.580968856811523\n",
      "epoch:26 batch 1810/2221) Loss:25.95124053955078\n",
      "epoch:26 batch 1820/2221) Loss:9.344449996948242\n",
      "epoch:26 batch 1830/2221) Loss:3.6403470039367676\n",
      "epoch:26 batch 1840/2221) Loss:6.0540690422058105\n",
      "epoch:26 batch 1850/2221) Loss:9.79259967803955\n",
      "epoch:26 batch 1860/2221) Loss:9.000170707702637\n",
      "epoch:26 batch 1870/2221) Loss:10.330253601074219\n",
      "epoch:26 batch 1880/2221) Loss:6.65070915222168\n",
      "epoch:26 batch 1890/2221) Loss:8.082289695739746\n",
      "epoch:26 batch 1900/2221) Loss:11.6318359375\n",
      "epoch:26 batch 1910/2221) Loss:5.3221821784973145\n",
      "epoch:26 batch 1920/2221) Loss:6.41124153137207\n",
      "epoch:26 batch 1930/2221) Loss:17.921001434326172\n",
      "epoch:26 batch 1940/2221) Loss:14.873404502868652\n",
      "epoch:26 batch 1950/2221) Loss:1.9742943048477173\n",
      "epoch:26 batch 1960/2221) Loss:2.863826274871826\n",
      "epoch:26 batch 1970/2221) Loss:9.343052864074707\n",
      "epoch:26 batch 1980/2221) Loss:10.98029899597168\n",
      "epoch:26 batch 1990/2221) Loss:8.948098182678223\n",
      "epoch:26 batch 2000/2221) Loss:12.617645263671875\n",
      "epoch:26 batch 2010/2221) Loss:1.4908981323242188\n",
      "epoch:26 batch 2020/2221) Loss:7.071145534515381\n",
      "epoch:26 batch 2030/2221) Loss:6.083364486694336\n",
      "epoch:26 batch 2040/2221) Loss:13.530077934265137\n",
      "epoch:26 batch 2050/2221) Loss:10.316932678222656\n",
      "epoch:26 batch 2060/2221) Loss:14.351186752319336\n",
      "epoch:26 batch 2070/2221) Loss:16.760530471801758\n",
      "epoch:26 batch 2080/2221) Loss:5.25643253326416\n",
      "epoch:26 batch 2090/2221) Loss:7.5066070556640625\n",
      "epoch:26 batch 2100/2221) Loss:7.033921718597412\n",
      "epoch:26 batch 2110/2221) Loss:6.419384002685547\n",
      "epoch:26 batch 2120/2221) Loss:5.666563510894775\n",
      "epoch:26 batch 2130/2221) Loss:1.2908884286880493\n",
      "epoch:26 batch 2140/2221) Loss:2.0781900882720947\n",
      "epoch:26 batch 2150/2221) Loss:20.57716941833496\n",
      "epoch:26 batch 2160/2221) Loss:8.740833282470703\n",
      "epoch:26 batch 2170/2221) Loss:14.78116226196289\n",
      "epoch:26 batch 2180/2221) Loss:17.921405792236328\n",
      "epoch:26 batch 2190/2221) Loss:1.6973295211791992\n",
      "epoch:26 batch 2200/2221) Loss:1.4994876384735107\n",
      "epoch:26 batch 2210/2221) Loss:12.338319778442383\n",
      "epoch:26 batch 2220/2221) Loss:26.215984344482422\n",
      "epoch:26 precision:0.9961106658543496 recall:0.9895205391100224 f1-score:0.9927686584024474\n",
      "epoch:27 batch 1/2221) Loss:18.089462280273438\n",
      "epoch:27 batch 10/2221) Loss:6.295257568359375\n",
      "epoch:27 batch 20/2221) Loss:10.152807235717773\n",
      "epoch:27 batch 30/2221) Loss:3.912562608718872\n",
      "epoch:27 batch 40/2221) Loss:14.465117454528809\n",
      "epoch:27 batch 50/2221) Loss:10.53663444519043\n",
      "epoch:27 batch 60/2221) Loss:5.94279670715332\n",
      "epoch:27 batch 70/2221) Loss:5.121912956237793\n",
      "epoch:27 batch 80/2221) Loss:4.840961456298828\n",
      "epoch:27 batch 90/2221) Loss:5.221961975097656\n",
      "epoch:27 batch 100/2221) Loss:7.945298671722412\n",
      "epoch:27 batch 110/2221) Loss:14.332441329956055\n",
      "epoch:27 batch 120/2221) Loss:25.567203521728516\n",
      "epoch:27 batch 130/2221) Loss:3.8690528869628906\n",
      "epoch:27 batch 140/2221) Loss:18.928874969482422\n",
      "epoch:27 batch 150/2221) Loss:2.6644935607910156\n",
      "epoch:27 batch 160/2221) Loss:16.942230224609375\n",
      "epoch:27 batch 170/2221) Loss:1.1900049448013306\n",
      "epoch:27 batch 180/2221) Loss:12.252233505249023\n",
      "epoch:27 batch 190/2221) Loss:1.5996476411819458\n",
      "epoch:27 batch 200/2221) Loss:10.48502254486084\n",
      "epoch:27 batch 210/2221) Loss:9.695558547973633\n",
      "epoch:27 batch 220/2221) Loss:9.456005096435547\n",
      "epoch:27 batch 230/2221) Loss:9.424848556518555\n",
      "epoch:27 batch 240/2221) Loss:1.0015097856521606\n",
      "epoch:27 batch 250/2221) Loss:9.677550315856934\n",
      "epoch:27 batch 260/2221) Loss:7.475584030151367\n",
      "epoch:27 batch 270/2221) Loss:10.6036376953125\n",
      "epoch:27 batch 280/2221) Loss:13.06036376953125\n",
      "epoch:27 batch 290/2221) Loss:3.6076674461364746\n",
      "epoch:27 batch 300/2221) Loss:22.886672973632812\n",
      "epoch:27 batch 310/2221) Loss:7.2260565757751465\n",
      "epoch:27 batch 320/2221) Loss:10.14346694946289\n",
      "epoch:27 batch 330/2221) Loss:6.647127151489258\n",
      "epoch:27 batch 340/2221) Loss:4.878702163696289\n",
      "epoch:27 batch 350/2221) Loss:1.361301064491272\n",
      "epoch:27 batch 360/2221) Loss:10.733267784118652\n",
      "epoch:27 batch 370/2221) Loss:2.507707118988037\n",
      "epoch:27 batch 380/2221) Loss:14.58565616607666\n",
      "epoch:27 batch 390/2221) Loss:0.7154401540756226\n",
      "epoch:27 batch 400/2221) Loss:8.140948295593262\n",
      "epoch:27 batch 410/2221) Loss:0.42492616176605225\n",
      "epoch:27 batch 420/2221) Loss:15.242280960083008\n",
      "epoch:27 batch 430/2221) Loss:1.9557257890701294\n",
      "epoch:27 batch 440/2221) Loss:24.42620849609375\n",
      "epoch:27 batch 450/2221) Loss:3.821941375732422\n",
      "epoch:27 batch 460/2221) Loss:7.956725597381592\n",
      "epoch:27 batch 470/2221) Loss:8.365745544433594\n",
      "epoch:27 batch 480/2221) Loss:8.836395263671875\n",
      "epoch:27 batch 490/2221) Loss:8.249521255493164\n",
      "epoch:27 batch 500/2221) Loss:6.643306255340576\n",
      "epoch:27 batch 510/2221) Loss:10.928533554077148\n",
      "epoch:27 batch 520/2221) Loss:13.798508644104004\n",
      "epoch:27 batch 530/2221) Loss:5.513387203216553\n",
      "epoch:27 batch 540/2221) Loss:5.76294469833374\n",
      "epoch:27 batch 550/2221) Loss:15.873746871948242\n",
      "epoch:27 batch 560/2221) Loss:1.1546766757965088\n",
      "epoch:27 batch 570/2221) Loss:11.355628967285156\n",
      "epoch:27 batch 580/2221) Loss:0.9262804985046387\n",
      "epoch:27 batch 590/2221) Loss:1.9229249954223633\n",
      "epoch:27 batch 600/2221) Loss:5.5857696533203125\n",
      "epoch:27 batch 610/2221) Loss:6.350184917449951\n",
      "epoch:27 batch 620/2221) Loss:3.8497278690338135\n",
      "epoch:27 batch 630/2221) Loss:10.345193862915039\n",
      "epoch:27 batch 640/2221) Loss:10.691323280334473\n",
      "epoch:27 batch 650/2221) Loss:11.317678451538086\n",
      "epoch:27 batch 660/2221) Loss:3.2926411628723145\n",
      "epoch:27 batch 670/2221) Loss:1.6798402070999146\n",
      "epoch:27 batch 680/2221) Loss:13.629629135131836\n",
      "epoch:27 batch 690/2221) Loss:7.302388668060303\n",
      "epoch:27 batch 700/2221) Loss:0.9125124216079712\n",
      "epoch:27 batch 710/2221) Loss:26.7061767578125\n",
      "epoch:27 batch 720/2221) Loss:10.07697868347168\n",
      "epoch:27 batch 730/2221) Loss:6.398916721343994\n",
      "epoch:27 batch 740/2221) Loss:10.631832122802734\n",
      "epoch:27 batch 750/2221) Loss:15.904754638671875\n",
      "epoch:27 batch 760/2221) Loss:25.110599517822266\n",
      "epoch:27 batch 770/2221) Loss:12.519852638244629\n",
      "epoch:27 batch 780/2221) Loss:1.1142011880874634\n",
      "epoch:27 batch 790/2221) Loss:10.793399810791016\n",
      "epoch:27 batch 800/2221) Loss:12.391669273376465\n",
      "epoch:27 batch 810/2221) Loss:1.8071259260177612\n",
      "epoch:27 batch 820/2221) Loss:15.86215591430664\n",
      "epoch:27 batch 830/2221) Loss:4.1910881996154785\n",
      "epoch:27 batch 840/2221) Loss:9.411905288696289\n",
      "epoch:27 batch 850/2221) Loss:15.97171688079834\n",
      "epoch:27 batch 860/2221) Loss:8.312026023864746\n",
      "epoch:27 batch 870/2221) Loss:17.059675216674805\n",
      "epoch:27 batch 880/2221) Loss:6.218944072723389\n",
      "epoch:27 batch 890/2221) Loss:3.640536308288574\n",
      "epoch:27 batch 900/2221) Loss:4.855416297912598\n",
      "epoch:27 batch 910/2221) Loss:3.5252938270568848\n",
      "epoch:27 batch 920/2221) Loss:10.718019485473633\n",
      "epoch:27 batch 930/2221) Loss:12.489507675170898\n",
      "epoch:27 batch 940/2221) Loss:7.841563701629639\n",
      "epoch:27 batch 950/2221) Loss:17.685386657714844\n",
      "epoch:27 batch 960/2221) Loss:3.211646795272827\n",
      "epoch:27 batch 970/2221) Loss:5.573990821838379\n",
      "epoch:27 batch 980/2221) Loss:15.592352867126465\n",
      "epoch:27 batch 990/2221) Loss:7.30849027633667\n",
      "epoch:27 batch 1000/2221) Loss:15.759085655212402\n",
      "epoch:27 batch 1010/2221) Loss:5.546174049377441\n",
      "epoch:27 batch 1020/2221) Loss:1.147078514099121\n",
      "epoch:27 batch 1030/2221) Loss:9.837030410766602\n",
      "epoch:27 batch 1040/2221) Loss:8.351515769958496\n",
      "epoch:27 batch 1050/2221) Loss:0.5952694416046143\n",
      "epoch:27 batch 1060/2221) Loss:3.391618013381958\n",
      "epoch:27 batch 1070/2221) Loss:9.278132438659668\n",
      "epoch:27 batch 1080/2221) Loss:11.243057250976562\n",
      "epoch:27 batch 1090/2221) Loss:4.1213884353637695\n",
      "epoch:27 batch 1100/2221) Loss:13.151494026184082\n",
      "epoch:27 batch 1110/2221) Loss:23.034137725830078\n",
      "epoch:27 batch 1120/2221) Loss:0.7703664898872375\n",
      "epoch:27 batch 1130/2221) Loss:4.014294624328613\n",
      "epoch:27 batch 1140/2221) Loss:5.829197883605957\n",
      "epoch:27 batch 1150/2221) Loss:1.2490863800048828\n",
      "epoch:27 batch 1160/2221) Loss:1.7088497877120972\n",
      "epoch:27 batch 1170/2221) Loss:18.200557708740234\n",
      "epoch:27 batch 1180/2221) Loss:37.40315246582031\n",
      "epoch:27 batch 1190/2221) Loss:6.242441654205322\n",
      "epoch:27 batch 1200/2221) Loss:7.177347183227539\n",
      "epoch:27 batch 1210/2221) Loss:1.8565036058425903\n",
      "epoch:27 batch 1220/2221) Loss:20.304759979248047\n",
      "epoch:27 batch 1230/2221) Loss:12.405923843383789\n",
      "epoch:27 batch 1240/2221) Loss:11.888660430908203\n",
      "epoch:27 batch 1250/2221) Loss:2.7439870834350586\n",
      "epoch:27 batch 1260/2221) Loss:4.445157527923584\n",
      "epoch:27 batch 1270/2221) Loss:6.151476860046387\n",
      "epoch:27 batch 1280/2221) Loss:8.477280616760254\n",
      "epoch:27 batch 1290/2221) Loss:0.48668575286865234\n",
      "epoch:27 batch 1300/2221) Loss:8.407597541809082\n",
      "epoch:27 batch 1310/2221) Loss:13.892017364501953\n",
      "epoch:27 batch 1320/2221) Loss:5.1773786544799805\n",
      "epoch:27 batch 1330/2221) Loss:9.557229042053223\n",
      "epoch:27 batch 1340/2221) Loss:4.712517738342285\n",
      "epoch:27 batch 1350/2221) Loss:4.212320804595947\n",
      "epoch:27 batch 1360/2221) Loss:0.49766647815704346\n",
      "epoch:27 batch 1370/2221) Loss:3.386955499649048\n",
      "epoch:27 batch 1380/2221) Loss:3.4306955337524414\n",
      "epoch:27 batch 1390/2221) Loss:2.3398704528808594\n",
      "epoch:27 batch 1400/2221) Loss:8.997965812683105\n",
      "epoch:27 batch 1410/2221) Loss:1.6468212604522705\n",
      "epoch:27 batch 1420/2221) Loss:7.061460971832275\n",
      "epoch:27 batch 1430/2221) Loss:11.800827026367188\n",
      "epoch:27 batch 1440/2221) Loss:6.22480583190918\n",
      "epoch:27 batch 1450/2221) Loss:5.3801445960998535\n",
      "epoch:27 batch 1460/2221) Loss:6.230123519897461\n",
      "epoch:27 batch 1470/2221) Loss:31.409278869628906\n",
      "epoch:27 batch 1480/2221) Loss:8.050284385681152\n",
      "epoch:27 batch 1490/2221) Loss:5.776063919067383\n",
      "epoch:27 batch 1500/2221) Loss:4.616673469543457\n",
      "epoch:27 batch 1510/2221) Loss:7.520390510559082\n",
      "epoch:27 batch 1520/2221) Loss:13.274395942687988\n",
      "epoch:27 batch 1530/2221) Loss:17.223482131958008\n",
      "epoch:27 batch 1540/2221) Loss:5.332520008087158\n",
      "epoch:27 batch 1550/2221) Loss:19.53213882446289\n",
      "epoch:27 batch 1560/2221) Loss:6.801718235015869\n",
      "epoch:27 batch 1570/2221) Loss:7.090972423553467\n",
      "epoch:27 batch 1580/2221) Loss:8.022045135498047\n",
      "epoch:27 batch 1590/2221) Loss:5.6005401611328125\n",
      "epoch:27 batch 1600/2221) Loss:11.8271484375\n",
      "epoch:27 batch 1610/2221) Loss:15.217371940612793\n",
      "epoch:27 batch 1620/2221) Loss:15.403995513916016\n",
      "epoch:27 batch 1630/2221) Loss:13.036112785339355\n",
      "epoch:27 batch 1640/2221) Loss:5.506669521331787\n",
      "epoch:27 batch 1650/2221) Loss:8.803054809570312\n",
      "epoch:27 batch 1660/2221) Loss:4.523087501525879\n",
      "epoch:27 batch 1670/2221) Loss:1.433872938156128\n",
      "epoch:27 batch 1680/2221) Loss:4.114719867706299\n",
      "epoch:27 batch 1690/2221) Loss:7.220349311828613\n",
      "epoch:27 batch 1700/2221) Loss:4.855432510375977\n",
      "epoch:27 batch 1710/2221) Loss:6.3295674324035645\n",
      "epoch:27 batch 1720/2221) Loss:5.943987846374512\n",
      "epoch:27 batch 1730/2221) Loss:4.245450019836426\n",
      "epoch:27 batch 1740/2221) Loss:3.1333394050598145\n",
      "epoch:27 batch 1750/2221) Loss:4.301572799682617\n",
      "epoch:27 batch 1760/2221) Loss:3.8163552284240723\n",
      "epoch:27 batch 1770/2221) Loss:4.027577877044678\n",
      "epoch:27 batch 1780/2221) Loss:4.075986862182617\n",
      "epoch:27 batch 1790/2221) Loss:21.98271942138672\n",
      "epoch:27 batch 1800/2221) Loss:8.66711139678955\n",
      "epoch:27 batch 1810/2221) Loss:2.6188740730285645\n",
      "epoch:27 batch 1820/2221) Loss:6.4500579833984375\n",
      "epoch:27 batch 1830/2221) Loss:8.050008773803711\n",
      "epoch:27 batch 1840/2221) Loss:18.240665435791016\n",
      "epoch:27 batch 1850/2221) Loss:10.273186683654785\n",
      "epoch:27 batch 1860/2221) Loss:18.969696044921875\n",
      "epoch:27 batch 1870/2221) Loss:14.14795207977295\n",
      "epoch:27 batch 1880/2221) Loss:14.352005958557129\n",
      "epoch:27 batch 1890/2221) Loss:8.288446426391602\n",
      "epoch:27 batch 1900/2221) Loss:3.7306008338928223\n",
      "epoch:27 batch 1910/2221) Loss:11.133660316467285\n",
      "epoch:27 batch 1920/2221) Loss:6.496874809265137\n",
      "epoch:27 batch 1930/2221) Loss:7.67315673828125\n",
      "epoch:27 batch 1940/2221) Loss:6.419883728027344\n",
      "epoch:27 batch 1950/2221) Loss:3.713627338409424\n",
      "epoch:27 batch 1960/2221) Loss:2.600407838821411\n",
      "epoch:27 batch 1970/2221) Loss:8.016353607177734\n",
      "epoch:27 batch 1980/2221) Loss:11.303017616271973\n",
      "epoch:27 batch 1990/2221) Loss:1.3028267621994019\n",
      "epoch:27 batch 2000/2221) Loss:3.3141016960144043\n",
      "epoch:27 batch 2010/2221) Loss:3.4815778732299805\n",
      "epoch:27 batch 2020/2221) Loss:12.318415641784668\n",
      "epoch:27 batch 2030/2221) Loss:0.8890165090560913\n",
      "epoch:27 batch 2040/2221) Loss:1.3893519639968872\n",
      "epoch:27 batch 2050/2221) Loss:16.810649871826172\n",
      "epoch:27 batch 2060/2221) Loss:10.002484321594238\n",
      "epoch:27 batch 2070/2221) Loss:2.3695452213287354\n",
      "epoch:27 batch 2080/2221) Loss:18.99245834350586\n",
      "epoch:27 batch 2090/2221) Loss:5.194467544555664\n",
      "epoch:27 batch 2100/2221) Loss:4.261688709259033\n",
      "epoch:27 batch 2110/2221) Loss:2.234058380126953\n",
      "epoch:27 batch 2120/2221) Loss:19.06082534790039\n",
      "epoch:27 batch 2130/2221) Loss:4.254770278930664\n",
      "epoch:27 batch 2140/2221) Loss:8.498635292053223\n",
      "epoch:27 batch 2150/2221) Loss:13.722005844116211\n",
      "epoch:27 batch 2160/2221) Loss:5.710455894470215\n",
      "epoch:27 batch 2170/2221) Loss:25.85531234741211\n",
      "epoch:27 batch 2180/2221) Loss:5.239573955535889\n",
      "epoch:27 batch 2190/2221) Loss:1.80339515209198\n",
      "epoch:27 batch 2200/2221) Loss:9.303976058959961\n",
      "epoch:27 batch 2210/2221) Loss:4.36940336227417\n",
      "epoch:27 batch 2220/2221) Loss:1.0220195055007935\n",
      "epoch:27 precision:0.9965789732111956 recall:0.9895642707255881 f1-score:0.9930242660863338\n",
      "epoch:28 batch 1/2221) Loss:2.959862232208252\n",
      "epoch:28 batch 10/2221) Loss:2.466437816619873\n",
      "epoch:28 batch 20/2221) Loss:11.586860656738281\n",
      "epoch:28 batch 30/2221) Loss:9.529109954833984\n",
      "epoch:28 batch 40/2221) Loss:3.771358013153076\n",
      "epoch:28 batch 50/2221) Loss:11.971639633178711\n",
      "epoch:28 batch 60/2221) Loss:6.2014031410217285\n",
      "epoch:28 batch 70/2221) Loss:8.548343658447266\n",
      "epoch:28 batch 80/2221) Loss:14.846525192260742\n",
      "epoch:28 batch 90/2221) Loss:8.804464340209961\n",
      "epoch:28 batch 100/2221) Loss:11.371053695678711\n",
      "epoch:28 batch 110/2221) Loss:8.096423149108887\n",
      "epoch:28 batch 120/2221) Loss:15.00676155090332\n",
      "epoch:28 batch 130/2221) Loss:3.9181251525878906\n",
      "epoch:28 batch 140/2221) Loss:15.51099967956543\n",
      "epoch:28 batch 150/2221) Loss:1.3089333772659302\n",
      "epoch:28 batch 160/2221) Loss:1.992224931716919\n",
      "epoch:28 batch 170/2221) Loss:0.7818956971168518\n",
      "epoch:28 batch 180/2221) Loss:12.85678768157959\n",
      "epoch:28 batch 190/2221) Loss:2.4098944664001465\n",
      "epoch:28 batch 200/2221) Loss:11.964492797851562\n",
      "epoch:28 batch 210/2221) Loss:2.8178248405456543\n",
      "epoch:28 batch 220/2221) Loss:2.882739782333374\n",
      "epoch:28 batch 230/2221) Loss:7.9929518699646\n",
      "epoch:28 batch 240/2221) Loss:13.714418411254883\n",
      "epoch:28 batch 250/2221) Loss:10.978591918945312\n",
      "epoch:28 batch 260/2221) Loss:17.675817489624023\n",
      "epoch:28 batch 270/2221) Loss:9.878084182739258\n",
      "epoch:28 batch 280/2221) Loss:28.177963256835938\n",
      "epoch:28 batch 290/2221) Loss:5.7746405601501465\n",
      "epoch:28 batch 300/2221) Loss:9.548638343811035\n",
      "epoch:28 batch 310/2221) Loss:10.48112678527832\n",
      "epoch:28 batch 320/2221) Loss:6.468439102172852\n",
      "epoch:28 batch 330/2221) Loss:1.1648633480072021\n",
      "epoch:28 batch 340/2221) Loss:7.354406356811523\n",
      "epoch:28 batch 350/2221) Loss:6.350831508636475\n",
      "epoch:28 batch 360/2221) Loss:6.342138290405273\n",
      "epoch:28 batch 370/2221) Loss:7.047414302825928\n",
      "epoch:28 batch 380/2221) Loss:5.718404769897461\n",
      "epoch:28 batch 390/2221) Loss:6.923473834991455\n",
      "epoch:28 batch 400/2221) Loss:8.538311004638672\n",
      "epoch:28 batch 410/2221) Loss:14.306621551513672\n",
      "epoch:28 batch 420/2221) Loss:4.974310874938965\n",
      "epoch:28 batch 430/2221) Loss:1.1505264043807983\n",
      "epoch:28 batch 440/2221) Loss:9.676340103149414\n",
      "epoch:28 batch 450/2221) Loss:3.1553235054016113\n",
      "epoch:28 batch 460/2221) Loss:6.300027847290039\n",
      "epoch:28 batch 470/2221) Loss:4.314411640167236\n",
      "epoch:28 batch 480/2221) Loss:2.785323143005371\n",
      "epoch:28 batch 490/2221) Loss:1.4002866744995117\n",
      "epoch:28 batch 500/2221) Loss:18.30810546875\n",
      "epoch:28 batch 510/2221) Loss:4.886628150939941\n",
      "epoch:28 batch 520/2221) Loss:8.560522079467773\n",
      "epoch:28 batch 530/2221) Loss:10.874229431152344\n",
      "epoch:28 batch 540/2221) Loss:1.6919599771499634\n",
      "epoch:28 batch 550/2221) Loss:2.7922263145446777\n",
      "epoch:28 batch 560/2221) Loss:14.506437301635742\n",
      "epoch:28 batch 570/2221) Loss:5.350142478942871\n",
      "epoch:28 batch 580/2221) Loss:5.900096893310547\n",
      "epoch:28 batch 590/2221) Loss:18.934741973876953\n",
      "epoch:28 batch 600/2221) Loss:7.763356685638428\n",
      "epoch:28 batch 610/2221) Loss:14.197689056396484\n",
      "epoch:28 batch 620/2221) Loss:2.3663017749786377\n",
      "epoch:28 batch 630/2221) Loss:7.615480422973633\n",
      "epoch:28 batch 640/2221) Loss:10.994220733642578\n",
      "epoch:28 batch 650/2221) Loss:1.4292802810668945\n",
      "epoch:28 batch 660/2221) Loss:15.974434852600098\n",
      "epoch:28 batch 670/2221) Loss:2.435579776763916\n",
      "epoch:28 batch 680/2221) Loss:10.154583930969238\n",
      "epoch:28 batch 690/2221) Loss:5.038694381713867\n",
      "epoch:28 batch 700/2221) Loss:7.12294864654541\n",
      "epoch:28 batch 710/2221) Loss:9.950315475463867\n",
      "epoch:28 batch 720/2221) Loss:14.410263061523438\n",
      "epoch:28 batch 730/2221) Loss:8.522104263305664\n",
      "epoch:28 batch 740/2221) Loss:31.89485740661621\n",
      "epoch:28 batch 750/2221) Loss:10.316915512084961\n",
      "epoch:28 batch 760/2221) Loss:13.6824312210083\n",
      "epoch:28 batch 770/2221) Loss:6.7373199462890625\n",
      "epoch:28 batch 780/2221) Loss:19.532306671142578\n",
      "epoch:28 batch 790/2221) Loss:3.48899507522583\n",
      "epoch:28 batch 800/2221) Loss:12.348908424377441\n",
      "epoch:28 batch 810/2221) Loss:6.523816108703613\n",
      "epoch:28 batch 820/2221) Loss:15.820466995239258\n",
      "epoch:28 batch 830/2221) Loss:7.79276180267334\n",
      "epoch:28 batch 840/2221) Loss:5.160738945007324\n",
      "epoch:28 batch 850/2221) Loss:5.544839859008789\n",
      "epoch:28 batch 860/2221) Loss:5.806854724884033\n",
      "epoch:28 batch 870/2221) Loss:4.7245378494262695\n",
      "epoch:28 batch 880/2221) Loss:10.814748764038086\n",
      "epoch:28 batch 890/2221) Loss:1.1036558151245117\n",
      "epoch:28 batch 900/2221) Loss:2.875974178314209\n",
      "epoch:28 batch 910/2221) Loss:7.264936447143555\n",
      "epoch:28 batch 920/2221) Loss:1.797903299331665\n",
      "epoch:28 batch 930/2221) Loss:3.0616793632507324\n",
      "epoch:28 batch 940/2221) Loss:1.4105854034423828\n",
      "epoch:28 batch 950/2221) Loss:15.631757736206055\n",
      "epoch:28 batch 960/2221) Loss:4.348232746124268\n",
      "epoch:28 batch 970/2221) Loss:18.896821975708008\n",
      "epoch:28 batch 980/2221) Loss:11.978981971740723\n",
      "epoch:28 batch 990/2221) Loss:7.372008323669434\n",
      "epoch:28 batch 1000/2221) Loss:5.629679203033447\n",
      "epoch:28 batch 1010/2221) Loss:17.174808502197266\n",
      "epoch:28 batch 1020/2221) Loss:10.105381965637207\n",
      "epoch:28 batch 1030/2221) Loss:0.7776528596878052\n",
      "epoch:28 batch 1040/2221) Loss:8.414555549621582\n",
      "epoch:28 batch 1050/2221) Loss:13.882052421569824\n",
      "epoch:28 batch 1060/2221) Loss:3.3032822608947754\n",
      "epoch:28 batch 1070/2221) Loss:4.223041534423828\n",
      "epoch:28 batch 1080/2221) Loss:6.018447399139404\n",
      "epoch:28 batch 1090/2221) Loss:16.58584976196289\n",
      "epoch:28 batch 1100/2221) Loss:3.2701728343963623\n",
      "epoch:28 batch 1110/2221) Loss:24.84067153930664\n",
      "epoch:28 batch 1120/2221) Loss:7.182243347167969\n",
      "epoch:28 batch 1130/2221) Loss:8.165706634521484\n",
      "epoch:28 batch 1140/2221) Loss:6.810367584228516\n",
      "epoch:28 batch 1150/2221) Loss:8.842487335205078\n",
      "epoch:28 batch 1160/2221) Loss:7.6957173347473145\n",
      "epoch:28 batch 1170/2221) Loss:1.7805404663085938\n",
      "epoch:28 batch 1180/2221) Loss:6.366171836853027\n",
      "epoch:28 batch 1190/2221) Loss:7.4463887214660645\n",
      "epoch:28 batch 1200/2221) Loss:2.6058273315429688\n",
      "epoch:28 batch 1210/2221) Loss:7.491796493530273\n",
      "epoch:28 batch 1220/2221) Loss:2.7702419757843018\n",
      "epoch:28 batch 1230/2221) Loss:12.970298767089844\n",
      "epoch:28 batch 1240/2221) Loss:1.874938726425171\n",
      "epoch:28 batch 1250/2221) Loss:6.340304374694824\n",
      "epoch:28 batch 1260/2221) Loss:10.488433837890625\n",
      "epoch:28 batch 1270/2221) Loss:6.111204624176025\n",
      "epoch:28 batch 1280/2221) Loss:4.181098937988281\n",
      "epoch:28 batch 1290/2221) Loss:13.784785270690918\n",
      "epoch:28 batch 1300/2221) Loss:6.166793346405029\n",
      "epoch:28 batch 1310/2221) Loss:1.0813130140304565\n",
      "epoch:28 batch 1320/2221) Loss:2.620542526245117\n",
      "epoch:28 batch 1330/2221) Loss:0.6710784435272217\n",
      "epoch:28 batch 1340/2221) Loss:11.853041648864746\n",
      "epoch:28 batch 1350/2221) Loss:5.874992847442627\n",
      "epoch:28 batch 1360/2221) Loss:7.2394561767578125\n",
      "epoch:28 batch 1370/2221) Loss:7.563501834869385\n",
      "epoch:28 batch 1380/2221) Loss:3.3340420722961426\n",
      "epoch:28 batch 1390/2221) Loss:7.451732158660889\n",
      "epoch:28 batch 1400/2221) Loss:3.030045986175537\n",
      "epoch:28 batch 1410/2221) Loss:11.978079795837402\n",
      "epoch:28 batch 1420/2221) Loss:8.170331001281738\n",
      "epoch:28 batch 1430/2221) Loss:6.51069974899292\n",
      "epoch:28 batch 1440/2221) Loss:16.631546020507812\n",
      "epoch:28 batch 1450/2221) Loss:3.278318405151367\n",
      "epoch:28 batch 1460/2221) Loss:3.3325107097625732\n",
      "epoch:28 batch 1470/2221) Loss:6.94249963760376\n",
      "epoch:28 batch 1480/2221) Loss:13.089391708374023\n",
      "epoch:28 batch 1490/2221) Loss:1.1072056293487549\n",
      "epoch:28 batch 1500/2221) Loss:1.1155505180358887\n",
      "epoch:28 batch 1510/2221) Loss:5.449297904968262\n",
      "epoch:28 batch 1520/2221) Loss:13.193544387817383\n",
      "epoch:28 batch 1530/2221) Loss:1.5287173986434937\n",
      "epoch:28 batch 1540/2221) Loss:7.332429885864258\n",
      "epoch:28 batch 1550/2221) Loss:4.014671325683594\n",
      "epoch:28 batch 1560/2221) Loss:1.0915567874908447\n",
      "epoch:28 batch 1570/2221) Loss:6.781604766845703\n",
      "epoch:28 batch 1580/2221) Loss:3.1680092811584473\n",
      "epoch:28 batch 1590/2221) Loss:7.178126335144043\n",
      "epoch:28 batch 1600/2221) Loss:0.7402330636978149\n",
      "epoch:28 batch 1610/2221) Loss:1.7647696733474731\n",
      "epoch:28 batch 1620/2221) Loss:7.010568618774414\n",
      "epoch:28 batch 1630/2221) Loss:2.0193302631378174\n",
      "epoch:28 batch 1640/2221) Loss:5.367016315460205\n",
      "epoch:28 batch 1650/2221) Loss:14.73263168334961\n",
      "epoch:28 batch 1660/2221) Loss:2.863234519958496\n",
      "epoch:28 batch 1670/2221) Loss:7.810707092285156\n",
      "epoch:28 batch 1680/2221) Loss:20.948270797729492\n",
      "epoch:28 batch 1690/2221) Loss:2.3429460525512695\n",
      "epoch:28 batch 1700/2221) Loss:10.47122859954834\n",
      "epoch:28 batch 1710/2221) Loss:26.946170806884766\n",
      "epoch:28 batch 1720/2221) Loss:14.020164489746094\n",
      "epoch:28 batch 1730/2221) Loss:8.625450134277344\n",
      "epoch:28 batch 1740/2221) Loss:3.971076726913452\n",
      "epoch:28 batch 1750/2221) Loss:5.6768798828125\n",
      "epoch:28 batch 1760/2221) Loss:10.061379432678223\n",
      "epoch:28 batch 1770/2221) Loss:6.041780471801758\n",
      "epoch:28 batch 1780/2221) Loss:2.161461353302002\n",
      "epoch:28 batch 1790/2221) Loss:5.188717365264893\n",
      "epoch:28 batch 1800/2221) Loss:6.5942487716674805\n",
      "epoch:28 batch 1810/2221) Loss:7.808706283569336\n",
      "epoch:28 batch 1820/2221) Loss:12.217972755432129\n",
      "epoch:28 batch 1830/2221) Loss:0.5671406984329224\n",
      "epoch:28 batch 1840/2221) Loss:5.677118301391602\n",
      "epoch:28 batch 1850/2221) Loss:3.9788596630096436\n",
      "epoch:28 batch 1860/2221) Loss:5.906792163848877\n",
      "epoch:28 batch 1870/2221) Loss:25.411714553833008\n",
      "epoch:28 batch 1880/2221) Loss:2.04856014251709\n",
      "epoch:28 batch 1890/2221) Loss:6.968775749206543\n",
      "epoch:28 batch 1900/2221) Loss:11.91016960144043\n",
      "epoch:28 batch 1910/2221) Loss:3.9653372764587402\n",
      "epoch:28 batch 1920/2221) Loss:15.67148208618164\n",
      "epoch:28 batch 1930/2221) Loss:6.147773265838623\n",
      "epoch:28 batch 1940/2221) Loss:10.968230247497559\n",
      "epoch:28 batch 1950/2221) Loss:11.841151237487793\n",
      "epoch:28 batch 1960/2221) Loss:11.200417518615723\n",
      "epoch:28 batch 1970/2221) Loss:5.298577785491943\n",
      "epoch:28 batch 1980/2221) Loss:6.765233039855957\n",
      "epoch:28 batch 1990/2221) Loss:16.862201690673828\n",
      "epoch:28 batch 2000/2221) Loss:15.136160850524902\n",
      "epoch:28 batch 2010/2221) Loss:4.315591812133789\n",
      "epoch:28 batch 2020/2221) Loss:11.702505111694336\n",
      "epoch:28 batch 2030/2221) Loss:5.075468063354492\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train(model, \u001b[39m'\u001b[39;49m\u001b[39mBilstm_CRF\u001b[39;49m\u001b[39m'\u001b[39;49m, train_dataloader,dev_dataloader, optimizer, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, scheduler\u001b[39m=\u001b[39;49mscheduler)\n",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, model_name, train_dataloader, validate_dataloader, optimizer, scheduler, epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m best_report \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m----> 9\u001b[0m     loss \u001b[39m=\u001b[39m train_single_epoch(model, train_dataloader, validate_dataloader, optimizer, epoch)\n\u001b[0;32m     10\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m     report \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m(model, validate_dataloader, id2tag)\n",
      "Cell \u001b[1;32mIn[9], line 44\u001b[0m, in \u001b[0;36mtrain_single_epoch\u001b[1;34m(model, train_dataloader, validate_dataloader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     41\u001b[0m loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcompute_loss(inputs, label, mask)\n\u001b[0;32m     43\u001b[0m \u001b[39m# 反向传播计算梯度\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     45\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     47\u001b[0m \u001b[39m# 统计损失\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, 'Bilstm_CRF', train_dataloader,dev_dataloader, optimizer, epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型预测与实体抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def tokenizer(sentence):\n",
    "    sentence = re.sub(r'(\\d)([a-zA-Z])', r'\\1 \\2', sentence)\n",
    "    sentence = re.sub(r'([a-zA-Z])(\\d)', r'\\1 \\2', sentence)\n",
    "    tokens = re.findall(r'\\d|[^\\w\\s]|\\w+', sentence)\n",
    "    return tokens\n",
    "\n",
    "def encode(inputs, word2id):\n",
    "    sentence_to_id = [word2id[word] if word in word2id else word2id['<UNK>'] for word in inputs]\n",
    "    return torch.tensor(sentence_to_id)\n",
    "\n",
    "def single_predict(model_path, content, word2id, tag2id):\n",
    "    id2word = {v:k for k,v in word2id.items()}\n",
    "    id2tag = {v:k for k,v in tag2id.items()}\n",
    "    model = BilstmCrf(word2id, tag2id, embedding_dim=128, hidden_dim=200, num_layers=2, dropout=0.3).to(device)\n",
    "    model.load_state_dict(model_path)\n",
    "    inputs = encode(tokenizer(content), word2id).unsqueeze(0)\n",
    "    predict = model.decode(inputs)[0]\n",
    "    entities = defaultdict(list)\n",
    "    current_entity = []\n",
    "    print(predict)\n",
    "    for i, char_no in enumerate(predict):\n",
    "        if inputs[0][i] == 0:\n",
    "            break\n",
    "        char_text = id2word[inputs.tolist()[0][i]]\n",
    "        predict_tag_type = id2tag[char_no]\n",
    "        if predict_tag_type.startswith('B'):\n",
    "            current_entity = [char_text + '/' + predict_tag_type]\n",
    "        elif predict_tag_type.startswith('I') or predict_tag_type.startswith('E'):\n",
    "            if current_entity and current_entity[-1].split('/')[1][1:] == predict_tag_type[1:]:\n",
    "                current_entity.append(char_text + '/' + predict_tag_type)\n",
    "            else:\n",
    "                current_entity = []\n",
    "        elif predict_tag_type == 'O' and current_entity:\n",
    "            entities[current_entity[-1].split('/')[1][2:]] = ''.join([w.split('/')[0] for w in current_entity])\n",
    "            current_entity = []\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "amount: 36600.0\n",
      "days: tomorrow\n"
     ]
    }
   ],
   "source": [
    "dic = torch.load('./Bilstm_CRF_20230521_232126.pt', map_location=lambda storage, loc: storage)\n",
    "inputs = 'Your OK loan of N 36600.0 is due tomorrow Please make sure your bank card ending in 2837 has sufficient balance You can pay via USSD or bank transfer paycom o pay 5568815140'\n",
    "entities = single_predict(dic, inputs, word2id, tag2id)\n",
    "for key in entities.keys():\n",
    "    print(f'{key}: {entities[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-amount': 1,\n",
       " 'I-amount': 2,\n",
       " 'E-amount': 3,\n",
       " 'B-days': 4,\n",
       " 'I-days': 5,\n",
       " 'E-days': 6}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"text\": [\"EaseCash\", \"reminds\", \"you\", \"that\", \"the\", \"1\", \"installment\", \"of\", \"your\", \"2\", \"9\", \"2\", \"1\", \"2\", \"NGN\", \"will\", \"be\", \"due\", \"in\", \"1\", \"?\", \"days\", \".\", \"Maintaining\", \"a\", \"good\", \"credit\", \"standing\", \"will\", \"help\", \"you\", \"to\", \"increase\", \"your\", \"credit\", \"limit\"], \n",
    "\"label\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-amount\", \"I-amount\", \"I-amount\", \"I-amount\", \"E-amount\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-days\", \"I-days\", \"E-days\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
